# –ü–ª–∞–Ω –∑–∞ –ü—Ä–æ–µ–∫—Ç: –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–∞–Ω–µ –Ω–∞ –ü–∞–∑–∞—Ä–∞ –Ω–∞ –ê–∫—Ü–∏–∏
## –û—Ç –Ω—É–ª–∞ –¥–æ –ø—Ä–æ—Ñ–µ—Å–∏–æ–Ω–∞–ª–Ω–∞ —Å–∏—Å—Ç–µ–º–∞

---

## üìã –û–±—â–∞ –≤–∏–∑–∏—è –Ω–∞ –ø—Ä–æ–µ–∫—Ç–∞

**–¶–µ–ª:** –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –º–æ–¥–µ–ª –æ—Ç –Ω—É–ª–∞—Ç–∞ –∑–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–∞–Ω–µ –Ω–∞ –ø–∞–∑–∞—Ä–∞ –Ω–∞ –∞–∫—Ü–∏–∏ —Å –∏–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ Hugging Face datasets –∏ —Å—ä–≤—Ä–µ–º–µ–Ω–Ω–∏ —Ç–µ—Ö–Ω–∏–∫–∏ –∑–∞ time series forecasting.

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ–Ω —Å—Ç–µ–∫:**
- Python 3.8+
- PyTorch / TensorFlow (–ø—Ä–µ–ø–æ—Ä—ä—á–∏—Ç–µ–ª–Ω–æ PyTorch –∑–∞ –ø–æ-–≥–æ–ª—è–º–∞ –∫–æ–Ω—Ç—Ä–æ–ª)
- Hugging Face Datasets & Transformers
- NumPy, Pandas
- Matplotlib, Plotly (–∑–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è)
- scikit-learn (–∑–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –±–∞–∑–æ–≤–∏ –º–æ–¥–µ–ª–∏)

---

## üèóÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
stock-price-prediction/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/              # –°–∏—Ä–æ–≤–∏ –¥–∞–Ω–Ω–∏ –æ—Ç Hugging Face
‚îÇ   ‚îú‚îÄ‚îÄ processed/        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–µ–Ω–∏ –¥–∞–Ω–Ω–∏
‚îÇ   ‚îî‚îÄ‚îÄ features/         # –ò–∑–≤–ª–µ—á–µ–Ω–∏ features
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader.py     # –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏ –æ—Ç Hugging Face
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessor.py  # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ—á–∏—Å—Ç–≤–∞–Ω–µ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_engineering.py  # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ features
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_model.py     # –ë–∞–∑–æ–≤ –∫–ª–∞—Å –∑–∞ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transformer_model.py  # Transformer –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –æ—Ç –Ω—É–ª–∞—Ç–∞
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lstm_model.py     # LSTM baseline
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ components/       # –û—Ç–¥–µ Architectural components
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ attention.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ encoder.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ decoder.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py        # Training loop
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ losses.py         # Loss functions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ callbacks.py      # Callbacks (early stopping, checkpointing)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py        # Evaluation metrics
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ visualizations.py # –ì—Ä–∞—Ñ–∏–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ config.py         # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îÇ       ‚îî‚îÄ‚îÄ helpers.py        # Helper —Ñ—É–Ω–∫—Ü–∏–∏
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_exploration.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_preprocessing.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_model_development.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_training.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 05_evaluation.ipynb
‚îÇ
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îú‚îÄ‚îÄ default_config.yaml   # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–µ–Ω —Ñ–∞–π–ª
‚îÇ   ‚îî‚îÄ‚îÄ model_configs.yaml    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–∞ –º–æ–¥–µ–ª–∏
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ train.py              # –°–∫—Ä–∏–ø—Ç –∑–∞ –æ–±—É—á–µ–Ω–∏–µ
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py           # –°–∫—Ä–∏–ø—Ç –∑–∞ –æ—Ü–µ–Ω–∫–∞
‚îÇ   ‚îî‚îÄ‚îÄ inference.py          # –°–∫—Ä–∏–ø—Ç –∑–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–∞–Ω–µ
‚îÇ
‚îú‚îÄ‚îÄ models/                   # –ó–∞–ø–∏—Å–∞–Ω–∏ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îî‚îÄ‚îÄ checkpoints/
‚îÇ
‚îú‚îÄ‚îÄ results/                  # –†–µ–∑—É–ª—Ç–∞—Ç–∏ –∏ –≥—Ä–∞—Ñ–∏–∫–∏
‚îÇ   ‚îú‚îÄ‚îÄ plots/
‚îÇ   ‚îî‚îÄ‚îÄ metrics/
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ setup.py
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ .gitignore
```

---

## üìÖ –ï—Ç–∞–ø 1: –ò–∑–±–æ—Ä –Ω–∞ Dataset –∏ –ü—Ä–æ—É—á–≤–∞–Ω–µ (1-2 –¥–Ω–∏)

### 1.1 –ò–∑–±–æ—Ä –Ω–∞ Hugging Face Dataset
**–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏ datasets:**
- `TimeSeries/stock_prices` - –∞–∫–æ —Å—ä—â–µ—Å—Ç–≤—É–≤–∞
- `t4tiana/store-sales-time-series-forecasting` - –∑–∞ time series forecasting
- `ykotseruba/stock-prices-daily` - –¥–Ω–µ–≤–Ω–∏ —Ü–µ–Ω–∏ –Ω–∞ –∞–∫—Ü–∏–∏
- `HUPD/stock-market` - –ø–∞–∑–∞—Ä–Ω–∏ –¥–∞–Ω–Ω–∏
- –ò–ª–∏ –∫–æ–º–±–∏–Ω–∏—Ä–∞–Ω–µ –Ω–∞ –Ω—è–∫–æ–ª–∫–æ datasets

**–î–µ–π—Å—Ç–≤–∏—è:**
- ‚úÖ –ü—Ä–æ—É—á–≤–∞–Ω–µ –Ω–∞ –Ω–∞–ª–∏—á–Ω–∏—Ç–µ datasets –≤ Hugging Face
- ‚úÖ –ò–∑–±–æ—Ä –Ω–∞ –ø–æ–¥—Ö–æ–¥—è—â dataset –∏–ª–∏ –∫–æ–º–±–∏–Ω–∞—Ü–∏—è
- ‚úÖ –ê–Ω–∞–ª–∏–∑ –Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞—Ç–∞ –∏ –∫–∞—á–µ—Å—Ç–≤–æ—Ç–æ –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ
- ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–∞–Ω–µ –Ω–∞ –∏–∑–±–æ—Ä–∞ –≤ notebook `01_data_exploration.ipynb`

### 1.2 –ê–Ω–∞–ª–∏–∑ –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ
- –†–∞–∑–º–µ—Ä–∏ –Ω–∞ dataset (–±—Ä–æ–π –∑–∞–ø–∏—Å–∏, –ø–µ—Ä–∏–æ–¥)
- –ù–∞–ª–∏—á–Ω–∏ features (Open, High, Low, Close, Volume, etc.)
- –õ–∏–ø—Å–≤–∞—â–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏ –∏ outliers
- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∞–Ω–∞–ª–∏–∑ (–¥–∏—Å—Ç—Ä–∏–±—É—Ü–∏—è, –∫–æ—Ä–µ–ª–∞—Ü–∏–∏)
- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ –≤—Ä–µ–º–µ–≤–∏ —Ä–µ–¥–∏—Ü–∏

---

## üìä –ï—Ç–∞–ø 2: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ Feature Engineering (2-3 –¥–Ω–∏)

### 2.1 –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ Data Pipeline (`src/data/loader.py`)
**–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–Ω–æ—Å—Ç–∏:**
```python
- load_hf_dataset(dataset_name, splits)
- save_raw_data()
- load_raw_data()
```

### 2.2 –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ (`src/data/preprocessor.py`)
**–ó–∞–¥–∞—á–∏:**
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ –ª–∏–ø—Å–≤–∞—â–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
  - Forward fill, backward fill
  - Interpolation
  - Drop rows —Å –∫—Ä–∏—Ç–∏—á–Ω–∏ –ª–∏–ø—Å–∏
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ outliers
  - IQR method
  - Z-score method
  - Clipping –Ω–∞ –µ–∫—Å—Ç—Ä–µ–º–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
- Normalization/Standardization
  - Min-Max scaling
  - Z-score normalization
  - Robust scaling
- –í—Ä–µ–º–µ–≤–∏ features
  - Extract date components (day, month, year, day_of_week)
  - Cyclical encoding (sin/cos –∑–∞ –¥–µ–Ω –∏ –º–µ—Å–µ—Ü)
  - Lag features (–ø—Ä–µ–¥—Ö–æ–¥–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏)

### 2.3 Feature Engineering (`src/data/feature_engineering.py`)
**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏:**
- Moving Averages (SMA, EMA, WMA)
- Momentum indicators (RSI, MACD, Stochastic)
- Volatility indicators (Bollinger Bands, ATR)
- Volume indicators (OBV, Volume SMA ratio)
- Price patterns (Candlestick patterns - –æ–ø—Ü–∏–æ–Ω–∞–ª–Ω–æ)

**–°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ features:**
```python
- calculate_technical_indicators(df, windows=[5, 10, 20, 50])
- create_lag_features(df, lags=[1, 2, 3, 5, 10])
- create_rolling_statistics(df)
- encode_temporal_features(df)
```

### 2.4 Train/Validation/Test Split
- **–í—Ä–µ–º–µ–≤–∏ split** (–Ω–µ —Å–ª—É—á–∞–π–Ω–æ!) - –≤–∞–∂–Ω–æ –∑–∞ time series
- Train: 70% (–Ω–∞–π-—Å—Ç–∞—Ä–∏ –¥–∞–Ω–Ω–∏)
- Validation: 15%
- Test: 15% (–Ω–∞–π-–Ω–æ–≤–∏ –¥–∞–Ω–Ω–∏)
- –û–±–µ—Å–ø–µ—á–∞–≤–∞–Ω–µ –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–Ω–æ—Å—Ç

---

## üß† –ï—Ç–∞–ø 3: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–∞ –º–æ–¥–µ–ª–∞ (3-4 –¥–Ω–∏)

### 3.1 –ë–∞–∑–æ–≤ –∫–ª–∞—Å (`src/models/base_model.py`)
–ê–±—Å—Ç—Ä–∞–∫—Ç–µ–Ω –∫–ª–∞—Å —Å –æ–±—â–∏ –º–µ—Ç–æ–¥–∏:
- `forward()`
- `predict()`
- `save_model()`
- `load_model()`

### 3.2 Transformer Model –æ—Ç –Ω—É–ª–∞—Ç–∞ (`src/models/transformer_model.py`)

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –∫–æ–∏—Ç–æ —Ç—Ä—è–±–≤–∞ –¥–∞ —Å—ä–∑–¥–∞–¥–µ–º:**

#### 3.2.1 Positional Encoding (`src/models/components/positional_encoding.py`)
- Sinusoidal positional encoding
- –ò–ª–∏ learnable positional embeddings

#### 3.2.2 Multi-Head Attention (`src/models/components/attention.py`)
- Scaled Dot-Product Attention
- Multi-Head Attention mechanism
- –û–ø—Ü–∏–æ–Ω–∞–ª–Ω–æ: Self-attention –∏ Cross-attention

#### 3.2.3 Encoder (`src/models/components/encoder.py`)
- Transformer Encoder Layer:
  - Multi-Head Self-Attention
  - Feed-Forward Network
  - Layer Normalization
  - Residual connections
- Stack of encoder layers

#### 3.2.4 Decoder (–æ–ø—Ü–∏–æ–Ω–∞–ª–Ω–æ) (`src/models/components/decoder.py`)
- Transformer Decoder Layer:
  - Masked Multi-Head Self-Attention
  - Multi-Head Cross-Attention
  - Feed-Forward Network
- Stack of decoder layers

#### 3.2.5 –ü—ä–ª–Ω–∞ Transformer –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
```python
class StockTransformer(nn.Module):
    - Input embedding layer
    - Positional encoding
    - Encoder stack (6-8 —Å–ª–æ—è)
    - Output projection layer
    - Forecast head (–º–æ–∂–µ –¥–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–≤–∞ –Ω—è–∫–æ–ª–∫–æ —Å—Ç—ä–ø–∫–∏ –Ω–∞–ø—Ä–µ–¥)
```

**–•–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑–∞ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–∞–Ω–µ:**
- `d_model`: 128, 256, 512 (embedding dimension)
- `n_heads`: 4, 8, 16 (–±—Ä–æ–π attention heads)
- `n_layers`: 4, 6, 8 (–±—Ä–æ–π encoder —Å–ª–æ–µ–≤–µ)
- `d_ff`: 512, 1024, 2048 (feed-forward dimension)
- `dropout`: 0.1, 0.2, 0.3
- `context_length`: 60, 90, 120 (–¥–Ω–∏ –∏—Å—Ç–æ—Ä–∏—è)
- `prediction_horizon`: 1, 5, 10 (–¥–Ω–∏ –Ω–∞–ø—Ä–µ–¥)

### 3.3 Baseline –º–æ–¥–µ–ª–∏

#### 3.3.1 LSTM Baseline (`src/models/lstm_model.py`)
- Vanilla LSTM –∏–ª–∏ Bidirectional LSTM
- –ó–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å Transformer

#### 3.3.2 Linear Baseline
- –ü—Ä–æ—Å—Ç–∞ –ª–∏–Ω–µ–π–Ω–∞ —Ä–µ–≥—Ä–µ—Å–∏—è
- –°–ª—É–∂–∏ –∫–∞—Ç–æ –º–∏–Ω–∏–º–∞–ª–µ–Ω baseline

---

## üéØ –ï—Ç–∞–ø 4: Training Pipeline (3-4 –¥–Ω–∏)

### 4.1 Loss Functions (`src/training/losses.py`)
**–í—ä–∑–º–æ–∂–Ω–∏ loss —Ñ—É–Ω–∫—Ü–∏–∏:**
- Mean Squared Error (MSE)
- Mean Absolute Error (MAE)
- Huber Loss (–∫–æ–º–±–∏–Ω–∞—Ü–∏—è –æ—Ç MSE –∏ MAE)
- Quantile Loss (–∑–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏)

### 4.2 Trainer Class (`src/training/trainer.py`)
**–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–Ω–æ—Å—Ç–∏:**
- Training loop —Å batched data
- Validation loop
- Gradient clipping (–∑–∞ —Å—Ç–∞–±–∏–ª–Ω–æ—Å—Ç)
- Learning rate scheduling
- Logging –Ω–∞ –º–µ—Ç—Ä–∏–∫–∏
- TensorBoard –∏–ª–∏ Weights & Biases integration

**–ú–µ—Ç–æ–¥–∏:**
```python
- train_epoch()
- validate()
- save_checkpoint()
- load_checkpoint()
- train()  # Main training method
```

### 4.3 Callbacks (`src/training/callbacks.py`)
- Early Stopping (—Å–ø–∏—Ä–∞–Ω–µ –ø—Ä–∏ overfitting)
- Model Checkpointing (–∑–∞–ø–∏—Å–≤–∞–Ω–µ –Ω–∞ –Ω–∞–π-–¥–æ–±—ä—Ä –º–æ–¥–µ–ª)
- Learning Rate Scheduler
- Metric Logger

### 4.4 –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (`src/utils/config.py`, `configs/default_config.yaml`)
YAML —Ñ–∞–π–ª —Å –≤—Å–∏—á–∫–∏ —Ö–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∏:
```yaml
data:
  dataset_name: "ykotseruba/stock-prices-daily"
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15
  
model:
  type: "transformer"
  d_model: 256
  n_heads: 8
  n_layers: 6
  dropout: 0.1
  context_length: 90
  prediction_horizon: 1
  
training:
  batch_size: 32
  learning_rate: 0.0001
  num_epochs: 100
  optimizer: "adam"
  scheduler: "cosine"
```

---

## üìà –ï—Ç–∞–ø 5: –û—Ü–µ–Ω–∫–∞ –∏ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (2-3 –¥–Ω–∏)

### 5.1 –ú–µ—Ç—Ä–∏–∫–∏ (`src/evaluation/metrics.py`)
**–†–µ–≥—Ä–µ—Å–∏–æ–Ω–Ω–∏ –º–µ—Ç—Ä–∏–∫–∏:**
- MAE (Mean Absolute Error)
- RMSE (Root Mean Squared Error)
- MAPE (Mean Absolute Percentage Error)
- R¬≤ (Coefficient of Determination)
- Directional Accuracy (% –ø—Ä–∞–≤–∏–ª–Ω–∏ –ø–æ—Å–æ–∫–∏)

### 5.2 –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (`src/evaluation/visualizations.py`)
**–ì—Ä–∞—Ñ–∏–∫–∏:**
- –ü—Ä–æ–≥–Ω–æ–∑–∏ vs –†–µ–∞–ª–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏ (time series plot)
- Residual plots (–∑–∞ –∞–Ω–∞–ª–∏–∑ –Ω–∞ –≥—Ä–µ—à–∫–∏)
- Error distribution
- –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –µ–ø–æ—Ö–∏ (training curves)
- Feature importance (–∞–∫–æ –ø—Ä–∏–ª–æ–∂–∏–º–æ)
- Backtesting —Ä–µ–∑—É–ª—Ç–∞—Ç–∏

### 5.3 –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å Baselines
- –¢–∞–±–ª–∏—Ü–∞ —Å –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –≤—Å–∏—á–∫–∏ –º–æ–¥–µ–ª–∏
- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ —Ç–µ—Å—Ç–æ–≤–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª–Ω–æ)
- –í–∏–∑—É–∞–ª–Ω–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ

---

## üìù –ï—Ç–∞–ø 6: –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –ö–æ–¥–æ–≤–∞ –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è (2-3 –¥–Ω–∏)

### 6.1 README.md
**–°–µ–∫—Ü–∏–∏:**
- –û–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –ø—Ä–æ–µ–∫—Ç–∞
- –ò–Ω—Å—Ç–∞–ª–∞—Ü–∏—è –∏ –∏–∑–∏—Å–∫–≤–∞–Ω–∏—è
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–∞ –ø—Ä–æ–µ–∫—Ç–∞
- –ö–∞–∫ –¥–∞ –∏–∑–ø–æ–ª–∑–≤–∞—à –º–æ–¥–µ–ª–∞
- –ü—Ä–∏–º–µ—Ä–∏ –∑–∞ —É–ø–æ—Ç—Ä–µ–±–∞
- –†–µ–∑—É–ª—Ç–∞—Ç–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏
- –ê–≤—Ç–æ—Ä –∏ –ª–∏—Ü–µ–Ω–∑

### 6.2 Docstrings –∏ Type Hints
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ –≤—Å–∏—á–∫–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –∫–ª–∞—Å–æ–≤–µ
- Type hints –∑–∞ –ø–æ-–¥–æ–±—Ä–∞ —á–∏—Ç–∞–µ–º–æ—Å—Ç
- –ö–æ–º–µ–Ω—Ç–∞—Ä–∏ –∑–∞ —Å–ª–æ–∂–Ω–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∏

### 6.3 Requirements.txt
```txt
torch>=2.0.0
numpy>=1.24.0
pandas>=2.0.0
datasets>=2.14.0
transformers>=4.30.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
plotly>=5.14.0
yfinance>=0.2.0
pyyaml>=6.0
tqdm>=4.65.0
```

### 6.4 Git Repository
- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ git
- .gitignore —Ñ–∞–π–ª
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–∞–Ω–∏ commit messages
- README –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

---

## üöÄ –ï—Ç–∞–ø 7: –§–∏–Ω–∞–ª–µ–Ω –¢–µ—Å—Ç –∏ –ü–æ–ª–∏—Ä–∞–Ω–µ (1-2 –¥–Ω–∏)

### 7.1 –¢–µ—Å—Ç–≤–∞–Ω–µ –Ω–∞ —Ü–µ–ª–∏—è pipeline
- End-to-end —Ç–µ—Å—Ç: –æ—Ç –¥–∞–Ω–Ω–∏ –¥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞ bugs –∏ edge cases
- Performance —Ç–µ—Å—Ç–æ–≤–µ

### 7.2 –ö–æ–¥ —Ä–µ–≤—é
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞ code quality
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (–∞–∫–æ –µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ)
- –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏—Ä–∞–Ω–µ

### 7.3 –§–∏–Ω–∞–ª–µ–Ω –∞–Ω–∞–ª–∏–∑
- –ù–∞–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ
- –ê–Ω–∞–ª–∏–∑ –Ω–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è—Ç–∞
- –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∑–∞ –Ω–∞–¥–≥—Ä–∞–∂–¥–∞–Ω–µ

---

## üìã –†–µ–∑—é–º–µ –Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏—Ç–µ

### Backend –∫–æ–¥ (src/): ~2000-3000 —Ä–µ–¥–∞
- Data pipeline: ~400-500 —Ä–µ–¥–∞
- Model –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∏: ~800-1000 —Ä–µ–¥–∞
- Training pipeline: ~400-500 —Ä–µ–¥–∞
- Evaluation: ~300-400 —Ä–µ–¥–∞
- Utils –∏ helpers: ~200-300 —Ä–µ–¥–∞

### Notebooks: ~5 notebooks –ø–æ 200-300 –∫–ª–µ—Ç–∫–∏ –≤—Å–µ–∫–∏
- –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–∞–Ω–µ –∏ –∞–Ω–∞–ª–∏–∑
- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
- –ü—Ä–∏–º–µ—Ä–Ω–∏ —É–ø–æ—Ç—Ä–µ–±–∏

### –°–∫—Ä–∏–ø—Ç–æ–≤–µ: ~3 —Å–∫—Ä–∏–ø—Ç–∞ –ø–æ 100-200 —Ä–µ–¥–∞
- –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–∞–Ω–µ –Ω–∞ –ø—Ä–æ—Ü–µ—Å–∞
- Command-line –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: ~500-1000 —Ä–µ–¥–∞
- YAML configs
- README
- Docstrings

**–û–ë–©–û: ~4000-5000+ —Ä–µ–¥–∞ –ø—Ä–æ—Ñ–µ—Å–∏–æ–Ω–∞–ª–µ–Ω –∫–æ–¥**

---

## ‚úÖ –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∑–∞ —É—Å–ø–µ—Ö

1. ‚úÖ –ú–æ–¥–µ–ª –æ–±—É—á–µ–Ω –æ—Ç –Ω—É–ª–∞—Ç–∞ (–Ω–µ –ø—Ä–æ—Å—Ç–æ –ø—Ä–µ–¥–∞–≤–∞–Ω–µ –Ω–∞ –≥–æ—Ç–æ–≤)
2. ‚úÖ –ò–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ Hugging Face datasets
3. ‚úÖ –î–æ–±—Ä–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–∞–Ω –∏ –º–æ–¥—É–ª–µ–Ω –∫–æ–¥
4. ‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline –º–æ–¥–µ–ª–∏
5. ‚úÖ –î–µ—Ç–∞–π–ª–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
6. ‚úÖ –†–µ–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏
7. ‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –∞–Ω–∞–ª–∏–∑

---

## üéì –ó–∞ –∫—É—Ä—Å–æ–≤–∞ —Ä–∞–±–æ—Ç–∞

**–ü—Ä–µ–ø–æ—Ä—ä—á–∏—Ç–µ–ª–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç:**

1. **–í—ä–≤–µ–¥–µ–Ω–∏–µ** - –¶–µ–ª, –º–æ—Ç–∏–≤–∞—Ü–∏—è, –æ–±—Ö–≤–∞—Ç
2. **–ü—Ä–æ—É—á–≤–∞–Ω–µ –Ω–∞ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞** - –°–≤—ä—Ä–∑–∞–Ω–∏ —Ä–∞–±–æ—Ç–∏, –º–µ—Ç–æ–¥–∏
3. **Dataset –∏ –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è** - –û–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ, –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
4. **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–∞ –º–æ–¥–µ–ª–∞** - –î–µ—Ç–∞–π–ª–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ Transformer
5. **–ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏** - –•–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∏, training –ø—Ä–æ—Ü–µ—Å
6. **–†–µ–∑—É–ª—Ç–∞—Ç–∏** - –ú–µ—Ç—Ä–∏–∫–∏, —Å—Ä–∞–≤–Ω–µ–Ω–∏—è, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
7. **–ó–∞–∫–ª—é—á–µ–Ω–∏–µ** - –ù–∞—É—á–µ–Ω–∏ –Ω–µ—â–∞, –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è, –±—ä–¥–µ—â–∏ —Ä–∞–±–æ—Ç–∏

---

**–ì–æ—Ç–æ–≤–∏ –ª–∏ —Å—Ç–µ –¥–∞ –∑–∞–ø–æ—á–Ω–µ–º? –° –∫–∞–∫—ä–≤ –µ—Ç–∞–ø –∏—Å–∫–∞—Ç–µ –¥–∞ –ø–æ—á–Ω–µ–º –ø—ä—Ä–≤–æ?**
