{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import os\n",
    "os.chdir(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.data.pipeline import get_datasets\n",
    "from src.models.transformer_model import StockTransformer\n",
    "from src.training.trainer import Trainer\n",
    "from src.utils.config import load_config\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, feature_columns = get_datasets(config)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.training.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.training.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "model = StockTransformer(\n",
    "    input_dim=len(feature_columns),\n",
    "    d_model=config.model.d_model,\n",
    "    n_heads=config.model.n_heads,\n",
    "    n_layers=config.model.n_layers,\n",
    "    d_ff=config.model.d_ff,\n",
    "    dropout=config.model.dropout,\n",
    "    activation=config.model.activation,\n",
    "    prediction_horizon=config.data.prediction_horizon,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    config=config,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.train()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Обучението завърши!\")\n",
    "print(f\"Best validation loss: {history['best_val_loss']:.6f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Use project root for absolute path (same as in 05_backtest_simulation)\n",
    "from src.utils import config as _cfg\n",
    "\n",
    "# IMPORTANT: Save base model as best_model_base.pt to avoid overwriting enhanced model\n",
    "# The enhanced model should stay as best_model.pt or best_model_with_news.pt\n",
    "base_model_path = _cfg.PROJECT_ROOT / config.paths.models_dir / \"best_model_base.pt\"\n",
    "\n",
    "# Also save to default location if it doesn't exist or if user wants to overwrite\n",
    "checkpoint_name = getattr(config.paths, \"checkpoint_file\", \"best_model.pt\")\n",
    "checkpoint_path = _cfg.PROJECT_ROOT / config.paths.models_dir / checkpoint_name\n",
    "\n",
    "# Check if checkpoint_path exists and contains enhanced model\n",
    "backup_existing = False\n",
    "if checkpoint_path.exists():\n",
    "    try:\n",
    "        existing_checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "        existing_state = existing_checkpoint.get('model_state_dict', {})\n",
    "        has_news = any('news' in k for k in existing_state.keys())\n",
    "        existing_type = existing_checkpoint.get('model_type', '')\n",
    "        \n",
    "        if has_news or existing_type == 'StockTransformerWithNews':\n",
    "            print(f\"  Warning: {checkpoint_path} contains enhanced model!\")\n",
    "            print(f\"  Will NOT overwrite it. Base model will be saved only as best_model_base.pt\")\n",
    "            checkpoint_path = None  # Don't overwrite enhanced model\n",
    "        else:\n",
    "            print(f\"  {checkpoint_path} exists but is not enhanced model. Will overwrite.\")\n",
    "    except:\n",
    "        print(f\"  Could not check existing checkpoint. Will save to both locations.\")\n",
    "\n",
    "# Ensure directory exists\n",
    "if checkpoint_path:\n",
    "    checkpoint_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "base_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save base model\n",
    "print(f\"\\nЗапазване на базов модел в: {base_model_path}\")\n",
    "torch.save({\n",
    "    'epoch': len(history['train_losses']) - 1,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'score': history['best_val_loss'],\n",
    "    'model_type': 'StockTransformer',  # Explicitly mark as base model\n",
    "}, base_model_path)\n",
    "\n",
    "# Also save to default location if it's safe\n",
    "if checkpoint_path:\n",
    "    print(f\"\\nЗапазване на модела в: {checkpoint_path}\")\n",
    "    torch.save({\n",
    "        'epoch': len(history['train_losses']) - 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'score': history['best_val_loss'],\n",
    "        'model_type': 'StockTransformer',  # Explicitly mark as base model\n",
    "    }, checkpoint_path)\n",
    "\n",
    "# VERIFICATION: Check that base model file exists and can be loaded\n",
    "if base_model_path.exists():\n",
    "    import time\n",
    "    file_size = base_model_path.stat().st_size / (1024 * 1024)  # MB\n",
    "    mtime = time.ctime(base_model_path.stat().st_mtime)\n",
    "    print(f\" Базовият модел е запазен успешно!\")\n",
    "    print(f\"  Файл: {base_model_path}\")\n",
    "    print(f\"  Размер: {file_size:.2f} MB\")\n",
    "    print(f\"  Модифициран: {mtime}\")\n",
    "    \n",
    "    # Try loading it back to verify\n",
    "    try:\n",
    "        test_checkpoint = torch.load(base_model_path, map_location=\"cpu\", weights_only=False)\n",
    "        if \"model_state_dict\" in test_checkpoint and \"score\" in test_checkpoint:\n",
    "            print(f\" Проверка: Файлът може да се зареди обратно\")\n",
    "            print(f\"  Epoch: {test_checkpoint.get('epoch', '?') + 1}\")\n",
    "            print(f\"  Val loss: {test_checkpoint.get('score', '?'):.6f}\")\n",
    "            print(f\"  Model type: {test_checkpoint.get('model_type', 'unknown')}\")\n",
    "            print(f\"  Параметри: {len(test_checkpoint['model_state_dict'])} keys\")\n",
    "        else:\n",
    "            print(f\" ВНИМАНИЕ: Файлът липсва ключови полета!\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error при зареждане на файла: {e}\")\n",
    "else:\n",
    "    print(f\" Error: Базовият модел не беше създаден!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.evaluation.metrics import calculate_metrics\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.training.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "print(\"Тестване на модела...\")\n",
    "model.eval()\n",
    "\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        predictions = model(batch_x)\n",
    "        \n",
    "        if predictions.dim() == 1:\n",
    "            predictions = predictions.unsqueeze(1)\n",
    "        if batch_y.dim() == 1:\n",
    "            batch_y = batch_y.unsqueeze(1)\n",
    "        \n",
    "        all_predictions.append(predictions)\n",
    "        all_targets.append(batch_y)\n",
    "\n",
    "predictions = torch.cat(all_predictions, dim=0)\n",
    "targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "metrics = calculate_metrics(predictions, targets)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"РЕЗУЛТАТИ НА TEST SET:\")\n",
    "print(\"=\"*60)\n",
    "for metric_name, value in metrics.items():\n",
    "    if metric_name == \"mape\":\n",
    "        print(f\"{metric_name.upper()}: {value:.2f}%\")\n",
    "    elif metric_name == \"directional_accuracy\":\n",
    "        print(f\"{metric_name.upper()}: {value*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"{metric_name.upper()}: {value:.6f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_np = predictions.numpy().flatten()\n",
    "targets_np = targets.numpy().flatten()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(targets_np[:200], label=\"Actual\", alpha=0.7, linewidth=1.5)\n",
    "plt.plot(predictions_np[:200], label=\"Predicted\", alpha=0.7, linewidth=1.5)\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Normalized Price\")\n",
    "plt.title(\"Predictions vs Actual (First 200 samples)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(targets_np, predictions_np, alpha=0.3, s=10)\n",
    "min_val = min(np.min(targets_np), np.min(predictions_np))\n",
    "max_val = max(np.max(targets_np), np.max(predictions_np))\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label=\"Perfect Prediction\")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Scatter Plot\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "residuals = targets_np - predictions_np\n",
    "plt.plot(residuals[:200], alpha=0.7)\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=1)\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.title(\"Residuals (First 200 samples)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(residuals, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Residuals Distribution\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nСтатистики на residuals:\")\n",
    "print(f\"  Mean: {np.mean(residuals):.6f}\")\n",
    "print(f\"  Std: {np.std(residuals):.6f}\")\n",
    "print(f\"  Min: {np.min(residuals):.6f}\")\n",
    "print(f\"  Max: {np.max(residuals):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}