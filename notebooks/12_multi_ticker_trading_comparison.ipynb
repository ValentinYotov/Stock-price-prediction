{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading Simulation: Базов vs Подобрен Модел на 10 Тикера\n",
    "\n",
    "Този notebook сравнява двата модела в реална търговска симулация на 10 различни тикера.\n",
    "\n",
    "## Модели:\n",
    "- **Базов модел**: `StockTransformer` (само технически features)\n",
    "- **Подобрен модел**: `StockTransformerWithNews` (технически features + news embeddings)\n",
    "\n",
    "## Метрики:\n",
    "- Total Return %\n",
    "- Sharpe Ratio\n",
    "- Max Drawdown %\n",
    "- Win Rate\n",
    "- Excess Return vs Buy & Hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import os\n",
    "os.chdir(project_root)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.loader import load_and_filter_dataset\n",
    "from src.data.preprocessor import preprocess_data\n",
    "from src.data.feature_engineering import create_all_features\n",
    "from src.data.dataset import StockDataset, create_sequences, time_series_split\n",
    "from src.data.dataset_with_news import StockDatasetWithNews, _align_news_embeddings_with_sequences\n",
    "from src.data.pipeline import extract_dataset\n",
    "from src.data.news_features import NewsFeatureExtractor\n",
    "from src.models.transformer_model import StockTransformer\n",
    "from src.models.transformer_model_with_news import StockTransformerWithNews\n",
    "from src.simulation.engine import BacktestEngine\n",
    "from src.simulation.metrics import compute_metrics\n",
    "from src.utils.config import load_config\n",
    "from src.utils import config as _cfg\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import yaml\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRADING SIMULATION: BASE vs ENHANCED MODEL\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Training tickers: {config.data.tickers}\")\n",
    "print(f\"Context length: {config.data.context_length}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 10 diverse tickers from different sectors\n",
    "# These should NOT be in training set\n",
    "TRAINING_TICKERS = set(config.data.tickers)\n",
    "\n",
    "TEST_TICKERS = [\n",
    "    \"DIS\",   # Entertainment\n",
    "    \"AMD\",   # Tech (semiconductors)\n",
    "    \"JPM\",   # Financials\n",
    "    \"JNJ\",   # Healthcare\n",
    "    \"WMT\",   # Retail\n",
    "    \"V\",     # Financials (payments)\n",
    "    \"INTC\",  # Tech (semiconductors)\n",
    "    \"CRM\",   # Tech (software)\n",
    "    \"NFLX\",  # Entertainment (streaming)\n",
    "    \"BAC\",   # Financials (banking)\n",
    "]\n",
    "\n",
    "print(f\"Training tickers: {sorted(TRAINING_TICKERS)}\")\n",
    "print(f\"\\nTesting on {len(TEST_TICKERS)} tickers:\")\n",
    "for i, ticker in enumerate(TEST_TICKERS, 1):\n",
    "    print(f\"  {i}. {ticker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load simulation config\n",
    "config_path = _cfg.PROJECT_ROOT / \"configs\" / \"default_config.yaml\"\n",
    "with config_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    raw_cfg = yaml.safe_load(f)\n",
    "sim = raw_cfg.get(\"simulation\", {})\n",
    "\n",
    "initial_capital = float(sim.get(\"initial_capital\", 100_000))\n",
    "position_size_pct = float(sim.get(\"position_size_pct\", 0.3))\n",
    "entry_threshold_pct = float(sim.get(\"entry_threshold_pct\", 0.5))\n",
    "exit_threshold_pct = float(sim.get(\"exit_threshold_pct\", -5.0))\n",
    "commission_pct = float(sim.get(\"commission_pct\", 0.1))\n",
    "risk_free_rate_annual = float(sim.get(\"risk_free_rate_annual\", 0.03))\n",
    "\n",
    "print(f\"Simulation config:\")\n",
    "print(f\"  Initial capital: ${initial_capital:,.0f}\")\n",
    "print(f\"  Position size: {position_size_pct*100:.0f}%\")\n",
    "print(f\"  Entry threshold: {entry_threshold_pct}%\")\n",
    "print(f\"  Exit threshold: {exit_threshold_pct}%\")\n",
    "print(f\"  Commission: {commission_pct}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base model\n",
    "print(\"\\n Loading BASE model...\")\n",
    "base_model_path = _cfg.PROJECT_ROOT / \"models/checkpoints/best_model_base.pt\"\n",
    "\n",
    "if not base_model_path.exists():\n",
    "    print(f\"  Base model not found at {base_model_path}\")\n",
    "    print(\"  Will skip base model simulation\")\n",
    "    base_model = None\n",
    "else:\n",
    "    checkpoint = torch.load(base_model_path, map_location='cpu', weights_only=False)\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "    \n",
    "    # Get model parameters\n",
    "    d_model = state_dict[\"input_projection.weight\"].shape[0]\n",
    "    input_dim = state_dict[\"input_projection.weight\"].shape[1]\n",
    "    \n",
    "    base_model = StockTransformer(\n",
    "        input_dim=input_dim,\n",
    "        d_model=d_model,\n",
    "        n_heads=config.model.n_heads,\n",
    "        n_layers=config.model.n_layers,\n",
    "        d_ff=config.model.d_ff,\n",
    "        dropout=config.model.dropout,\n",
    "        activation=config.model.activation,\n",
    "        prediction_horizon=config.data.prediction_horizon,\n",
    "    )\n",
    "    base_model.load_state_dict(state_dict, strict=False)\n",
    "    base_model.eval()\n",
    "    print(f\" Base model loaded\")\n",
    "    print(f\"  Validation loss: {checkpoint.get('score', 'N/A'):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load enhanced model\n",
    "print(\"\\n Loading ENHANCED model...\")\n",
    "enhanced_model_path = _cfg.PROJECT_ROOT / \"models/checkpoints/best_model_with_news.pt\"\n",
    "\n",
    "if not enhanced_model_path.exists():\n",
    "    print(f\"  Enhanced model not found at {enhanced_model_path}\")\n",
    "    print(\"  Will skip enhanced model simulation\")\n",
    "    enhanced_model = None\n",
    "else:\n",
    "    checkpoint = torch.load(enhanced_model_path, map_location='cpu', weights_only=False)\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "    \n",
    "    # Get model parameters\n",
    "    d_model = state_dict[\"input_projection.weight\"].shape[0]\n",
    "    input_dim = state_dict[\"input_projection.weight\"].shape[1]\n",
    "    \n",
    "    # Check fusion method\n",
    "    if 'output_projection.weight' in state_dict:\n",
    "        output_shape = state_dict['output_projection.weight'].shape\n",
    "        if output_shape[1] > d_model * 1.5:\n",
    "            fusion_method = \"concat\"\n",
    "        else:\n",
    "            fusion_method = \"add\"\n",
    "    else:\n",
    "        fusion_method = \"concat\"\n",
    "    \n",
    "    enhanced_model = StockTransformerWithNews(\n",
    "        input_dim=input_dim,\n",
    "        news_embedding_dim=768,\n",
    "        d_model=d_model,\n",
    "        n_heads=config.model.n_heads,\n",
    "        n_layers=config.model.n_layers,\n",
    "        d_ff=config.model.d_ff,\n",
    "        dropout=config.model.dropout,\n",
    "        activation=config.model.activation,\n",
    "        prediction_horizon=config.data.prediction_horizon,\n",
    "        news_fusion_method=fusion_method,\n",
    "    )\n",
    "    enhanced_model.load_state_dict(state_dict, strict=False)\n",
    "    enhanced_model.eval()\n",
    "    print(f\" Enhanced model loaded\")\n",
    "    print(f\"  Validation loss: {checkpoint.get('score', 'N/A'):.6f}\")\n",
    "    print(f\"  Fusion method: {fusion_method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data to fit scaler (same as model training)\n",
    "print(\"\\n Loading training data for scaler...\")\n",
    "df_train_original, feature_columns = extract_dataset(config=config)\n",
    "train_df_original, _, _ = time_series_split(\n",
    "    df_train_original,\n",
    "    train_split=config.data.train_split,\n",
    "    val_split=config.data.val_split,\n",
    "    test_split=config.data.test_split,\n",
    ")\n",
    "\n",
    "# Fit scaler on original training data\n",
    "all_numeric_cols = feature_columns + [\"close\"]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df_original[all_numeric_cols])\n",
    "print(f\" Scaler fitted on {len(train_df_original)} training samples\")\n",
    "print(f\"  Feature columns: {len(feature_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test both models on each ticker\n",
    "base_results = []\n",
    "enhanced_results = []\n",
    "\n",
    "for ticker in tqdm(TEST_TICKERS, desc=\"Testing tickers\"):\n",
    "    try:\n",
    "        # Load data for this ticker\n",
    "        test_config = deepcopy(config)\n",
    "        test_config.data.tickers = [ticker]\n",
    "        \n",
    "        df_raw = load_and_filter_dataset(\n",
    "            config=test_config,\n",
    "            tickers=[ticker],\n",
    "            start_date=test_config.data.start_date,\n",
    "            end_date=test_config.data.end_date,\n",
    "        )\n",
    "        \n",
    "        if len(df_raw) == 0:\n",
    "            print(f\"  No data for {ticker}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Preprocess\n",
    "        df_processed, _ = preprocess_data(\n",
    "            df_raw,\n",
    "            handle_missing=True,\n",
    "            missing_method=\"forward_fill\",\n",
    "            handle_outliers_flag=True,\n",
    "            outliers_method=\"clip\",\n",
    "            normalize=False,\n",
    "            date_column=\"date\",\n",
    "            symbol_column=\"symbol\",\n",
    "        )\n",
    "        \n",
    "        # Create features\n",
    "        df_features = create_all_features(\n",
    "            df_processed,\n",
    "            price_column=\"close\",\n",
    "            high_column=\"high\",\n",
    "            low_column=\"low\",\n",
    "            volume_column=\"volume\",\n",
    "            date_column=\"date\",\n",
    "            symbol_column=\"symbol\",\n",
    "            windows=test_config.data.features.windows,\n",
    "            lags=[1, 2, 3, 5, 10] if test_config.data.features.lag_features else [],\n",
    "            add_technical=test_config.data.features.technical_indicators,\n",
    "            add_lags=test_config.data.features.lag_features,\n",
    "            add_temporal=test_config.data.features.temporal_features,\n",
    "            add_volume=True,\n",
    "            simplified=test_config.data.features.simplified,\n",
    "        )\n",
    "        \n",
    "        df_features = df_features.dropna()\n",
    "        \n",
    "        if len(df_features) == 0:\n",
    "            print(f\"  No valid data after feature engineering for {ticker}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Apply scaler\n",
    "        df_features[all_numeric_cols] = scaler.transform(df_features[all_numeric_cols])\n",
    "        \n",
    "        # Split into train/val/test\n",
    "        train_df, val_df, test_df = time_series_split(\n",
    "            df_features,\n",
    "            train_split=test_config.data.train_split,\n",
    "            val_split=test_config.data.val_split,\n",
    "            test_split=test_config.data.test_split,\n",
    "        )\n",
    "        \n",
    "        if len(test_df) < config.data.context_length + 10:\n",
    "            print(f\"  Not enough test data for {ticker}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Create dataset\n",
    "        test_data = test_df[feature_columns].values\n",
    "        test_targets = test_df[\"close\"].values.reshape(-1, 1)\n",
    "        \n",
    "        test_X, test_y = create_sequences(\n",
    "            np.column_stack([test_data, test_targets]),\n",
    "            config.data.context_length,\n",
    "            config.data.prediction_horizon,\n",
    "        )\n",
    "        \n",
    "        test_X = test_X[:, :, :-1]\n",
    "        if config.data.prediction_horizon > 1:\n",
    "            test_y = test_y[:, :, -1]\n",
    "        else:\n",
    "            test_y = test_y[:, -1, -1]\n",
    "            if test_y.ndim == 0:\n",
    "                test_y = test_y.reshape(-1, 1)\n",
    "        \n",
    "        test_dataset = StockDataset(test_X, test_y, config.data.context_length, config.data.prediction_horizon)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "        \n",
    "        # Align prices for backtest\n",
    "        test_prices = test_df[\"close\"].values\n",
    "        context_length = config.data.context_length\n",
    "        prices_for_backtest = test_prices[context_length:]\n",
    "        \n",
    "        # Test BASE model\n",
    "        if base_model is not None:\n",
    "            base_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for batch in test_loader:\n",
    "                    features, _ = batch\n",
    "                    preds = base_model(features)\n",
    "                    base_predictions.append(preds.cpu().numpy())\n",
    "            \n",
    "            base_pred_next = np.concatenate(base_predictions).ravel()\n",
    "            min_len = min(len(base_pred_next), len(prices_for_backtest))\n",
    "            base_prices = prices_for_backtest[:min_len]\n",
    "            base_pred = base_pred_next[:min_len]\n",
    "            \n",
    "            # Run backtest\n",
    "            engine = BacktestEngine(\n",
    "                initial_capital=initial_capital,\n",
    "                position_size_pct=position_size_pct,\n",
    "                entry_threshold_pct=entry_threshold_pct,\n",
    "                exit_threshold_pct=exit_threshold_pct,\n",
    "                commission_pct=commission_pct,\n",
    "            )\n",
    "            \n",
    "            result = engine.run(prices=base_prices, predictions=base_pred)\n",
    "            metrics = compute_metrics(\n",
    "                result,\n",
    "                initial_capital=initial_capital,\n",
    "                risk_free_rate_annual=risk_free_rate_annual,\n",
    "                prices=base_prices,\n",
    "            )\n",
    "            \n",
    "            base_results.append({\n",
    "                \"ticker\": ticker,\n",
    "                \"equity_curve\": result.equity_curve,\n",
    "                \"prices\": base_prices,\n",
    "                \"total_return_pct\": metrics.total_return_pct,\n",
    "                \"sharpe_ratio\": metrics.sharpe_ratio_annual,\n",
    "                \"max_drawdown_pct\": metrics.max_drawdown_pct,\n",
    "                \"num_trades\": metrics.num_trades,\n",
    "                \"buy_hold_return_pct\": metrics.buy_and_hold_return_pct,\n",
    "                \"excess_return_pct\": metrics.excess_return_vs_bh_pct,\n",
    "                \"final_equity\": result.equity_curve[-1],\n",
    "            })\n",
    "        \n",
    "        # Test ENHANCED model with news embeddings\n",
    "        if enhanced_model is not None:\n",
    "            # Extract news embeddings for this ticker\n",
    "            tqdm.write(f\"   Extracting news for {ticker}...\")\n",
    "            news_extractor = NewsFeatureExtractor()\n",
    "            news_embeddings_df = news_extractor.get_news_for_dataframe(\n",
    "                test_df,\n",
    "                date_column=\"date\",\n",
    "                symbol_column=\"symbol\",\n",
    "                use_cache=True,\n",
    "            )\n",
    "            \n",
    "            # Align news embeddings with sequences\n",
    "            test_news_embeddings = None\n",
    "            if news_embeddings_df is not None and len(news_embeddings_df) > 0:\n",
    "                test_news_embeddings = _align_news_embeddings_with_sequences(\n",
    "                    test_df,\n",
    "                    test_X,\n",
    "                    news_embeddings_df,\n",
    "                    date_column=\"date\",\n",
    "                    symbol_column=\"symbol\",\n",
    "                    context_length=config.data.context_length,\n",
    "                )\n",
    "                if test_news_embeddings is not None:\n",
    "                    # Check if we have non-zero embeddings\n",
    "                    non_zero_count = np.count_nonzero(np.any(test_news_embeddings != 0, axis=1))\n",
    "                    tqdm.write(f\"     {len(test_news_embeddings)} news embeddings ({non_zero_count} non-zero)\")\n",
    "                else:\n",
    "                    tqdm.write(f\"      Failed to align news embeddings\")\n",
    "            else:\n",
    "                tqdm.write(f\"      No news embeddings found\")\n",
    "            \n",
    "            # Create dataset with news\n",
    "            test_dataset_enhanced = StockDatasetWithNews(\n",
    "                test_X, test_y, test_news_embeddings,\n",
    "                config.data.context_length, config.data.prediction_horizon\n",
    "            )\n",
    "            test_loader_enhanced = DataLoader(test_dataset_enhanced, batch_size=64, shuffle=False)\n",
    "            \n",
    "            enhanced_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for batch in test_loader_enhanced:\n",
    "                    features, news_emb, _ = batch\n",
    "                    # Pass news embeddings to enhanced model\n",
    "                    preds = enhanced_model(features, news_embeddings=news_emb)\n",
    "                    enhanced_predictions.append(preds.cpu().numpy())\n",
    "            \n",
    "            enhanced_pred_next = np.concatenate(enhanced_predictions).ravel()\n",
    "            min_len = min(len(enhanced_pred_next), len(prices_for_backtest))\n",
    "            enhanced_prices = prices_for_backtest[:min_len]\n",
    "            enhanced_pred = enhanced_pred_next[:min_len]\n",
    "            \n",
    "            # Run backtest\n",
    "            engine = BacktestEngine(\n",
    "                initial_capital=initial_capital,\n",
    "                position_size_pct=position_size_pct,\n",
    "                entry_threshold_pct=entry_threshold_pct,\n",
    "                exit_threshold_pct=exit_threshold_pct,\n",
    "                commission_pct=commission_pct,\n",
    "            )\n",
    "            \n",
    "            result = engine.run(prices=enhanced_prices, predictions=enhanced_pred)\n",
    "            metrics = compute_metrics(\n",
    "                result,\n",
    "                initial_capital=initial_capital,\n",
    "                risk_free_rate_annual=risk_free_rate_annual,\n",
    "                prices=enhanced_prices,\n",
    "            )\n",
    "            \n",
    "            enhanced_results.append({\n",
    "                \"ticker\": ticker,\n",
    "                \"equity_curve\": result.equity_curve,\n",
    "                \"prices\": enhanced_prices,\n",
    "                \"total_return_pct\": metrics.total_return_pct,\n",
    "                \"sharpe_ratio\": metrics.sharpe_ratio_annual,\n",
    "                \"max_drawdown_pct\": metrics.max_drawdown_pct,\n",
    "                \"num_trades\": metrics.num_trades,\n",
    "                \"buy_hold_return_pct\": metrics.buy_and_hold_return_pct,\n",
    "                \"excess_return_pct\": metrics.excess_return_vs_bh_pct,\n",
    "                \"final_equity\": result.equity_curve[-1],\n",
    "            })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error processing {ticker}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(f\"\\n Successfully tested:\")\n",
    "print(f\"  Base model: {len(base_results)} tickers\")\n",
    "print(f\"  Enhanced model: {len(enhanced_results)} tickers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRADING RESULTS COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if base_results and enhanced_results:\n",
    "    # Create DataFrames\n",
    "    df_base = pd.DataFrame(base_results)\n",
    "    df_enhanced = pd.DataFrame(enhanced_results)\n",
    "    \n",
    "    # Merge on ticker for comparison\n",
    "    df_comparison = df_base.merge(\n",
    "        df_enhanced,\n",
    "        on='ticker',\n",
    "        suffixes=('_base', '_enhanced')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'Ticker':<8} {'Base Return':<15} {'Enhanced Return':<18} {'Difference':<15} {'Base Sharpe':<15} {'Enhanced Sharpe':<18}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for _, row in df_comparison.iterrows():\n",
    "        diff = row['total_return_pct_enhanced'] - row['total_return_pct_base']\n",
    "        print(f\"{row['ticker']:<8} {row['total_return_pct_base']:>13.2f}% {row['total_return_pct_enhanced']:>16.2f}% {diff:>13.2f}% {row['sharpe_ratio_base']:>13.3f} {row['sharpe_ratio_enhanced']:>16.3f}\")\n",
    "    \n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'AVERAGE':<8} {df_base['total_return_pct'].mean():>13.2f}% {df_enhanced['total_return_pct'].mean():>16.2f}% {(df_enhanced['total_return_pct'].mean() - df_base['total_return_pct'].mean()):>13.2f}% {df_base['sharpe_ratio'].mean():>13.3f} {df_enhanced['sharpe_ratio'].mean():>16.3f}\")\n",
    "    \n",
    "    # Win rates\n",
    "    base_wins = (df_base['total_return_pct'] > 0).sum()\n",
    "    enhanced_wins = (df_enhanced['total_return_pct'] > 0).sum()\n",
    "    print(f\"\\nWin Rate:\")\n",
    "    print(f\"  Base: {base_wins}/{len(df_base)} ({100*base_wins/len(df_base):.1f}%)\")\n",
    "    print(f\"  Enhanced: {enhanced_wins}/{len(df_enhanced)} ({100*enhanced_wins/len(df_enhanced):.1f}%)\")\n",
    "    \n",
    "    # Beat buy & hold\n",
    "    base_beat_bh = (df_base['excess_return_pct'] > 0).sum()\n",
    "    enhanced_beat_bh = (df_enhanced['excess_return_pct'] > 0).sum()\n",
    "    print(f\"\\nBeat Buy & Hold:\")\n",
    "    print(f\"  Base: {base_beat_bh}/{len(df_base)} ({100*base_beat_bh/len(df_base):.1f}%)\")\n",
    "    print(f\"  Enhanced: {enhanced_beat_bh}/{len(df_enhanced)} ({100*enhanced_beat_bh/len(df_enhanced):.1f}%)\")\n",
    "    \n",
    "elif base_results:\n",
    "    df_base = pd.DataFrame(base_results)\n",
    "    print(f\"\\n{'Ticker':<8} {'Return %':<12} {'Sharpe':<10} {'Max DD %':<12} {'Trades':<8}\")\n",
    "    print(\"-\" * 60)\n",
    "    for _, row in df_base.iterrows():\n",
    "        print(f\"{row['ticker']:<8} {row['total_return_pct']:>10.2f}% {row['sharpe_ratio']:>8.3f} {row['max_drawdown_pct']:>10.2f}% {row['num_trades']:>6}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'AVERAGE':<8} {df_base['total_return_pct'].mean():>10.2f}% {df_base['sharpe_ratio'].mean():>8.3f} {df_base['max_drawdown_pct'].mean():>10.2f}% {df_base['num_trades'].mean():>6.0f}\")\n",
    "    \n",
    "elif enhanced_results:\n",
    "    df_enhanced = pd.DataFrame(enhanced_results)\n",
    "    print(f\"\\n{'Ticker':<8} {'Return %':<12} {'Sharpe':<10} {'Max DD %':<12} {'Trades':<8}\")\n",
    "    print(\"-\" * 60)\n",
    "    for _, row in df_enhanced.iterrows():\n",
    "        print(f\"{row['ticker']:<8} {row['total_return_pct']:>10.2f}% {row['sharpe_ratio']:>8.3f} {row['max_drawdown_pct']:>10.2f}% {row['num_trades']:>6}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'AVERAGE':<8} {df_enhanced['total_return_pct'].mean():>10.2f}% {df_enhanced['sharpe_ratio'].mean():>8.3f} {df_enhanced['max_drawdown_pct'].mean():>10.2f}% {df_enhanced['num_trades'].mean():>6.0f}\")\n",
    "else:\n",
    "    print(\"  No results available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "if base_results and enhanced_results:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    \n",
    "    # Plot 1: Equity curves comparison (average)\n",
    "    # Note: Different tickers may have different lengths, so we need to handle that\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    # Normalize and interpolate to common length for averaging\n",
    "    max_len = max([len(r['equity_curve']) for r in base_results + enhanced_results])\n",
    "    \n",
    "    base_normalized = []\n",
    "    for r in base_results:\n",
    "        equity = r['equity_curve'] / r['equity_curve'][0] * initial_capital\n",
    "        # Interpolate to max_len if needed\n",
    "        if len(equity) < max_len:\n",
    "            indices = np.linspace(0, len(equity) - 1, max_len)\n",
    "            equity = np.interp(np.arange(max_len), np.arange(len(equity)), equity)\n",
    "        base_normalized.append(equity)\n",
    "    \n",
    "    enhanced_normalized = []\n",
    "    for r in enhanced_results:\n",
    "        equity = r['equity_curve'] / r['equity_curve'][0] * initial_capital\n",
    "        # Interpolate to max_len if needed\n",
    "        if len(equity) < max_len:\n",
    "            indices = np.linspace(0, len(equity) - 1, max_len)\n",
    "            equity = np.interp(np.arange(max_len), np.arange(len(equity)), equity)\n",
    "        enhanced_normalized.append(equity)\n",
    "    \n",
    "    base_avg_equity = np.mean(base_normalized, axis=0)\n",
    "    enhanced_avg_equity = np.mean(enhanced_normalized, axis=0)\n",
    "    \n",
    "    ax1.plot(base_avg_equity, label='Base Model', linewidth=2, alpha=0.8, color='blue')\n",
    "    ax1.plot(enhanced_avg_equity, label='Enhanced Model', linewidth=2, alpha=0.8, color='green')\n",
    "    ax1.axhline(y=initial_capital, color='black', linestyle='--', linewidth=1, alpha=0.5, label='Initial Capital')\n",
    "    ax1.set_ylabel('Portfolio Value ($)', fontsize=12)\n",
    "    ax1.set_title('Average Equity Curves Comparison', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Returns comparison\n",
    "    ax2 = axes[0, 1]\n",
    "    df_comparison = pd.DataFrame(base_results).merge(\n",
    "        pd.DataFrame(enhanced_results),\n",
    "        on='ticker',\n",
    "        suffixes=('_base', '_enhanced')\n",
    "    )\n",
    "    tickers = df_comparison['ticker'].values\n",
    "    x = np.arange(len(tickers))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax2.bar(x - width/2, df_comparison['total_return_pct_base'], width, \n",
    "                    label='Base Model', color='steelblue', alpha=0.8)\n",
    "    bars2 = ax2.bar(x + width/2, df_comparison['total_return_pct_enhanced'], width, \n",
    "                    label='Enhanced Model', color='green', alpha=0.8)\n",
    "    \n",
    "    ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax2.set_xlabel('Ticker', fontsize=12)\n",
    "    ax2.set_ylabel('Return (%)', fontsize=12)\n",
    "    ax2.set_title('Returns Comparison by Ticker', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(tickers, rotation=45, ha='right')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 3: Sharpe Ratio comparison\n",
    "    ax3 = axes[1, 0]\n",
    "    bars1 = ax3.bar(x - width/2, df_comparison['sharpe_ratio_base'], width, \n",
    "                    label='Base Model', color='steelblue', alpha=0.8)\n",
    "    bars2 = ax3.bar(x + width/2, df_comparison['sharpe_ratio_enhanced'], width, \n",
    "                    label='Enhanced Model', color='green', alpha=0.8)\n",
    "    \n",
    "    ax3.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax3.set_xlabel('Ticker', fontsize=12)\n",
    "    ax3.set_ylabel('Sharpe Ratio', fontsize=12)\n",
    "    ax3.set_title('Sharpe Ratio Comparison', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xticks(x)\n",
    "    ax3.set_xticklabels(tickers, rotation=45, ha='right')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 4: Win rate and metrics summary\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "    SUMMARY STATISTICS\n",
    "    \n",
    "    Base Model:\n",
    "      Avg Return: {df_base['total_return_pct'].mean():.2f}%\n",
    "      Avg Sharpe: {df_base['sharpe_ratio'].mean():.3f}\n",
    "      Avg Max DD: {df_base['max_drawdown_pct'].mean():.2f}%\n",
    "      Win Rate: {(df_base['total_return_pct'] > 0).sum()}/{len(df_base)} ({(df_base['total_return_pct'] > 0).sum()/len(df_base)*100:.1f}%)\n",
    "    \n",
    "    Enhanced Model:\n",
    "      Avg Return: {df_enhanced['total_return_pct'].mean():.2f}%\n",
    "      Avg Sharpe: {df_enhanced['sharpe_ratio'].mean():.3f}\n",
    "      Avg Max DD: {df_enhanced['max_drawdown_pct'].mean():.2f}%\n",
    "      Win Rate: {(df_enhanced['total_return_pct'] > 0).sum()}/{len(df_enhanced)} ({(df_enhanced['total_return_pct'] > 0).sum()/len(df_enhanced)*100:.1f}%)\n",
    "    \n",
    "    Improvement:\n",
    "      Return: {df_enhanced['total_return_pct'].mean() - df_base['total_return_pct'].mean():+.2f}%\n",
    "      Sharpe: {df_enhanced['sharpe_ratio'].mean() - df_base['sharpe_ratio'].mean():+.3f}\n",
    "    \"\"\"\n",
    "    ax4.text(0.1, 0.5, summary_text, fontsize=11, family='monospace', \n",
    "             verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/plots/trading_comparison_10_tickers.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"\\n Comparison plots saved to results/plots/trading_comparison_10_tickers.png\")\n",
    "    plt.show()\n",
    "    \n",
    "elif base_results:\n",
    "    # Only base model available\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    df_base = pd.DataFrame(base_results)\n",
    "    \n",
    "    # Equity curves\n",
    "    ax1 = axes[0]\n",
    "    for result in base_results:\n",
    "        equity = result['equity_curve'] / result['equity_curve'][0] * initial_capital\n",
    "        ax1.plot(equity, label=result['ticker'], alpha=0.7, linewidth=1.5)\n",
    "    ax1.axhline(y=initial_capital, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    ax1.set_ylabel('Portfolio Value ($)')\n",
    "    ax1.set_title('Base Model: Equity Curves')\n",
    "    ax1.legend(ncol=2, fontsize=8)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Returns\n",
    "    ax2 = axes[1]\n",
    "    ax2.bar(df_base['ticker'], df_base['total_return_pct'], color='steelblue', alpha=0.8)\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax2.set_ylabel('Return (%)')\n",
    "    ax2.set_title('Base Model: Returns by Ticker')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "elif enhanced_results:\n",
    "    # Only enhanced model available\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    df_enhanced = pd.DataFrame(enhanced_results)\n",
    "    \n",
    "    # Equity curves\n",
    "    ax1 = axes[0]\n",
    "    for result in enhanced_results:\n",
    "        equity = result['equity_curve'] / result['equity_curve'][0] * initial_capital\n",
    "        ax1.plot(equity, label=result['ticker'], alpha=0.7, linewidth=1.5)\n",
    "    ax1.axhline(y=initial_capital, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    ax1.set_ylabel('Portfolio Value ($)')\n",
    "    ax1.set_title('Enhanced Model: Equity Curves')\n",
    "    ax1.legend(ncol=2, fontsize=8)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Returns\n",
    "    ax2 = axes[1]\n",
    "    ax2.bar(df_enhanced['ticker'], df_enhanced['total_return_pct'], color='green', alpha=0.8)\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax2.set_ylabel('Return (%)')\n",
    "    ax2.set_title('Enhanced Model: Returns by Ticker')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"  No results to visualize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed visualization: All tickers equity curves\n",
    "if base_results and enhanced_results:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(18, 12))\n",
    "    \n",
    "    # Plot 1: Base Model - All tickers\n",
    "    ax1 = axes[0]\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(base_results)))\n",
    "    \n",
    "    for i, result in enumerate(base_results):\n",
    "        ticker = result['ticker']\n",
    "        equity = result['equity_curve'] / result['equity_curve'][0] * initial_capital\n",
    "        return_pct = result['total_return_pct']\n",
    "        \n",
    "        ax1.plot(equity, label=f\"{ticker} ({return_pct:+.1f}%)\", \n",
    "                color=colors[i], linewidth=2, alpha=0.8)\n",
    "    \n",
    "    ax1.axhline(y=initial_capital, color='black', linestyle='--', linewidth=1, alpha=0.5, label='Initial Capital')\n",
    "    ax1.set_ylabel('Portfolio Value ($)', fontsize=12)\n",
    "    ax1.set_title('Base Model: Equity Curves - All Tickers', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(loc='best', ncol=3, fontsize=9)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Enhanced Model - All tickers\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    for i, result in enumerate(enhanced_results):\n",
    "        ticker = result['ticker']\n",
    "        equity = result['equity_curve'] / result['equity_curve'][0] * initial_capital\n",
    "        return_pct = result['total_return_pct']\n",
    "        \n",
    "        ax2.plot(equity, label=f\"{ticker} ({return_pct:+.1f}%)\", \n",
    "                color=colors[i], linewidth=2, alpha=0.8)\n",
    "    \n",
    "    ax2.axhline(y=initial_capital, color='black', linestyle='--', linewidth=1, alpha=0.5, label='Initial Capital')\n",
    "    ax2.set_xlabel('Trading Days', fontsize=12)\n",
    "    ax2.set_ylabel('Portfolio Value ($)', fontsize=12)\n",
    "    ax2.set_title('Enhanced Model: Equity Curves - All Tickers', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(loc='best', ncol=3, fontsize=9)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/plots/trading_all_tickers_detailed.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"\\n Detailed ticker plots saved to results/plots/trading_all_tickers_detailed.png\")\n",
    "    plt.show()\n",
    "    \n",
    "elif base_results:\n",
    "    # Only base model\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(base_results)))\n",
    "    \n",
    "    for i, result in enumerate(base_results):\n",
    "        ticker = result['ticker']\n",
    "        equity = result['equity_curve'] / result['equity_curve'][0] * initial_capital\n",
    "        return_pct = result['total_return_pct']\n",
    "        \n",
    "        ax.plot(equity, label=f\"{ticker} ({return_pct:+.1f}%)\", \n",
    "               color=colors[i], linewidth=2, alpha=0.8)\n",
    "    \n",
    "    ax.axhline(y=initial_capital, color='black', linestyle='--', linewidth=1, alpha=0.5, label='Initial Capital')\n",
    "    ax.set_xlabel('Trading Days', fontsize=12)\n",
    "    ax.set_ylabel('Portfolio Value ($)', fontsize=12)\n",
    "    ax.set_title('Base Model: Equity Curves - All Tickers', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best', ncol=3, fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/plots/trading_all_tickers_base.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"\\n Detailed ticker plots saved to results/plots/trading_all_tickers_base.png\")\n",
    "    plt.show()\n",
    "    \n",
    "elif enhanced_results:\n",
    "    # Only enhanced model\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(enhanced_results)))\n",
    "    \n",
    "    for i, result in enumerate(enhanced_results):\n",
    "        ticker = result['ticker']\n",
    "        equity = result['equity_curve'] / result['equity_curve'][0] * initial_capital\n",
    "        return_pct = result['total_return_pct']\n",
    "        \n",
    "        ax.plot(equity, label=f\"{ticker} ({return_pct:+.1f}%)\", \n",
    "               color=colors[i], linewidth=2, alpha=0.8)\n",
    "    \n",
    "    ax.axhline(y=initial_capital, color='black', linestyle='--', linewidth=1, alpha=0.5, label='Initial Capital')\n",
    "    ax.set_xlabel('Trading Days', fontsize=12)\n",
    "    ax.set_ylabel('Portfolio Value ($)', fontsize=12)\n",
    "    ax.set_title('Enhanced Model: Equity Curves - All Tickers', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best', ncol=3, fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/plots/trading_all_tickers_enhanced.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"\\n Detailed ticker plots saved to results/plots/trading_all_tickers_enhanced.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"  No results to visualize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison: Base vs Enhanced for each ticker\n",
    "if base_results and enhanced_results:\n",
    "    # Match tickers between base and enhanced results\n",
    "    base_dict = {r['ticker']: r for r in base_results}\n",
    "    enhanced_dict = {r['ticker']: r for r in enhanced_results}\n",
    "    common_tickers = sorted(set(base_dict.keys()) & set(enhanced_dict.keys()))\n",
    "    \n",
    "    if common_tickers:\n",
    "        n_tickers = len(common_tickers)\n",
    "        n_cols = 3\n",
    "        n_rows = (n_tickers + n_cols - 1) // n_cols\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5 * n_rows))\n",
    "        if n_rows == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for idx, ticker in enumerate(common_tickers):\n",
    "            ax = axes[idx]\n",
    "            \n",
    "            base_result = base_dict[ticker]\n",
    "            enhanced_result = enhanced_dict[ticker]\n",
    "            \n",
    "            base_equity = base_result['equity_curve'] / base_result['equity_curve'][0] * initial_capital\n",
    "            enhanced_equity = enhanced_result['equity_curve'] / enhanced_result['equity_curve'][0] * initial_capital\n",
    "            \n",
    "            base_return = base_result['total_return_pct']\n",
    "            enhanced_return = enhanced_result['total_return_pct']\n",
    "            \n",
    "            ax.plot(base_equity, label=f\"Base ({base_return:+.1f}%)\", \n",
    "                   color='blue', linewidth=2, alpha=0.8)\n",
    "            ax.plot(enhanced_equity, label=f\"Enhanced ({enhanced_return:+.1f}%)\", \n",
    "                   color='green', linewidth=2, alpha=0.8)\n",
    "            ax.axhline(y=initial_capital, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "            \n",
    "            ax.set_title(f'{ticker}', fontsize=12, fontweight='bold')\n",
    "            ax.set_xlabel('Trading Days', fontsize=10)\n",
    "            ax.set_ylabel('Portfolio Value ($)', fontsize=10)\n",
    "            ax.legend(fontsize=9)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for idx in range(len(common_tickers), len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/plots/trading_comparison_by_ticker.png', dpi=150, bbox_inches='tight')\n",
    "        print(\"\\n Side-by-side comparison saved to results/plots/trading_comparison_by_ticker.png\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"  No common tickers between base and enhanced results\")\n",
    "else:\n",
    "    print(\"  Need both models for side-by-side comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}