{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "project_root = Path().absolute().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "import os\n",
        "os.chdir(project_root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from src.utils.config import load_config\n",
        "from src.data.loader import load_and_filter_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–°–≤–∞–ª—è–Ω–µ –Ω–∞ dataset –æ—Ç Hugging Face...\n",
            "–û–ø–∏—Ç–≤–∞–º —Å–µ –¥–∞ –∑–∞—Ä–µ–¥—è —Å–∞–º–æ price –¥–∞–Ω–Ω–∏—Ç–µ...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19c81e2110a44dffa8d1bc914fbca15d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sp500_daily_ratios_20yrs.zip:   0%|          | 0.00/13.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6daefb3253a4f059bd62468b60e2f8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset –∑–∞—Ä–µ–¥–µ–Ω —É—Å–ø–µ—à–Ω–æ!\n",
            "Splits: ['train']\n",
            "–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞–Ω–æ –≤ pandas. –†–∞–∑–º–µ—Ä: (1048575, 23)\n",
            "–ö–æ–ª–æ–Ω–∏: ['Ticker', 'Date', 'Open', 'Close', 'Volume', 'quarter', 'year', 'Asset Turnover', 'Current Ratio', 'Days Sales In Receivables', 'Debt/Equity Ratio', 'EBIT Margin', 'EBITDA Margin', 'Gross Margin', 'Inventory Turnover Ratio']...\n",
            "\n",
            "Dataset –∑–∞–ø–∞–∑–µ–Ω –ª–æ–∫–∞–ª–Ω–æ –≤: data\\raw\\sp500_stocks_data.parquet\n",
            "–†–∞–∑–º–µ—Ä –Ω–∞ —Ñ–∞–π–ª–∞: 11.41 MB\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "print(\"–°–≤–∞–ª—è–Ω–µ –Ω–∞ dataset –æ—Ç Hugging Face...\")\n",
        "dataset_name = \"pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs\"\n",
        "\n",
        "try:\n",
        "    print(\"–û–ø–∏—Ç–≤–∞–º —Å–µ –¥–∞ –∑–∞—Ä–µ–¥—è —Å–∞–º–æ price –¥–∞–Ω–Ω–∏—Ç–µ...\")\n",
        "    dataset = load_dataset(\n",
        "        dataset_name,\n",
        "        data_files=\"sp500_daily_ratios_20yrs.zip\",\n",
        "        download_mode=\"force_redownload\"\n",
        "    )\n",
        "    print(f\"Dataset –∑–∞—Ä–µ–¥–µ–Ω —É—Å–ø–µ—à–Ω–æ!\")\n",
        "    print(f\"Splits: {list(dataset.keys())}\")\n",
        "    \n",
        "    split_name = list(dataset.keys())[0]\n",
        "    df = dataset[split_name].to_pandas()\n",
        "    \n",
        "    print(f\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞–Ω–æ –≤ pandas. –†–∞–∑–º–µ—Ä: {df.shape}\")\n",
        "    print(f\"–ö–æ–ª–æ–Ω–∏: {list(df.columns)[:15]}...\")\n",
        "    \n",
        "    output_path = Path(\"data/raw/sp500_stocks_data.parquet\")\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    df.to_parquet(output_path, index=False)\n",
        "    print(f\"\\nDataset –∑–∞–ø–∞–∑–µ–Ω –ª–æ–∫–∞–ª–Ω–æ –≤: {output_path}\")\n",
        "    print(f\"–†–∞–∑–º–µ—Ä –Ω–∞ —Ñ–∞–π–ª–∞: {output_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ —Å–≤–∞–ª—è–Ω–µ —Å data_files: {e}\")\n",
        "    print(\"\\n–û–ø–∏—Ç–≤–∞–º —Å–µ –∞–ª—Ç–µ—Ä–Ω–∞—Ç–∏–≤–µ–Ω –º–µ—Ç–æ–¥ - –¥–∏—Ä–µ–∫—Ç–Ω–æ –æ—Ç zip —Ñ–∞–π–ª–∞...\")\n",
        "    try:\n",
        "        from huggingface_hub import hf_hub_download\n",
        "        import zipfile\n",
        "        \n",
        "        zip_path = hf_hub_download(\n",
        "            repo_id=dataset_name,\n",
        "            filename=\"sp500_daily_ratios_20yrs.zip\",\n",
        "            repo_type=\"dataset\"\n",
        "        )\n",
        "        \n",
        "        print(f\"Zip —Ñ–∞–π–ª —Å–≤–∞–ª–µ–Ω–∏ –≤: {zip_path}\")\n",
        "        \n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]\n",
        "            print(f\"–ù–∞–º–µ—Ä–µ–Ω–∏ CSV —Ñ–∞–π–ª–æ–≤–µ: {csv_files[:5]}...\")\n",
        "            \n",
        "            if csv_files:\n",
        "                first_csv = csv_files[0]\n",
        "                with zip_ref.open(first_csv) as f:\n",
        "                    df = pd.read_csv(f)\n",
        "                    print(f\"–ó–∞—Ä–µ–¥–µ–Ω CSV —Ñ–∞–π–ª: {first_csv}\")\n",
        "                    print(f\"–†–∞–∑–º–µ—Ä: {df.shape}\")\n",
        "                    print(f\"–ö–æ–ª–æ–Ω–∏: {list(df.columns)[:15]}...\")\n",
        "                    \n",
        "                    output_path = Path(\"data/raw/sp500_stocks_data.parquet\")\n",
        "                    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "                    df.to_parquet(output_path, index=False)\n",
        "                    print(f\"\\nDataset –∑–∞–ø–∞–∑–µ–Ω –ª–æ–∫–∞–ª–Ω–æ –≤: {output_path}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∞–ª—Ç–µ—Ä–Ω–∞—Ç–∏–≤–µ–Ω –º–µ—Ç–æ–¥: {e2}\")\n",
        "        print(\"\\n–ú–æ–ª—è, –ø—Ä–æ–≤–µ—Ä–∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –≤—Ä—ä–∑–∫–∞—Ç–∞ –∏ –æ–ø–∏—Ç–∞–π –æ—Ç–Ω–æ–≤–æ.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ –°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –ú–æ–¥–µ–ª–∞\n",
        "\n",
        "–¢–æ–∑–∏ cell —Å—Ç–∞—Ä—Ç–∏—Ä–∞ –æ–±—É—á–µ–Ω–∏–µ—Ç–æ –Ω–∞ Transformer –º–æ–¥–µ–ª–∞. –©–µ –≤–∏–∂–¥–∞—à –ø—Ä–æ–≥—Ä–µ—Å–∞ –Ω–∞ –≤—Å–µ–∫–∏ epoch –≤ —Ä–µ–∞–ª–Ω–æ –≤—Ä–µ–º–µ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Dataset: pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'DataFeaturesConfig' object has no attribute 'simplified'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Features: simplified=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimplified\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39md_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124md, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mn_heads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m heads, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mn_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epochs, batch_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'DataFeaturesConfig' object has no attribute 'simplified'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "from src.data.pipeline import get_datasets\n",
        "from src.models.transformer_model import StockTransformer\n",
        "from src.training.trainer import Trainer\n",
        "from src.utils.config import load_config\n",
        "from src.evaluation.visualizations import plot_training_curves\n",
        "\n",
        "# –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n",
        "config = load_config()\n",
        "\n",
        "\n",
        "print(f\" Dataset: {config.data.dataset_name}\")\n",
        "print(f\" Features: simplified={config.data.features.simplified}\")\n",
        "print(f\" Model: {config.model.d_model}d, {config.model.n_heads} heads, {config.model.n_layers} layers\")\n",
        "print(f\"  Training: {config.training.num_epochs} epochs, batch_size={config.training.batch_size}\")\n",
        "\n",
        "print()\n",
        "\n",
        "# –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏\n",
        "print(\"üì• –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏...\")\n",
        "train_dataset, val_dataset, test_dataset, feature_columns = get_datasets(config)\n",
        "\n",
        "print(f\"\\n –î–∞–Ω–Ω–∏ –∑–∞—Ä–µ–¥–µ–Ω–∏ —É—Å–ø–µ—à–Ω–æ!\")\n",
        "print(f\"   ‚Ä¢ Train samples: {len(train_dataset):,}\")\n",
        "print(f\"   ‚Ä¢ Val samples: {len(val_dataset):,}\")\n",
        "print(f\"   ‚Ä¢ Test samples: {len(test_dataset):,}\")\n",
        "print(f\"   ‚Ä¢ Features: {len(feature_columns)}\")\n",
        "print()\n",
        "\n",
        "# –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ DataLoaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config.training.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=False,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config.training.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=False,\n",
        ")\n",
        "\n",
        "# –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –º–æ–¥–µ–ª\n",
        "print(\"üß† –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –º–æ–¥–µ–ª...\")\n",
        "model = StockTransformer(\n",
        "    input_dim=len(feature_columns),\n",
        "    d_model=config.model.d_model,\n",
        "    n_heads=config.model.n_heads,\n",
        "    n_layers=config.model.n_layers,\n",
        "    d_ff=config.model.d_ff,\n",
        "    dropout=config.model.dropout,\n",
        "    activation=config.model.activation,\n",
        "    prediction_horizon=config.data.prediction_horizon,\n",
        ")\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"   ‚Ä¢ Total parameters: {total_params:,}\")\n",
        "print(f\"   ‚Ä¢ Model size: {total_params * 4 / 1024 / 1024:.2f} MB\")\n",
        "print()\n",
        "\n",
        "# –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ trainer\n",
        "print(\"  –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ trainer...\")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    config=config,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        ")\n",
        "print(\" Trainer —Å—ä–∑–¥–∞–¥–µ–Ω!\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ—Ç–æ\n",
        "print(\"üéØ –ó–∞–ø–æ—á–≤–∞–Ω–µ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ...\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    history = trainer.train()\n",
        "    \n",
        "    elapsed_time = time.time() - start_time\n",
        "    hours = int(elapsed_time // 3600)\n",
        "    minutes = int((elapsed_time % 3600) // 60)\n",
        "    seconds = int(elapsed_time % 60)\n",
        "    \n",
        "    print()\n",
        "    print(\"=\" * 60)\n",
        "    print(\"‚úÖ –û–ë–£–ß–ï–ù–ò–ï–¢–û –ó–ê–í–™–†–®–ò –£–°–ü–ï–®–ù–û!\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"‚è±Ô∏è  –û–±—â–æ –≤—Ä–µ–º–µ: {hours}h {minutes}m {seconds}s\")\n",
        "    print(f\"üìà Best validation loss: {history['best_val_loss']:.6f}\")\n",
        "    print(f\"üíæ –ú–æ–¥–µ–ª—ä—Ç –µ –∑–∞–ø–∏—Å–∞–Ω –≤: {config.paths.models_dir}/best_model.pt\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "except KeyboardInterrupt:\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"\\n‚ö†Ô∏è  –û–±—É—á–µ–Ω–∏–µ—Ç–æ –µ –ø—Ä–µ–∫—ä—Å–Ω–∞—Ç–æ –æ—Ç –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è —Å–ª–µ–¥ {elapsed_time/60:.1f} –º–∏–Ω—É—Ç–∏.\")\n",
        "    print(f\"üíæ –ü–æ—Å–ª–µ–¥–Ω–∏—è—Ç checkpoint –µ –∑–∞–ø–∞–∑–µ–Ω –≤: {config.paths.models_dir}/best_model.pt\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå –ì–†–ï–®–ö–ê: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ\n",
        "if 'history' in locals() and len(history['train_losses']) > 0:\n",
        "    print(\"\\nüìä –ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–∏...\")\n",
        "    \n",
        "    results_dir = Path(config.paths.results_dir)\n",
        "    results_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # –ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–∏\n",
        "    plot_training_curves(\n",
        "        history[\"train_losses\"],\n",
        "        history[\"val_losses\"],\n",
        "        save_path=results_dir / \"training_curves.png\",\n",
        "    )\n",
        "    \n",
        "    # –ü–æ–∫–∞–∑–≤–∞–Ω–µ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–∏ –≤ notebook\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['train_losses'], label='Train Loss', linewidth=2)\n",
        "    plt.plot(history['val_losses'], label='Val Loss', linewidth=2)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Progress')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    epochs = range(1, len(history['train_losses']) + 1)\n",
        "    plt.plot(epochs, history['train_losses'], 'o-', label='Train Loss', markersize=4)\n",
        "    plt.plot(epochs, history['val_losses'], 's-', label='Val Loss', markersize=4)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss per Epoch')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # –ü–æ–∫–∞–∑–≤–∞–Ω–µ –Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
        "    print(\"\\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏:\")\n",
        "    print(f\"   ‚Ä¢ –û–±—â–æ epochs: {len(history['train_losses'])}\")\n",
        "    print(f\"   ‚Ä¢ –ù–∞—á–∞–ª–µ–Ω train loss: {history['train_losses'][0]:.6f}\")\n",
        "    print(f\"   ‚Ä¢ –§–∏–Ω–∞–ª–µ–Ω train loss: {history['train_losses'][-1]:.6f}\")\n",
        "    print(f\"   ‚Ä¢ –ù–∞—á–∞–ª–µ–Ω val loss: {history['val_losses'][0]:.6f}\")\n",
        "    print(f\"   ‚Ä¢ –§–∏–Ω–∞–ª–µ–Ω val loss: {history['val_losses'][-1]:.6f}\")\n",
        "    print(f\"   ‚Ä¢ –ü–æ–¥–æ–±—Ä–µ–Ω–∏–µ: {((history['val_losses'][0] - history['val_losses'][-1]) / history['val_losses'][0] * 100):.2f}%\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  –ù—è–º–∞ –¥–∞–Ω–Ω–∏ –∑–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è. –û–±—É—á–µ–Ω–∏–µ—Ç–æ –Ω–µ –µ –∑–∞–≤—ä—Ä—à–∏–ª–æ —É—Å–ø–µ—à–Ω–æ.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs\n",
            "Tickers: ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META']\n",
            "Start date: 2010-01-01\n",
            "End date: None\n"
          ]
        }
      ],
      "source": [
        "config = load_config()\n",
        "print(f\"Dataset: {config.data.dataset_name}\")\n",
        "print(f\"Tickers: {config.data.tickers}\")\n",
        "print(f\"Start date: {config.data.start_date}\")\n",
        "print(f\"End date: {config.data.end_date}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏...\n",
            "–ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ dataset –æ—Ç Hugging Face: pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs\n",
            "–¢–æ–≤–∞ –º–æ–∂–µ –¥–∞ –æ—Ç–Ω–µ–º–µ –Ω—è–∫–æ–ª–∫–æ –º–∏–Ω—É—Ç–∏ –ø—Ä–∏ –ø—ä—Ä–≤–æ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c01b2e456f747ae8c582f88ce32dc16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/290728 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ: An error occurred while generating the dataset\n",
            "\n",
            "All the data files must have the same columns, but at some point there are 23 new columns ({'Return On Tangible Equity', 'Inventory Turnover Ratio', 'ROE - Return On Equity', 'Gross Margin', 'Ticker', 'Receiveable Turnover', 'year', 'Open', 'Asset Turnover', 'Pre-Tax Profit Margin', 'Current Ratio', 'Debt/Equity Ratio', 'quarter', 'Long-term Debt / Capital', 'ROA - Return On Assets', 'Close', 'Volume', 'EBIT Margin', 'Net Profit Margin', 'Date', 'Operating Margin', 'EBITDA Margin', 'Days Sales In Receivables'}) and 9 missing columns ({'time', 'neg', '_id', 'pos', 'ticker', 'neu', 'headline', 'compound', 'date'}).\n",
            "\n",
            "This happened while the csv dataset builder was generating data using\n",
            "\n",
            "zip://sp500_daily_ratios_20yrs.csv::C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip, [C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_daily_ratios_20yrs.zip), C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_news_290k_articles.csv (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_news_290k_articles.csv)]\n",
            "\n",
            "Please either edit the data files to have matching columns, or separate them into different configurations (see docs at https://hf.co/docs/hub/datasets-manual-configuration#multiple-configurations)\n",
            "–û–ø–∏—Ç–≤–∞–º —Å–µ –¥–∞ –∑–∞—Ä–µ–¥—è –±–µ–∑ download_mode...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "616988c05b184670a3c6624ea543c949",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/290728 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ì—Ä–µ—à–∫–∞: An error occurred while generating the dataset\n",
            "\n",
            "All the data files must have the same columns, but at some point there are 23 new columns ({'Return On Tangible Equity', 'Inventory Turnover Ratio', 'ROE - Return On Equity', 'Gross Margin', 'Ticker', 'Receiveable Turnover', 'year', 'Open', 'Asset Turnover', 'Pre-Tax Profit Margin', 'Current Ratio', 'Debt/Equity Ratio', 'quarter', 'Long-term Debt / Capital', 'ROA - Return On Assets', 'Close', 'Volume', 'EBIT Margin', 'Net Profit Margin', 'Date', 'Operating Margin', 'EBITDA Margin', 'Days Sales In Receivables'}) and 9 missing columns ({'time', 'neg', '_id', 'pos', 'ticker', 'neu', 'headline', 'compound', 'date'}).\n",
            "\n",
            "This happened while the csv dataset builder was generating data using\n",
            "\n",
            "zip://sp500_daily_ratios_20yrs.csv::C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip, [C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_daily_ratios_20yrs.zip), C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_news_290k_articles.csv (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_news_290k_articles.csv)]\n",
            "\n",
            "Please either edit the data files to have matching columns, or separate them into different configurations (see docs at https://hf.co/docs/hub/datasets-manual-configuration#multiple-configurations)\n",
            "\n",
            "–ü—Ä–æ–±–ª–µ–º: –ù–µ –º–æ–∂–µ –¥–∞ —Å–µ —Å–≤—ä—Ä–∂–µ —Å Hugging Face Hub.\n",
            "–ú–æ–ª—è, —Å–≤–∞–ª–∏ dataset-–∞ —Ä—ä—á–Ω–æ –≤ notebook-–∞ –∏ –∑–∞–ø–∞–∑–∏ –≥–æ –≤: data\\raw\\sp500_stocks_data.parquet\n"
          ]
        },
        {
          "ename": "DatasetGenerationCastError",
          "evalue": "An error occurred while generating the dataset\n\nAll the data files must have the same columns, but at some point there are 23 new columns ({'Return On Tangible Equity', 'Inventory Turnover Ratio', 'ROE - Return On Equity', 'Gross Margin', 'Ticker', 'Receiveable Turnover', 'year', 'Open', 'Asset Turnover', 'Pre-Tax Profit Margin', 'Current Ratio', 'Debt/Equity Ratio', 'quarter', 'Long-term Debt / Capital', 'ROA - Return On Assets', 'Close', 'Volume', 'EBIT Margin', 'Net Profit Margin', 'Date', 'Operating Margin', 'EBITDA Margin', 'Days Sales In Receivables'}) and 9 missing columns ({'time', 'neg', '_id', 'pos', 'ticker', 'neu', 'headline', 'compound', 'date'}).\n\nThis happened while the csv dataset builder was generating data using\n\nzip://sp500_daily_ratios_20yrs.csv::C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip, [C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_daily_ratios_20yrs.zip), C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_news_290k_articles.csv (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_news_290k_articles.csv)]\n\nPlease either edit the data files to have matching columns, or separate them into different configurations (see docs at https://hf.co/docs/hub/datasets-manual-configuration#multiple-configurations)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mCastError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:1887\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1887\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CastError \u001b[38;5;28;01mas\u001b[39;00m cast_error:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\arrow_writer.py:674\u001b[0m, in \u001b[0;36mArrowWriter.write_table\u001b[1;34m(self, pa_table, writer_batch_size)\u001b[0m\n\u001b[0;32m    673\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mcombine_chunks()\n\u001b[1;32m--> 674\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m \u001b[43mtable_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_local_files:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\table.py:2272\u001b[0m, in \u001b[0;36mtable_cast\u001b[1;34m(table, schema)\u001b[0m\n\u001b[0;32m   2271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m!=\u001b[39m schema:\n\u001b[1;32m-> 2272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcast_table_to_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m table\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m!=\u001b[39m schema\u001b[38;5;241m.\u001b[39mmetadata:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\table.py:2218\u001b[0m, in \u001b[0;36mcast_table_to_schema\u001b[1;34m(table, schema)\u001b[0m\n\u001b[0;32m   2217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m table_column_names \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(schema\u001b[38;5;241m.\u001b[39mnames):\n\u001b[1;32m-> 2218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CastError(\n\u001b[0;32m   2219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt cast\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_short_str(table\u001b[38;5;241m.\u001b[39mschema)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mto\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_short_str(features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mbecause column names don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2220\u001b[0m         table_column_names\u001b[38;5;241m=\u001b[39mtable\u001b[38;5;241m.\u001b[39mcolumn_names,\n\u001b[0;32m   2221\u001b[0m         requested_column_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(features),\n\u001b[0;32m   2222\u001b[0m     )\n\u001b[0;32m   2223\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2224\u001b[0m     cast_array_to_feature(\n\u001b[0;32m   2225\u001b[0m         table[name] \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m table_column_names \u001b[38;5;28;01melse\u001b[39;00m pa\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(table), \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mschema\u001b[38;5;241m.\u001b[39mfield(name)\u001b[38;5;241m.\u001b[39mtype),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2228\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, feature \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   2229\u001b[0m ]\n",
            "\u001b[1;31mCastError\u001b[0m: Couldn't cast\nTicker: string\nDate: string\nOpen: double\nClose: double\nVolume: int64\nquarter: int64\nyear: int64\nAsset Turnover: double\nCurrent Ratio: double\nDays Sales In Receivables: double\nDebt/Equity Ratio: double\nEBIT Margin: double\nEBITDA Margin: int64\nGross Margin: double\nInventory Turnover Ratio: double\nLong-term Debt / Capital: double\nNet Profit Margin: double\nOperating Margin: double\nPre-Tax Profit Margin: double\nROA - Return On Assets: double\nROE - Return On Equity: double\nReceiveable Turnover: double\nReturn On Tangible Equity: double\n-- schema metadata --\npandas: '{\"index_columns\": [{\"kind\": \"range\", \"name\": null, \"start\": 0, \"' + 3250\nto\n{'_id': Value('string'), 'compound': Value('float64'), 'date': Value('string'), 'headline': Value('string'), 'neg': Value('float64'), 'neu': Value('float64'), 'pos': Value('float64'), 'ticker': Value('string'), 'time': Value('string')}\nbecause column names don't match",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mDatasetGenerationCastError\u001b[0m                Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\vyoto\\OneDrive\\Desktop\\CODE STUFF\\Stock price prediction\\src\\data\\loader.py:30\u001b[0m, in \u001b[0;36mload_raw_dataset\u001b[1;34m(config, split)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreuse_cache_if_exists\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\load.py:1508\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[1;32m-> 1508\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:884\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    883\u001b[0m     prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[1;32m--> 884\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:947\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:1736\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split\u001b[1;34m(self, split_generator, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[1;32m-> 1736\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_split_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_prepare_split_args\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:1889\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CastError \u001b[38;5;28;01mas\u001b[39;00m cast_error:\n\u001b[1;32m-> 1889\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetGenerationCastError\u001b[38;5;241m.\u001b[39mfrom_cast_error(\n\u001b[0;32m   1890\u001b[0m         cast_error\u001b[38;5;241m=\u001b[39mcast_error,\n\u001b[0;32m   1891\u001b[0m         builder_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mbuilder_name,\n\u001b[0;32m   1892\u001b[0m         gen_kwargs\u001b[38;5;241m=\u001b[39mgen_kwargs,\n\u001b[0;32m   1893\u001b[0m         token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[0;32m   1894\u001b[0m     )\n\u001b[0;32m   1895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(original_shard_lengths) \u001b[38;5;241m==\u001b[39m original_shard_id:\n",
            "\u001b[1;31mDatasetGenerationCastError\u001b[0m: An error occurred while generating the dataset\n\nAll the data files must have the same columns, but at some point there are 23 new columns ({'Return On Tangible Equity', 'Inventory Turnover Ratio', 'ROE - Return On Equity', 'Gross Margin', 'Ticker', 'Receiveable Turnover', 'year', 'Open', 'Asset Turnover', 'Pre-Tax Profit Margin', 'Current Ratio', 'Debt/Equity Ratio', 'quarter', 'Long-term Debt / Capital', 'ROA - Return On Assets', 'Close', 'Volume', 'EBIT Margin', 'Net Profit Margin', 'Date', 'Operating Margin', 'EBITDA Margin', 'Days Sales In Receivables'}) and 9 missing columns ({'time', 'neg', '_id', 'pos', 'ticker', 'neu', 'headline', 'compound', 'date'}).\n\nThis happened while the csv dataset builder was generating data using\n\nzip://sp500_daily_ratios_20yrs.csv::C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip, [C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_daily_ratios_20yrs.zip), C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_news_290k_articles.csv (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_news_290k_articles.csv)]\n\nPlease either edit the data files to have matching columns, or separate them into different configurations (see docs at https://hf.co/docs/hub/datasets-manual-configuration#multiple-configurations)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mCastError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:1887\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1887\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CastError \u001b[38;5;28;01mas\u001b[39;00m cast_error:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\arrow_writer.py:674\u001b[0m, in \u001b[0;36mArrowWriter.write_table\u001b[1;34m(self, pa_table, writer_batch_size)\u001b[0m\n\u001b[0;32m    673\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mcombine_chunks()\n\u001b[1;32m--> 674\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m \u001b[43mtable_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_local_files:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\table.py:2272\u001b[0m, in \u001b[0;36mtable_cast\u001b[1;34m(table, schema)\u001b[0m\n\u001b[0;32m   2271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m!=\u001b[39m schema:\n\u001b[1;32m-> 2272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcast_table_to_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m table\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m!=\u001b[39m schema\u001b[38;5;241m.\u001b[39mmetadata:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\table.py:2218\u001b[0m, in \u001b[0;36mcast_table_to_schema\u001b[1;34m(table, schema)\u001b[0m\n\u001b[0;32m   2217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m table_column_names \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(schema\u001b[38;5;241m.\u001b[39mnames):\n\u001b[1;32m-> 2218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CastError(\n\u001b[0;32m   2219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt cast\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_short_str(table\u001b[38;5;241m.\u001b[39mschema)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mto\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_short_str(features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mbecause column names don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2220\u001b[0m         table_column_names\u001b[38;5;241m=\u001b[39mtable\u001b[38;5;241m.\u001b[39mcolumn_names,\n\u001b[0;32m   2221\u001b[0m         requested_column_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(features),\n\u001b[0;32m   2222\u001b[0m     )\n\u001b[0;32m   2223\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2224\u001b[0m     cast_array_to_feature(\n\u001b[0;32m   2225\u001b[0m         table[name] \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m table_column_names \u001b[38;5;28;01melse\u001b[39;00m pa\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(table), \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mschema\u001b[38;5;241m.\u001b[39mfield(name)\u001b[38;5;241m.\u001b[39mtype),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2228\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, feature \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   2229\u001b[0m ]\n",
            "\u001b[1;31mCastError\u001b[0m: Couldn't cast\nTicker: string\nDate: string\nOpen: double\nClose: double\nVolume: int64\nquarter: int64\nyear: int64\nAsset Turnover: double\nCurrent Ratio: double\nDays Sales In Receivables: double\nDebt/Equity Ratio: double\nEBIT Margin: double\nEBITDA Margin: int64\nGross Margin: double\nInventory Turnover Ratio: double\nLong-term Debt / Capital: double\nNet Profit Margin: double\nOperating Margin: double\nPre-Tax Profit Margin: double\nROA - Return On Assets: double\nROE - Return On Equity: double\nReceiveable Turnover: double\nReturn On Tangible Equity: double\n-- schema metadata --\npandas: '{\"index_columns\": [{\"kind\": \"range\", \"name\": null, \"start\": 0, \"' + 3250\nto\n{'_id': Value('string'), 'compound': Value('float64'), 'date': Value('string'), 'headline': Value('string'), 'neg': Value('float64'), 'neu': Value('float64'), 'pos': Value('float64'), 'ticker': Value('string'), 'time': Value('string')}\nbecause column names don't match",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mDatasetGenerationCastError\u001b[0m                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m–ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_filter_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m–ó–∞—Ä–µ–¥–µ–Ω–∏ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m —Ä–µ–¥–∞\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\vyoto\\OneDrive\\Desktop\\CODE STUFF\\Stock price prediction\\src\\data\\loader.py:108\u001b[0m, in \u001b[0;36mload_and_filter_dataset\u001b[1;34m(config, tickers, start_date, end_date, split)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end_date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     end_date \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mend_date\n\u001b[1;32m--> 108\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_raw_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m    110\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
            "File \u001b[1;32mc:\\Users\\vyoto\\OneDrive\\Desktop\\CODE STUFF\\Stock price prediction\\src\\data\\loader.py:35\u001b[0m, in \u001b[0;36mload_raw_dataset\u001b[1;34m(config, split)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m–û–ø–∏—Ç–≤–∞–º —Å–µ –¥–∞ –∑–∞—Ä–µ–¥—è –±–µ–∑ download_mode...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e2:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m–ì—Ä–µ—à–∫–∞: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\load.py:1508\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\u001b[38;5;241m.\u001b[39mas_streaming_dataset(split\u001b[38;5;241m=\u001b[39msplit)\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[1;32m-> 1508\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1518\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[0;32m   1519\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:884\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    883\u001b[0m     prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[1;32m--> 884\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:947\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m    943\u001b[0m split_dict\u001b[38;5;241m.\u001b[39madd(split_generator\u001b[38;5;241m.\u001b[39msplit_info)\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find data file. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:1736\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split\u001b[1;34m(self, split_generator, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[0;32m   1734\u001b[0m job_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[1;32m-> 1736\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_split_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_prepare_split_args\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:1889\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[0;32m   1887\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwrite_table(table)\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CastError \u001b[38;5;28;01mas\u001b[39;00m cast_error:\n\u001b[1;32m-> 1889\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetGenerationCastError\u001b[38;5;241m.\u001b[39mfrom_cast_error(\n\u001b[0;32m   1890\u001b[0m         cast_error\u001b[38;5;241m=\u001b[39mcast_error,\n\u001b[0;32m   1891\u001b[0m         builder_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mbuilder_name,\n\u001b[0;32m   1892\u001b[0m         gen_kwargs\u001b[38;5;241m=\u001b[39mgen_kwargs,\n\u001b[0;32m   1893\u001b[0m         token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[0;32m   1894\u001b[0m     )\n\u001b[0;32m   1895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(original_shard_lengths) \u001b[38;5;241m==\u001b[39m original_shard_id:\n\u001b[0;32m   1896\u001b[0m     original_shard_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(table))\n",
            "\u001b[1;31mDatasetGenerationCastError\u001b[0m: An error occurred while generating the dataset\n\nAll the data files must have the same columns, but at some point there are 23 new columns ({'Return On Tangible Equity', 'Inventory Turnover Ratio', 'ROE - Return On Equity', 'Gross Margin', 'Ticker', 'Receiveable Turnover', 'year', 'Open', 'Asset Turnover', 'Pre-Tax Profit Margin', 'Current Ratio', 'Debt/Equity Ratio', 'quarter', 'Long-term Debt / Capital', 'ROA - Return On Assets', 'Close', 'Volume', 'EBIT Margin', 'Net Profit Margin', 'Date', 'Operating Margin', 'EBITDA Margin', 'Days Sales In Receivables'}) and 9 missing columns ({'time', 'neg', '_id', 'pos', 'ticker', 'neu', 'headline', 'compound', 'date'}).\n\nThis happened while the csv dataset builder was generating data using\n\nzip://sp500_daily_ratios_20yrs.csv::C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip, [C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_daily_ratios_20yrs.zip), C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_news_290k_articles.csv (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_news_290k_articles.csv)]\n\nPlease either edit the data files to have matching columns, or separate them into different configurations (see docs at https://hf.co/docs/hub/datasets-manual-configuration#multiple-configurations)"
          ]
        }
      ],
      "source": [
        "print(\"–ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏...\")\n",
        "df = load_and_filter_dataset(config=config)\n",
        "print(f\"–ó–∞—Ä–µ–¥–µ–Ω–∏ {len(df)} —Ä–µ–¥–∞\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"–†–∞–∑–º–µ—Ä–∏: {df.shape}\")\n",
        "print(f\"\\n–ö–æ–ª–æ–Ω–∏:\")\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique_tickers = df['symbol'].unique() if 'symbol' in df.columns else None\n",
        "if unique_tickers is not None:\n",
        "    print(f\"–£–Ω–∏–∫–∞–ª–Ω–∏ —Ç–∏–∫–µ—Ä–∏ ({len(unique_tickers)}):\")\n",
        "    print(sorted(unique_tickers))\n",
        "else:\n",
        "    print(\"–ù–µ –µ –Ω–∞–º–µ—Ä–µ–Ω–∞ –∫–æ–ª–æ–Ω–∞ 'symbol'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "date_col = 'date' if 'date' in df.columns else None\n",
        "if date_col:\n",
        "    df[date_col] = pd.to_datetime(df[date_col])\n",
        "    print(f\"–ü–µ—Ä–∏–æ–¥:\")\n",
        "    print(f\"  –û—Ç: {df[date_col].min()}\")\n",
        "    print(f\"  –î–æ: {df[date_col].max()}\")\n",
        "    print(f\"  –î–Ω–∏: {(df[date_col].max() - df[date_col].min()).days}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"–ü—ä—Ä–≤–∏ 10 —Ä–µ–¥–∞:\")\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"–ë–∞–∑–æ–≤–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing = df.isnull().sum()\n",
        "if missing.sum() > 0:\n",
        "    print(\"–õ–∏–ø—Å–≤–∞—â–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏:\")\n",
        "    print(missing[missing > 0])\n",
        "else:\n",
        "    print(\"–ù—è–º–∞ –ª–∏–ø—Å–≤–∞—â–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block after function definition on line 3 (3043839700.py, line 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    t = np.linspace(0, 1, 1000)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 3\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def plot_adc_conversion():\n",
        "# –ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –∞–Ω–∞–ª–æ–≥–æ–≤ —Å–∏–≥–Ω–∞–ª\n",
        "t = np.linspace(0, 1, 1000)\n",
        "analog_signal = 2.5 + 1.5 * np.sin(2 * np.pi * 5 * t)\n",
        "# ADC –ø–∞—Ä–∞–º–µ—Ç—Ä–∏\n",
        "resolution = 8\n",
        "v_ref = 5.0\n",
        "sampling_rate = 50\n",
        "# –î–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏—è –∏ –∫–≤–∞–Ω—Ç—É–≤–∞–Ω–µ\n",
        "sample_times = np.arange(0, 1, 1/sampling_rate)\n",
        "samples = 2.5 + 1.5 * np.sin(2 * np.pi * 5 * sample_times)\n",
        "digital_samples = np.round((samples / v_ref) * (2**resolution - 1))\n",
        "quantized_voltage = (digital_samples / (2**resolution - 1)) * v_ref\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
        "ax1.plot(t, analog_signal, &#39;b-&#39;, label=&#39;–ê–Ω–∞–ª–æ–≥–æ–≤ —Å–∏–≥–Ω–∞–ª&#39;, alpha=0.7)\n",
        "ax1.stem(sample_times, quantized_voltage, &#39;r-&#39;, markerfmt=&#39;ro&#39;,\n",
        "label=&#39;–î–∏—Å–∫—Ä–µ—Ç–∏–∑–∏—Ä–∞–Ω–∏ –ø—Ä–æ–±–∏&#39;)\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "quantization_error = samples - quantized_voltage\n",
        "ax2.stem(sample_times, quantization_error, &#39;g-&#39;, markerfmt=&#39;go&#39;)\n",
        "ax2.set_title(&#39;–ö–≤–∞–Ω—Ç–æ–≤–∞ –≥—Ä–µ—à–∫–∞&#39;)\n",
        "ax2.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plot_adc_conversion()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid character '¬±' (U+00B1) (3808661557.py, line 14)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 14\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f&quot;–ú–∞–∫—Å–∏–º–∞–ª–Ω–∞ –∫–≤–∞–Ω—Ç–æ–≤–∞ –≥—Ä–µ—à–∫–∞: ¬±{quantization_error:} V&quot;)\u001b[0m\n\u001b[1;37m                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '¬±' (U+00B1)\n"
          ]
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def calculate_adc_parameters(resolution, v_ref, analog_input):\n",
        "    steps = 2 ** resolution\n",
        "    lsb = v_ref / steps\n",
        "    digital_value = int((analog_input / v_ref) * steps)\n",
        "    quantization_error = lsb / 2\n",
        "    print(f&quot;=== –†–µ–∑—É–ª—Ç–∞—Ç–∏ –∑–∞ {resolution}-–±–∏—Ç–æ–≤ –ê–¶–ü ===&quot;)\n",
        "    print(f&quot;–ë—Ä–æ–π —Å—Ç—ä–ø–∫–∏: {steps}&quot;)\n",
        "    print(f&quot;–†–∞–∑–¥–µ–ª–∏—Ç–µ–ª–Ω–∞ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç (LSB): {lsb:} V&quot;)\n",
        "    print(f&quot;–¶–∏—Ñ—Ä–æ–≤–∞ —Å—Ç–æ–π–Ω–æ—Å—Ç –∑–∞ {analog_input}V: {digital_value}&quot;)\n",
        "    print(f&quot;–ú–∞–∫—Å–∏–º–∞–ª–Ω–∞ –∫–≤–∞–Ω—Ç–æ–≤–∞ –≥—Ä–µ—à–∫–∞: ¬±{quantization_error:} V&quot;)\n",
        "     return steps, lsb, digital_value, quantization_error\n",
        "# –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏ –∫–æ–Ω—Ç—Ä–æ–ª–∏\n",
        "resolution_slider = widgets.IntSlider(value=10, min=8, max=16,\n",
        "description=&#39;–ë–∏—Ç–æ–≤–µ:&#39;)\n",
        "vref_slider = widgets.FloatSlider(value=3.3, min=1.8, max=5.0,\n",
        "step=0.1, description=&#39;Vref:&#39;)\n",
        "input_slider = widgets.FloatSlider(value=1.65, min=0, max=3.3,\n",
        "step=0.01, description=&#39;V–≤—Ö–æ–¥:&#39;)\n",
        "def on_parameter_change(change):\n",
        "     calculate_adc_parameters(\n",
        "        resolution_slider.value,\n",
        "        vref_slider.value,\n",
        "        input_slider.value\n",
        "    )\n",
        "resolution_slider.observe(on_parameter_change, names=&#39;value&#39;)\n",
        "vref_slider.observe(on_parameter_change, names=&#39;value&#39;)\n",
        "input_slider.observe(on_parameter_change, names=&#39;value&#39;)\n",
        "display(resolution_slider, vref_slider, input_slider)\n",
        "calculate_adc_parameters(10, 3.3, 1.65)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
