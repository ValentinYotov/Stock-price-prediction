{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "project_root = Path().absolute().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "import os\n",
        "os.chdir(project_root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from src.utils.config import load_config\n",
        "from src.data.loader import load_and_filter_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Сваляне на dataset от Hugging Face...\n",
            "Опитвам се да заредя само price данните...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19c81e2110a44dffa8d1bc914fbca15d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sp500_daily_ratios_20yrs.zip:   0%|          | 0.00/13.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6daefb3253a4f059bd62468b60e2f8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset зареден успешно!\n",
            "Splits: ['train']\n",
            "Конвертирано в pandas. Размер: (1048575, 23)\n",
            "Колони: ['Ticker', 'Date', 'Open', 'Close', 'Volume', 'quarter', 'year', 'Asset Turnover', 'Current Ratio', 'Days Sales In Receivables', 'Debt/Equity Ratio', 'EBIT Margin', 'EBITDA Margin', 'Gross Margin', 'Inventory Turnover Ratio']...\n",
            "\n",
            "Dataset запазен локално в: data\\raw\\sp500_stocks_data.parquet\n",
            "Размер на файла: 11.41 MB\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "print(\"Сваляне на dataset от Hugging Face...\")\n",
        "dataset_name = \"pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs\"\n",
        "\n",
        "try:\n",
        "    print(\"Опитвам се да заредя само price данните...\")\n",
        "    dataset = load_dataset(\n",
        "        dataset_name,\n",
        "        data_files=\"sp500_daily_ratios_20yrs.zip\",\n",
        "        download_mode=\"force_redownload\"\n",
        "    )\n",
        "    print(f\"Dataset зареден успешно!\")\n",
        "    print(f\"Splits: {list(dataset.keys())}\")\n",
        "    \n",
        "    split_name = list(dataset.keys())[0]\n",
        "    df = dataset[split_name].to_pandas()\n",
        "    \n",
        "    print(f\"Конвертирано в pandas. Размер: {df.shape}\")\n",
        "    print(f\"Колони: {list(df.columns)[:15]}...\")\n",
        "    \n",
        "    output_path = Path(\"data/raw/sp500_stocks_data.parquet\")\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    df.to_parquet(output_path, index=False)\n",
        "    print(f\"\\nDataset запазен локално в: {output_path}\")\n",
        "    print(f\"Размер на файла: {output_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Грешка при сваляне с data_files: {e}\")\n",
        "    print(\"\\nОпитвам се алтернативен метод - директно от zip файла...\")\n",
        "    try:\n",
        "        from huggingface_hub import hf_hub_download\n",
        "        import zipfile\n",
        "        \n",
        "        zip_path = hf_hub_download(\n",
        "            repo_id=dataset_name,\n",
        "            filename=\"sp500_daily_ratios_20yrs.zip\",\n",
        "            repo_type=\"dataset\"\n",
        "        )\n",
        "        \n",
        "        print(f\"Zip файл свалени в: {zip_path}\")\n",
        "        \n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]\n",
        "            print(f\"Намерени CSV файлове: {csv_files[:5]}...\")\n",
        "            \n",
        "            if csv_files:\n",
        "                first_csv = csv_files[0]\n",
        "                with zip_ref.open(first_csv) as f:\n",
        "                    df = pd.read_csv(f)\n",
        "                    print(f\"Зареден CSV файл: {first_csv}\")\n",
        "                    print(f\"Размер: {df.shape}\")\n",
        "                    print(f\"Колони: {list(df.columns)[:15]}...\")\n",
        "                    \n",
        "                    output_path = Path(\"data/raw/sp500_stocks_data.parquet\")\n",
        "                    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "                    df.to_parquet(output_path, index=False)\n",
        "                    print(f\"\\nDataset запазен локално в: {output_path}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"Грешка при алтернативен метод: {e2}\")\n",
        "        print(\"\\nМоля, провери интернет връзката и опитай отново.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs\n",
            "Tickers: ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META']\n",
            "Start date: 2010-01-01\n",
            "End date: None\n"
          ]
        }
      ],
      "source": [
        "config = load_config()\n",
        "print(f\"Dataset: {config.data.dataset_name}\")\n",
        "print(f\"Tickers: {config.data.tickers}\")\n",
        "print(f\"Start date: {config.data.start_date}\")\n",
        "print(f\"End date: {config.data.end_date}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Зареждане на данни...\n",
            "Зареждане на dataset от Hugging Face: pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs\n",
            "Това може да отнеме няколко минути при първо зареждане...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c01b2e456f747ae8c582f88ce32dc16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/290728 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Грешка при зареждане: An error occurred while generating the dataset\n",
            "\n",
            "All the data files must have the same columns, but at some point there are 23 new columns ({'Return On Tangible Equity', 'Inventory Turnover Ratio', 'ROE - Return On Equity', 'Gross Margin', 'Ticker', 'Receiveable Turnover', 'year', 'Open', 'Asset Turnover', 'Pre-Tax Profit Margin', 'Current Ratio', 'Debt/Equity Ratio', 'quarter', 'Long-term Debt / Capital', 'ROA - Return On Assets', 'Close', 'Volume', 'EBIT Margin', 'Net Profit Margin', 'Date', 'Operating Margin', 'EBITDA Margin', 'Days Sales In Receivables'}) and 9 missing columns ({'time', 'neg', '_id', 'pos', 'ticker', 'neu', 'headline', 'compound', 'date'}).\n",
            "\n",
            "This happened while the csv dataset builder was generating data using\n",
            "\n",
            "zip://sp500_daily_ratios_20yrs.csv::C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip, [C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_daily_ratios_20yrs.zip), C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_news_290k_articles.csv (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_news_290k_articles.csv)]\n",
            "\n",
            "Please either edit the data files to have matching columns, or separate them into different configurations (see docs at https://hf.co/docs/hub/datasets-manual-configuration#multiple-configurations)\n",
            "Опитвам се да заредя без download_mode...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "616988c05b184670a3c6624ea543c949",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/290728 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Грешка: An error occurred while generating the dataset\n",
            "\n",
            "All the data files must have the same columns, but at some point there are 23 new columns ({'Return On Tangible Equity', 'Inventory Turnover Ratio', 'ROE - Return On Equity', 'Gross Margin', 'Ticker', 'Receiveable Turnover', 'year', 'Open', 'Asset Turnover', 'Pre-Tax Profit Margin', 'Current Ratio', 'Debt/Equity Ratio', 'quarter', 'Long-term Debt / Capital', 'ROA - Return On Assets', 'Close', 'Volume', 'EBIT Margin', 'Net Profit Margin', 'Date', 'Operating Margin', 'EBITDA Margin', 'Days Sales In Receivables'}) and 9 missing columns ({'time', 'neg', '_id', 'pos', 'ticker', 'neu', 'headline', 'compound', 'date'}).\n",
            "\n",
            "This happened while the csv dataset builder was generating data using\n",
            "\n",
            "zip://sp500_daily_ratios_20yrs.csv::C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip, [C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_daily_ratios_20yrs.zip), C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_news_290k_articles.csv (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_news_290k_articles.csv)]\n",
            "\n",
            "Please either edit the data files to have matching columns, or separate them into different configurations (see docs at https://hf.co/docs/hub/datasets-manual-configuration#multiple-configurations)\n",
            "\n",
            "Проблем: Не може да се свърже с Hugging Face Hub.\n",
            "Моля, свали dataset-а ръчно в notebook-а и запази го в: data\\raw\\sp500_stocks_data.parquet\n"
          ]
        },
        {
          "ename": "DatasetGenerationCastError",
          "evalue": "An error occurred while generating the dataset\n\nAll the data files must have the same columns, but at some point there are 23 new columns ({'Return On Tangible Equity', 'Inventory Turnover Ratio', 'ROE - Return On Equity', 'Gross Margin', 'Ticker', 'Receiveable Turnover', 'year', 'Open', 'Asset Turnover', 'Pre-Tax Profit Margin', 'Current Ratio', 'Debt/Equity Ratio', 'quarter', 'Long-term Debt / Capital', 'ROA - Return On Assets', 'Close', 'Volume', 'EBIT Margin', 'Net Profit Margin', 'Date', 'Operating Margin', 'EBITDA Margin', 'Days Sales In Receivables'}) and 9 missing columns ({'time', 'neg', '_id', 'pos', 'ticker', 'neu', 'headline', 'compound', 'date'}).\n\nThis happened while the csv dataset builder was generating data using\n\nzip://sp500_daily_ratios_20yrs.csv::C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip, [C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_daily_ratios_20yrs.zip), C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_news_290k_articles.csv (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_news_290k_articles.csv)]\n\nPlease either edit the data files to have matching columns, or separate them into different configurations (see docs at https://hf.co/docs/hub/datasets-manual-configuration#multiple-configurations)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mCastError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:1887\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1887\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CastError \u001b[38;5;28;01mas\u001b[39;00m cast_error:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\arrow_writer.py:674\u001b[0m, in \u001b[0;36mArrowWriter.write_table\u001b[1;34m(self, pa_table, writer_batch_size)\u001b[0m\n\u001b[0;32m    673\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mcombine_chunks()\n\u001b[1;32m--> 674\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m \u001b[43mtable_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_local_files:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\table.py:2272\u001b[0m, in \u001b[0;36mtable_cast\u001b[1;34m(table, schema)\u001b[0m\n\u001b[0;32m   2271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m!=\u001b[39m schema:\n\u001b[1;32m-> 2272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcast_table_to_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m table\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m!=\u001b[39m schema\u001b[38;5;241m.\u001b[39mmetadata:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\table.py:2218\u001b[0m, in \u001b[0;36mcast_table_to_schema\u001b[1;34m(table, schema)\u001b[0m\n\u001b[0;32m   2217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m table_column_names \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(schema\u001b[38;5;241m.\u001b[39mnames):\n\u001b[1;32m-> 2218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CastError(\n\u001b[0;32m   2219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt cast\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_short_str(table\u001b[38;5;241m.\u001b[39mschema)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mto\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_short_str(features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mbecause column names don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2220\u001b[0m         table_column_names\u001b[38;5;241m=\u001b[39mtable\u001b[38;5;241m.\u001b[39mcolumn_names,\n\u001b[0;32m   2221\u001b[0m         requested_column_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(features),\n\u001b[0;32m   2222\u001b[0m     )\n\u001b[0;32m   2223\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2224\u001b[0m     cast_array_to_feature(\n\u001b[0;32m   2225\u001b[0m         table[name] \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m table_column_names \u001b[38;5;28;01melse\u001b[39;00m pa\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(table), \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mschema\u001b[38;5;241m.\u001b[39mfield(name)\u001b[38;5;241m.\u001b[39mtype),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2228\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, feature \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   2229\u001b[0m ]\n",
            "\u001b[1;31mCastError\u001b[0m: Couldn't cast\nTicker: string\nDate: string\nOpen: double\nClose: double\nVolume: int64\nquarter: int64\nyear: int64\nAsset Turnover: double\nCurrent Ratio: double\nDays Sales In Receivables: double\nDebt/Equity Ratio: double\nEBIT Margin: double\nEBITDA Margin: int64\nGross Margin: double\nInventory Turnover Ratio: double\nLong-term Debt / Capital: double\nNet Profit Margin: double\nOperating Margin: double\nPre-Tax Profit Margin: double\nROA - Return On Assets: double\nROE - Return On Equity: double\nReceiveable Turnover: double\nReturn On Tangible Equity: double\n-- schema metadata --\npandas: '{\"index_columns\": [{\"kind\": \"range\", \"name\": null, \"start\": 0, \"' + 3250\nto\n{'_id': Value('string'), 'compound': Value('float64'), 'date': Value('string'), 'headline': Value('string'), 'neg': Value('float64'), 'neu': Value('float64'), 'pos': Value('float64'), 'ticker': Value('string'), 'time': Value('string')}\nbecause column names don't match",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mDatasetGenerationCastError\u001b[0m                Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\vyoto\\OneDrive\\Desktop\\CODE STUFF\\Stock price prediction\\src\\data\\loader.py:30\u001b[0m, in \u001b[0;36mload_raw_dataset\u001b[1;34m(config, split)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreuse_cache_if_exists\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\load.py:1508\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[1;32m-> 1508\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:884\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    883\u001b[0m     prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[1;32m--> 884\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:947\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:1736\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split\u001b[1;34m(self, split_generator, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[1;32m-> 1736\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_split_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_prepare_split_args\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:1889\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CastError \u001b[38;5;28;01mas\u001b[39;00m cast_error:\n\u001b[1;32m-> 1889\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetGenerationCastError\u001b[38;5;241m.\u001b[39mfrom_cast_error(\n\u001b[0;32m   1890\u001b[0m         cast_error\u001b[38;5;241m=\u001b[39mcast_error,\n\u001b[0;32m   1891\u001b[0m         builder_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mbuilder_name,\n\u001b[0;32m   1892\u001b[0m         gen_kwargs\u001b[38;5;241m=\u001b[39mgen_kwargs,\n\u001b[0;32m   1893\u001b[0m         token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[0;32m   1894\u001b[0m     )\n\u001b[0;32m   1895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(original_shard_lengths) \u001b[38;5;241m==\u001b[39m original_shard_id:\n",
            "\u001b[1;31mDatasetGenerationCastError\u001b[0m: An error occurred while generating the dataset\n\nAll the data files must have the same columns, but at some point there are 23 new columns ({'Return On Tangible Equity', 'Inventory Turnover Ratio', 'ROE - Return On Equity', 'Gross Margin', 'Ticker', 'Receiveable Turnover', 'year', 'Open', 'Asset Turnover', 'Pre-Tax Profit Margin', 'Current Ratio', 'Debt/Equity Ratio', 'quarter', 'Long-term Debt / Capital', 'ROA - Return On Assets', 'Close', 'Volume', 'EBIT Margin', 'Net Profit Margin', 'Date', 'Operating Margin', 'EBITDA Margin', 'Days Sales In Receivables'}) and 9 missing columns ({'time', 'neg', '_id', 'pos', 'ticker', 'neu', 'headline', 'compound', 'date'}).\n\nThis happened while the csv dataset builder was generating data using\n\nzip://sp500_daily_ratios_20yrs.csv::C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip, [C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_daily_ratios_20yrs.zip), C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_news_290k_articles.csv (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_news_290k_articles.csv)]\n\nPlease either edit the data files to have matching columns, or separate them into different configurations (see docs at https://hf.co/docs/hub/datasets-manual-configuration#multiple-configurations)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mCastError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:1887\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1887\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CastError \u001b[38;5;28;01mas\u001b[39;00m cast_error:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\arrow_writer.py:674\u001b[0m, in \u001b[0;36mArrowWriter.write_table\u001b[1;34m(self, pa_table, writer_batch_size)\u001b[0m\n\u001b[0;32m    673\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mcombine_chunks()\n\u001b[1;32m--> 674\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m \u001b[43mtable_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_local_files:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\table.py:2272\u001b[0m, in \u001b[0;36mtable_cast\u001b[1;34m(table, schema)\u001b[0m\n\u001b[0;32m   2271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m!=\u001b[39m schema:\n\u001b[1;32m-> 2272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcast_table_to_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m table\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m!=\u001b[39m schema\u001b[38;5;241m.\u001b[39mmetadata:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\table.py:2218\u001b[0m, in \u001b[0;36mcast_table_to_schema\u001b[1;34m(table, schema)\u001b[0m\n\u001b[0;32m   2217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m table_column_names \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(schema\u001b[38;5;241m.\u001b[39mnames):\n\u001b[1;32m-> 2218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CastError(\n\u001b[0;32m   2219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt cast\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_short_str(table\u001b[38;5;241m.\u001b[39mschema)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mto\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_short_str(features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mbecause column names don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2220\u001b[0m         table_column_names\u001b[38;5;241m=\u001b[39mtable\u001b[38;5;241m.\u001b[39mcolumn_names,\n\u001b[0;32m   2221\u001b[0m         requested_column_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(features),\n\u001b[0;32m   2222\u001b[0m     )\n\u001b[0;32m   2223\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2224\u001b[0m     cast_array_to_feature(\n\u001b[0;32m   2225\u001b[0m         table[name] \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m table_column_names \u001b[38;5;28;01melse\u001b[39;00m pa\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(table), \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mschema\u001b[38;5;241m.\u001b[39mfield(name)\u001b[38;5;241m.\u001b[39mtype),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2228\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, feature \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   2229\u001b[0m ]\n",
            "\u001b[1;31mCastError\u001b[0m: Couldn't cast\nTicker: string\nDate: string\nOpen: double\nClose: double\nVolume: int64\nquarter: int64\nyear: int64\nAsset Turnover: double\nCurrent Ratio: double\nDays Sales In Receivables: double\nDebt/Equity Ratio: double\nEBIT Margin: double\nEBITDA Margin: int64\nGross Margin: double\nInventory Turnover Ratio: double\nLong-term Debt / Capital: double\nNet Profit Margin: double\nOperating Margin: double\nPre-Tax Profit Margin: double\nROA - Return On Assets: double\nROE - Return On Equity: double\nReceiveable Turnover: double\nReturn On Tangible Equity: double\n-- schema metadata --\npandas: '{\"index_columns\": [{\"kind\": \"range\", \"name\": null, \"start\": 0, \"' + 3250\nto\n{'_id': Value('string'), 'compound': Value('float64'), 'date': Value('string'), 'headline': Value('string'), 'neg': Value('float64'), 'neu': Value('float64'), 'pos': Value('float64'), 'ticker': Value('string'), 'time': Value('string')}\nbecause column names don't match",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mDatasetGenerationCastError\u001b[0m                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЗареждане на данни...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_filter_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЗаредени \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m реда\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\vyoto\\OneDrive\\Desktop\\CODE STUFF\\Stock price prediction\\src\\data\\loader.py:108\u001b[0m, in \u001b[0;36mload_and_filter_dataset\u001b[1;34m(config, tickers, start_date, end_date, split)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end_date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     end_date \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mend_date\n\u001b[1;32m--> 108\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_raw_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m    110\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
            "File \u001b[1;32mc:\\Users\\vyoto\\OneDrive\\Desktop\\CODE STUFF\\Stock price prediction\\src\\data\\loader.py:35\u001b[0m, in \u001b[0;36mload_raw_dataset\u001b[1;34m(config, split)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mОпитвам се да заредя без download_mode...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e2:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mГрешка: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\load.py:1508\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\u001b[38;5;241m.\u001b[39mas_streaming_dataset(split\u001b[38;5;241m=\u001b[39msplit)\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[1;32m-> 1508\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1518\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[0;32m   1519\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:884\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    883\u001b[0m     prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[1;32m--> 884\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:947\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m    943\u001b[0m split_dict\u001b[38;5;241m.\u001b[39madd(split_generator\u001b[38;5;241m.\u001b[39msplit_info)\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find data file. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:1736\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split\u001b[1;34m(self, split_generator, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[0;32m   1734\u001b[0m job_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[1;32m-> 1736\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_split_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_prepare_split_args\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\builder.py:1889\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[0m\n\u001b[0;32m   1887\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwrite_table(table)\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CastError \u001b[38;5;28;01mas\u001b[39;00m cast_error:\n\u001b[1;32m-> 1889\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetGenerationCastError\u001b[38;5;241m.\u001b[39mfrom_cast_error(\n\u001b[0;32m   1890\u001b[0m         cast_error\u001b[38;5;241m=\u001b[39mcast_error,\n\u001b[0;32m   1891\u001b[0m         builder_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mbuilder_name,\n\u001b[0;32m   1892\u001b[0m         gen_kwargs\u001b[38;5;241m=\u001b[39mgen_kwargs,\n\u001b[0;32m   1893\u001b[0m         token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[0;32m   1894\u001b[0m     )\n\u001b[0;32m   1895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(original_shard_lengths) \u001b[38;5;241m==\u001b[39m original_shard_id:\n\u001b[0;32m   1896\u001b[0m     original_shard_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(table))\n",
            "\u001b[1;31mDatasetGenerationCastError\u001b[0m: An error occurred while generating the dataset\n\nAll the data files must have the same columns, but at some point there are 23 new columns ({'Return On Tangible Equity', 'Inventory Turnover Ratio', 'ROE - Return On Equity', 'Gross Margin', 'Ticker', 'Receiveable Turnover', 'year', 'Open', 'Asset Turnover', 'Pre-Tax Profit Margin', 'Current Ratio', 'Debt/Equity Ratio', 'quarter', 'Long-term Debt / Capital', 'ROA - Return On Assets', 'Close', 'Volume', 'EBIT Margin', 'Net Profit Margin', 'Date', 'Operating Margin', 'EBITDA Margin', 'Days Sales In Receivables'}) and 9 missing columns ({'time', 'neg', '_id', 'pos', 'ticker', 'neu', 'headline', 'compound', 'date'}).\n\nThis happened while the csv dataset builder was generating data using\n\nzip://sp500_daily_ratios_20yrs.csv::C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip, [C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_daily_ratios_20yrs.zip (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_daily_ratios_20yrs.zip), C:\\Users\\vyoto\\.cache\\huggingface\\hub\\datasets--pmoe7--SP_500_Stocks_Data-ratios_news_price_10_yrs\\snapshots\\8ae97891ad22af1be38cad1a8a88997bfc8862bd\\sp500_news_290k_articles.csv (origin=hf://datasets/pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs@8ae97891ad22af1be38cad1a8a88997bfc8862bd/sp500_news_290k_articles.csv)]\n\nPlease either edit the data files to have matching columns, or separate them into different configurations (see docs at https://hf.co/docs/hub/datasets-manual-configuration#multiple-configurations)"
          ]
        }
      ],
      "source": [
        "print(\"Зареждане на данни...\")\n",
        "df = load_and_filter_dataset(config=config)\n",
        "print(f\"Заредени {len(df)} реда\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Размери: {df.shape}\")\n",
        "print(f\"\\nКолони:\")\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique_tickers = df['symbol'].unique() if 'symbol' in df.columns else None\n",
        "if unique_tickers is not None:\n",
        "    print(f\"Уникални тикери ({len(unique_tickers)}):\")\n",
        "    print(sorted(unique_tickers))\n",
        "else:\n",
        "    print(\"Не е намерена колона 'symbol'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "date_col = 'date' if 'date' in df.columns else None\n",
        "if date_col:\n",
        "    df[date_col] = pd.to_datetime(df[date_col])\n",
        "    print(f\"Период:\")\n",
        "    print(f\"  От: {df[date_col].min()}\")\n",
        "    print(f\"  До: {df[date_col].max()}\")\n",
        "    print(f\"  Дни: {(df[date_col].max() - df[date_col].min()).days}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Първи 10 реда:\")\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Базова статистика:\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing = df.isnull().sum()\n",
        "if missing.sum() > 0:\n",
        "    print(\"Липсващи стойности:\")\n",
        "    print(missing[missing > 0])\n",
        "else:\n",
        "    print(\"Няма липсващи стойности\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block after function definition on line 3 (3043839700.py, line 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    t = np.linspace(0, 1, 1000)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 3\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def plot_adc_conversion():\n",
        "# Генериране на аналогов сигнал\n",
        "t = np.linspace(0, 1, 1000)\n",
        "analog_signal = 2.5 + 1.5 * np.sin(2 * np.pi * 5 * t)\n",
        "# ADC параметри\n",
        "resolution = 8\n",
        "v_ref = 5.0\n",
        "sampling_rate = 50\n",
        "# Дискретизация и квантуване\n",
        "sample_times = np.arange(0, 1, 1/sampling_rate)\n",
        "samples = 2.5 + 1.5 * np.sin(2 * np.pi * 5 * sample_times)\n",
        "digital_samples = np.round((samples / v_ref) * (2**resolution - 1))\n",
        "quantized_voltage = (digital_samples / (2**resolution - 1)) * v_ref\n",
        "# Визуализация\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
        "ax1.plot(t, analog_signal, &#39;b-&#39;, label=&#39;Аналогов сигнал&#39;, alpha=0.7)\n",
        "ax1.stem(sample_times, quantized_voltage, &#39;r-&#39;, markerfmt=&#39;ro&#39;,\n",
        "label=&#39;Дискретизирани проби&#39;)\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "quantization_error = samples - quantized_voltage\n",
        "ax2.stem(sample_times, quantization_error, &#39;g-&#39;, markerfmt=&#39;go&#39;)\n",
        "ax2.set_title(&#39;Квантова грешка&#39;)\n",
        "ax2.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plot_adc_conversion()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid character '±' (U+00B1) (3808661557.py, line 14)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 14\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f&quot;Максимална квантова грешка: ±{quantization_error:} V&quot;)\u001b[0m\n\u001b[1;37m                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '±' (U+00B1)\n"
          ]
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def calculate_adc_parameters(resolution, v_ref, analog_input):\n",
        "    steps = 2 ** resolution\n",
        "    lsb = v_ref / steps\n",
        "    digital_value = int((analog_input / v_ref) * steps)\n",
        "    quantization_error = lsb / 2\n",
        "    print(f&quot;=== Резултати за {resolution}-битов АЦП ===&quot;)\n",
        "    print(f&quot;Брой стъпки: {steps}&quot;)\n",
        "    print(f&quot;Разделителна способност (LSB): {lsb:} V&quot;)\n",
        "    print(f&quot;Цифрова стойност за {analog_input}V: {digital_value}&quot;)\n",
        "    print(f&quot;Максимална квантова грешка: ±{quantization_error:} V&quot;)\n",
        "     return steps, lsb, digital_value, quantization_error\n",
        "# Интерактивни контроли\n",
        "resolution_slider = widgets.IntSlider(value=10, min=8, max=16,\n",
        "description=&#39;Битове:&#39;)\n",
        "vref_slider = widgets.FloatSlider(value=3.3, min=1.8, max=5.0,\n",
        "step=0.1, description=&#39;Vref:&#39;)\n",
        "input_slider = widgets.FloatSlider(value=1.65, min=0, max=3.3,\n",
        "step=0.01, description=&#39;Vвход:&#39;)\n",
        "def on_parameter_change(change):\n",
        "     calculate_adc_parameters(\n",
        "        resolution_slider.value,\n",
        "        vref_slider.value,\n",
        "        input_slider.value\n",
        "    )\n",
        "resolution_slider.observe(on_parameter_change, names=&#39;value&#39;)\n",
        "vref_slider.observe(on_parameter_change, names=&#39;value&#39;)\n",
        "input_slider.observe(on_parameter_change, names=&#39;value&#39;)\n",
        "display(resolution_slider, vref_slider, input_slider)\n",
        "calculate_adc_parameters(10, 3.3, 1.65)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
