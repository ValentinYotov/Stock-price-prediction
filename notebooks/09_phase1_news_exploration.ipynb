{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: News Sources Exploration\n",
        "\n",
        "This notebook explores different news sources and checks if our current dataset already contains news data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "project_root = Path().absolute().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "import os\n",
        "os.chdir(project_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from src.data.loader import load_raw_dataset\n",
        "from src.utils.config import load_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 Check Current Dataset for News Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset name: pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs\n",
            "\n",
            "Loading local dataset: data\\raw\\sp500_stocks_data.parquet\n",
            "Shape: (1048575, 23)\n",
            "\n",
            "Columns (23):\n",
            "  1. Ticker\n",
            "  2. Date\n",
            "  3. Open\n",
            "  4. Close\n",
            "  5. Volume\n",
            "  6. quarter\n",
            "  7. year\n",
            "  8. Asset Turnover\n",
            "  9. Current Ratio\n",
            "  10. Days Sales In Receivables\n",
            "  11. Debt/Equity Ratio\n",
            "  12. EBIT Margin\n",
            "  13. EBITDA Margin\n",
            "  14. Gross Margin\n",
            "  15. Inventory Turnover Ratio\n",
            "  16. Long-term Debt / Capital\n",
            "  17. Net Profit Margin\n",
            "  18. Operating Margin\n",
            "  19. Pre-Tax Profit Margin\n",
            "  20. ROA - Return On Assets\n",
            "  21. ROE - Return On Equity\n",
            "  22. Receiveable Turnover\n",
            "  23. Return On Tangible Equity\n",
            "\n",
            "❌ No news-related columns found in dataset\n",
            "\n",
            "Sample row (first 5 columns):\n",
            "Ticker             A\n",
            "Date      2005-04-01\n",
            "Open           13.88\n",
            "Close          13.67\n",
            "Volume       4717800\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Load current dataset\n",
        "config = load_config()\n",
        "print(f\"Dataset name: {config.data.dataset_name}\")\n",
        "\n",
        "# Check local file first\n",
        "local_file = Path(\"data/raw/sp500_stocks_data.parquet\")\n",
        "if local_file.exists():\n",
        "    print(f\"\\nLoading local dataset: {local_file}\")\n",
        "    df = pd.read_parquet(local_file)\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"\\nColumns ({len(df.columns)}):\")\n",
        "    for i, col in enumerate(df.columns, 1):\n",
        "        print(f\"  {i}. {col}\")\n",
        "    \n",
        "    # Check for news-related columns\n",
        "    news_keywords = ['news', 'article', 'headline', 'title', 'content', 'text', 'sentiment']\n",
        "    news_cols = [col for col in df.columns if any(kw in col.lower() for kw in news_keywords)]\n",
        "    \n",
        "    if news_cols:\n",
        "        print(f\"\\n✅ Found news-related columns: {news_cols}\")\n",
        "        for col in news_cols:\n",
        "            print(f\"\\n  {col}:\")\n",
        "            print(f\"    Non-null count: {df[col].notna().sum()} / {len(df)}\")\n",
        "            if df[col].dtype == 'object':\n",
        "                sample = df[col].dropna().iloc[0] if df[col].notna().any() else None\n",
        "                if sample:\n",
        "                    print(f\"    Sample (first 200 chars): {str(sample)[:200]}...\")\n",
        "    else:\n",
        "        print(f\"\\n❌ No news-related columns found in dataset\")\n",
        "    \n",
        "    # Show sample row\n",
        "    print(f\"\\nSample row (first 5 columns):\")\n",
        "    print(df.iloc[0][df.columns[:5]])\n",
        "else:\n",
        "    print(f\"\\n⚠️  Local file not found. Would need to load from Hugging Face.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Check Hugging Face Dataset Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 4: FinBERT for Text Processing\n",
        "\n",
        "FinBERT is a specialized BERT model trained on financial texts. It's perfect for:\n",
        "- **Text embeddings** - Converting news text to numerical vectors\n",
        "- **Sentiment analysis** - Classifying news as positive/negative/neutral\n",
        "- **Financial domain understanding** - Better than general BERT for financial texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing FinBERT...\n",
            "Loading FinBERT model...\n",
            "This may take a minute on first run (downloading ~500MB)...\n",
            "✅ FinBERT loaded successfully!\n",
            "   Model: ProsusAI/finbert\n",
            "   Max sequence length: 512\n",
            "\\nTesting sentiment analysis on sample texts:\n",
            "================================================================================\n",
            "\\nText: Apple Inc. reported strong quarterly earnings, beating analyst expecta...\n",
            "Sentiment: POSITIVE (confidence: 0.952)\n",
            "Scores: positive=0.952, negative=0.025, neutral=0.022\n",
            "\\nText: The stock market crashed following the unexpected interest rate hike....\n",
            "Sentiment: NEGATIVE (confidence: 0.909)\n",
            "Scores: positive=0.017, negative=0.909, neutral=0.075\n",
            "\\nText: Microsoft announced a new partnership with major cloud providers....\n",
            "Sentiment: POSITIVE (confidence: 0.920)\n",
            "Scores: positive=0.920, negative=0.010, neutral=0.070\n",
            "\\n================================================================================\n",
            "\\n✅ FinBERT is working correctly!\n",
            "\\nUsage:\n",
            "  1. For sentiment: Use the classification head (as shown above)\n",
            "  2. For embeddings: Use model.bert() to get hidden states\n",
            "  3. For fine-tuning: Can further train on your specific data\n"
          ]
        }
      ],
      "source": [
        "# FinBERT - Financial BERT model\n",
        "# Hugging Face: ProsusAI/finbert\n",
        "# Perfect for financial news embeddings and sentiment analysis\n",
        "\n",
        "def test_finbert():\n",
        "    \"\"\"Test FinBERT for financial text processing\"\"\"\n",
        "    try:\n",
        "        from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "        import torch\n",
        "        \n",
        "        print(\"Loading FinBERT model...\")\n",
        "        print(\"This may take a minute on first run (downloading ~500MB)...\")\n",
        "        \n",
        "        # Load FinBERT model and tokenizer\n",
        "        model_name = \"ProsusAI/finbert\"\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "        model.eval()\n",
        "        \n",
        "        print(f\"✅ FinBERT loaded successfully!\")\n",
        "        print(f\"   Model: {model_name}\")\n",
        "        print(f\"   Max sequence length: {tokenizer.model_max_length}\")\n",
        "        \n",
        "        # Test with sample financial news\n",
        "        test_texts = [\n",
        "            \"Apple Inc. reported strong quarterly earnings, beating analyst expectations.\",\n",
        "            \"The stock market crashed following the unexpected interest rate hike.\",\n",
        "            \"Microsoft announced a new partnership with major cloud providers.\",\n",
        "        ]\n",
        "        \n",
        "        print(f\"\\\\nTesting sentiment analysis on sample texts:\")\n",
        "        print(\"=\" * 80)\n",
        "        \n",
        "        for text in test_texts:\n",
        "            # Tokenize\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "            \n",
        "            # Get predictions\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "            \n",
        "            # Get sentiment labels\n",
        "            labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "            scores = predictions[0].tolist()\n",
        "            \n",
        "            # Find predicted label\n",
        "            predicted_idx = scores.index(max(scores))\n",
        "            predicted_label = labels[predicted_idx]\n",
        "            confidence = scores[predicted_idx]\n",
        "            \n",
        "            print(f\"\\\\nText: {text[:70]}...\")\n",
        "            print(f\"Sentiment: {predicted_label.upper()} (confidence: {confidence:.3f})\")\n",
        "            print(f\"Scores: positive={scores[0]:.3f}, negative={scores[1]:.3f}, neutral={scores[2]:.3f}\")\n",
        "        \n",
        "        print(\"\\\\n\" + \"=\" * 80)\n",
        "        print(\"\\\\n✅ FinBERT is working correctly!\")\n",
        "        print(\"\\\\nUsage:\")\n",
        "        print(\"  1. For sentiment: Use the classification head (as shown above)\")\n",
        "        print(\"  2. For embeddings: Use model.bert() to get hidden states\")\n",
        "        print(\"  3. For fine-tuning: Can further train on your specific data\")\n",
        "        \n",
        "        return model, tokenizer\n",
        "        \n",
        "    except ImportError:\n",
        "        print(\"❌ transformers library not installed\")\n",
        "        print(\"Install with: pip install transformers torch\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading FinBERT: {e}\")\n",
        "        return None, None\n",
        "\n",
        "print(\"Testing FinBERT...\")\n",
        "finbert_model, finbert_tokenizer = test_finbert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FinBERT Usage: Embeddings vs Sentiment\n",
        "\n",
        "FinBERT може да се използва по **два начина**:\n",
        "\n",
        "1. **Sentiment Analysis (оценка)** - Класифицира новината като positive/negative/neutral\n",
        "2. **Text Embeddings (като features)** - Конвертира текста в числов вектор за невронната мрежа\n",
        "\n",
        "**За нашия модел ще използваме EMBEDDINGS като features!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FinBERT: Embeddings vs Sentiment\n",
            "================================================================================\n",
            "Loading FinBERT model: ProsusAI/finbert\n",
            "Device: cpu\n",
            "✅ FinBERT loaded successfully\n",
            "\\n1. SENTIMENT ANALYSIS (оценка):\n",
            "--------------------------------------------------------------------------------\n",
            "\\nNews: Apple Inc. reported strong quarterly earnings, beating analy...\n",
            "Sentiment: POSITIVE\n",
            "Probabilities: {'positive': 0.9540815, 'negative': 0.02447934, 'neutral': 0.021439075}\n",
            "\\nNews: The Federal Reserve announced an unexpected interest rate hi...\n",
            "Sentiment: NEGATIVE\n",
            "Probabilities: {'positive': 0.032959264, 'negative': 0.92655826, 'neutral': 0.04048254}\n",
            "\\nNews: Microsoft announced a new strategic partnership with major c...\n",
            "Sentiment: POSITIVE\n",
            "Probabilities: {'positive': 0.9315136, 'negative': 0.011544814, 'neutral': 0.056941617}\n",
            "\\n\\n2. TEXT EMBEDDINGS (като features за модела):\n",
            "--------------------------------------------------------------------------------\n",
            "\\nEmbeddings shape: (3, 768)\n",
            "  - 3 news items\n",
            "  - 768 dimensions per embedding\n",
            "\\nThis is what we'll feed into the neural network!\n",
            "\\nSample embedding (first 10 dimensions):\n",
            "[ 0.7080523  -0.7400395   0.32401642  0.17763725  0.17293246  0.71291643\n",
            " -0.1886649  -0.942159    0.5805611  -0.66185063]\n",
            "\\n\\n3. COMBINED APPROACH:\n",
            "--------------------------------------------------------------------------------\n",
            "We can use BOTH:\n",
            "  - Embeddings → Input features for the model\n",
            "  - Sentiment → Additional feature or for analysis\n",
            "\\nEmbeddings: (3, 768)\n",
            "Sentiment dict keys: ['labels', 'probabilities', 'predicted']\n",
            "Predicted labels: ['positive', 'negative', 'positive']\n",
            "\\nSentiment scores: [ 1. -1.  1.]\n",
            "  (Can be added as additional feature alongside embeddings)\n",
            "\\nFirst item probabilities:\n",
            "  positive: 0.9541\n",
            "  negative: 0.0245\n",
            "  neutral: 0.0214\n",
            "\\n================================================================================\n",
            "CONCLUSION:\n",
            "================================================================================\n",
            "\n",
            "✅ FinBERT embeddings → Main features for neural network (768 dimensions)\n",
            "✅ Sentiment scores → Optional additional feature (1 dimension)\n",
            "\n",
            "The embeddings capture semantic meaning of the news text,\n",
            "which the model can learn to correlate with price movements.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Example: Using FinBERT embeddings as features for the model\n",
        "\n",
        "from src.models.news_encoder import FinBERTEncoder\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"FinBERT: Embeddings vs Sentiment\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Initialize encoder\n",
        "encoder = FinBERTEncoder()\n",
        "\n",
        "# Sample news text\n",
        "sample_news = [\n",
        "    \"Apple Inc. reported strong quarterly earnings, beating analyst expectations by 15%.\",\n",
        "    \"The Federal Reserve announced an unexpected interest rate hike, causing market volatility.\",\n",
        "    \"Microsoft announced a new strategic partnership with major cloud providers.\",\n",
        "]\n",
        "\n",
        "print(\"\\\\n1. SENTIMENT ANALYSIS (оценка):\")\n",
        "print(\"-\" * 80)\n",
        "for news in sample_news:\n",
        "    sentiment = encoder.get_sentiment(news)\n",
        "    print(f\"\\\\nNews: {news[:60]}...\")\n",
        "    print(f\"Sentiment: {sentiment['label'].upper()}\")\n",
        "    print(f\"Probabilities: {sentiment['probabilities']}\")\n",
        "\n",
        "print(\"\\\\n\\\\n2. TEXT EMBEDDINGS (като features за модела):\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Get embeddings (these will be used as features in the neural network)\n",
        "embeddings = encoder.encode_text(sample_news)\n",
        "print(f\"\\\\nEmbeddings shape: {embeddings.shape}\")\n",
        "print(f\"  - {embeddings.shape[0]} news items\")\n",
        "print(f\"  - {embeddings.shape[1]} dimensions per embedding\")\n",
        "print(f\"\\\\nThis is what we'll feed into the neural network!\")\n",
        "\n",
        "# Show sample embedding\n",
        "print(f\"\\\\nSample embedding (first 10 dimensions):\")\n",
        "print(embeddings[0][:10])\n",
        "\n",
        "print(\"\\\\n\\\\n3. COMBINED APPROACH:\")\n",
        "print(\"-\" * 80)\n",
        "print(\"We can use BOTH:\")\n",
        "print(\"  - Embeddings → Input features for the model\")\n",
        "print(\"  - Sentiment → Additional feature or for analysis\")\n",
        "\n",
        "# Get both embeddings and sentiment\n",
        "embeddings_with_sentiment, sentiment_dict = encoder.encode_text(\n",
        "    sample_news,\n",
        "    return_sentiment=True\n",
        ")\n",
        "\n",
        "print(f\"\\\\nEmbeddings: {embeddings_with_sentiment.shape}\")\n",
        "print(f\"Sentiment dict keys: {list(sentiment_dict.keys())}\")\n",
        "\n",
        "# Check format of sentiment_dict\n",
        "# For multiple texts, sentiment_dict has 'predicted' (list of strings), 'probabilities', and 'labels'\n",
        "if isinstance(sentiment_dict, dict):\n",
        "    if 'predicted' in sentiment_dict:\n",
        "        # Multiple texts - sentiment_dict['predicted'] is a list of strings\n",
        "        predicted_labels = sentiment_dict['predicted']\n",
        "        print(f\"Predicted labels: {predicted_labels}\")\n",
        "        \n",
        "        # Convert sentiment to numerical score\n",
        "        # positive = +1, neutral = 0, negative = -1\n",
        "        score_map = {'positive': 1.0, 'neutral': 0.0, 'negative': -1.0}\n",
        "        sentiment_scores = np.array([score_map.get(label, 0.0) for label in predicted_labels])\n",
        "        \n",
        "        print(f\"\\\\nSentiment scores: {sentiment_scores}\")\n",
        "        print(f\"  (Can be added as additional feature alongside embeddings)\")\n",
        "        \n",
        "        # Show probabilities for first item\n",
        "        if 'probabilities' in sentiment_dict and len(sentiment_dict['probabilities']) > 0:\n",
        "            print(f\"\\\\nFirst item probabilities:\")\n",
        "            probs = sentiment_dict['probabilities'][0]\n",
        "            labels = sentiment_dict['labels']\n",
        "            for label, prob in zip(labels, probs):\n",
        "                print(f\"  {label}: {prob:.4f}\")\n",
        "    elif 'label' in sentiment_dict:\n",
        "        # Single text - sentiment_dict has 'label' key\n",
        "        label = sentiment_dict['label']\n",
        "        score_map = {'positive': 1.0, 'neutral': 0.0, 'negative': -1.0}\n",
        "        sentiment_scores = np.array([score_map.get(label, 0.0)])\n",
        "        print(f\"Sentiment label: {label}\")\n",
        "        print(f\"Sentiment score: {sentiment_scores}\")\n",
        "else:\n",
        "    print(f\"Unexpected sentiment format: {type(sentiment_dict)}\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\" * 80)\n",
        "print(\"CONCLUSION:\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "✅ FinBERT embeddings → Main features for neural network (768 dimensions)\n",
        "✅ Sentiment scores → Optional additional feature (1 dimension)\n",
        "\n",
        "The embeddings capture semantic meaning of the news text,\n",
        "which the model can learn to correlate with price movements.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Важно: Откъде идват новините?\n",
        "\n",
        "**FinBERT НЕ извлича новини!** FinBERT само обработва новини които ние му даваме.\n",
        "\n",
        "**Пълният pipeline е:**\n",
        "\n",
        "```\n",
        "┌─────────────────┐\n",
        "│  News Source    │  ← Извлича новини от интернет\n",
        "│  (yfinance/     │     (yfinance, Alpha Vantage, и т.н.)\n",
        "│   Alpha Vantage)│\n",
        "└────────┬────────┘\n",
        "         │\n",
        "         │ новини (текст)\n",
        "         ▼\n",
        "┌─────────────────┐\n",
        "│    FinBERT      │  ← Обработва новините\n",
        "│  (news_encoder) │     (embeddings + sentiment)\n",
        "└────────┬────────┘\n",
        "         │\n",
        "         │ embeddings (768 числа)\n",
        "         ▼\n",
        "┌─────────────────┐\n",
        "│  Our Model      │  ← Използва embeddings като features\n",
        "│  (Transformer)  │\n",
        "└─────────────────┘\n",
        "```\n",
        "\n",
        "**Стъпки:**\n",
        "1. **News Source** извлича новини → \"Apple reported strong earnings...\"\n",
        "2. **FinBERT** обработва новините → [0.23, -0.45, ..., 0.12] (768 числа)\n",
        "3. **Нашият модел** използва embeddings → прогноза за цената"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ПЪЛЕН PIPELINE: News Source → FinBERT → Embeddings\n",
            "================================================================================\n",
            "\\n1. ИЗВЛИЧАНЕ НА НОВИНИ (от news source):\n",
            "--------------------------------------------------------------------------------\n",
            "Извличане на новини за AAPL от Yahoo Finance...\n",
            "✅ Извлечени 3 новини\n",
            "\\nПримерна новина:\n",
            "  Title: \n",
            "  Publisher: \n",
            "  Time: 1970-01-01 02:00:00\n",
            "\\n\\n2. ОБРАБОТКА С FINBERT:\n",
            "--------------------------------------------------------------------------------\n",
            "Loading FinBERT model: ProsusAI/finbert\n",
            "Device: cpu\n",
            "✅ FinBERT loaded successfully\n",
            "Обработване на новина: '...'\n",
            "\\n✅ Embeddings shape: (768,)\n",
            "   (Това са 768 числа които ще използваме като features)\n",
            "\\n✅ Sentiment: neutral\n",
            "   Probabilities: {'positive': 0.35916334, 'negative': 0.21665199, 'neutral': 0.4241847}\n",
            "\\n\\n3. РЕЗУЛТАТ:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "        ✅ Имаме новини (от Yahoo Finance)\n",
            "        ✅ Имаме embeddings (от FinBERT) - 768 числа\n",
            "        ✅ Имаме sentiment (от FinBERT) - positive/negative/neutral\n",
            "        \n",
            "        Следваща стъпка: Добавяне на embeddings към техническите features\n",
            "        и трениране на модела!\n",
            "        \n",
            "\\n================================================================================\n",
            "ЗАКЛЮЧЕНИЕ:\n",
            "================================================================================\n",
            "\n",
            "✅ News Source (yfinance) → Извлича новини от интернет\n",
            "✅ FinBERT → Обработва новините и ги конвертира в embeddings\n",
            "✅ Our Model → Използва embeddings като features за прогнози\n",
            "\n",
            "FinBERT е инструмент за обработка, не източник на новини!\n",
            "\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Пример: Пълен pipeline от новини до embeddings\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ПЪЛЕН PIPELINE: News Source → FinBERT → Embeddings\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Стъпка 1: Извличане на новини (от news source)\n",
        "print(\"\\\\n1. ИЗВЛИЧАНЕ НА НОВИНИ (от news source):\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "try:\n",
        "    from src.data.news_loader import fetch_yahoo_finance_news\n",
        "    \n",
        "    # Извличаме новини за AAPL\n",
        "    print(\"Извличане на новини за AAPL от Yahoo Finance...\")\n",
        "    news_list = fetch_yahoo_finance_news('AAPL', limit=3)\n",
        "    \n",
        "    if news_list:\n",
        "        print(f\"✅ Извлечени {len(news_list)} новини\")\n",
        "        print(\"\\\\nПримерна новина:\")\n",
        "        news_item = news_list[0]\n",
        "        print(f\"  Title: {news_item['title']}\")\n",
        "        print(f\"  Publisher: {news_item['publisher']}\")\n",
        "        print(f\"  Time: {news_item['published_time']}\")\n",
        "        \n",
        "        # Стъпка 2: Обработка с FinBERT\n",
        "        print(\"\\\\n\\\\n2. ОБРАБОТКА С FINBERT:\")\n",
        "        print(\"-\" * 80)\n",
        "        \n",
        "        from src.models.news_encoder import FinBERTEncoder\n",
        "        encoder = FinBERTEncoder()\n",
        "        \n",
        "        # Взимаме текста на новината\n",
        "        news_text = news_item['title']  # Може да добавим и description/summary\n",
        "        \n",
        "        print(f\"Обработване на новина: '{news_text[:80]}...'\")\n",
        "        \n",
        "        # Получаваме embeddings\n",
        "        embeddings = encoder.encode_text(news_text)\n",
        "        print(f\"\\\\n✅ Embeddings shape: {embeddings.shape}\")\n",
        "        print(f\"   (Това са {embeddings.shape[0]} числа които ще използваме като features)\")\n",
        "        \n",
        "        # Получаваме sentiment\n",
        "        sentiment = encoder.get_sentiment(news_text)\n",
        "        print(f\"\\\\n✅ Sentiment: {sentiment['label']}\")\n",
        "        print(f\"   Probabilities: {sentiment['probabilities']}\")\n",
        "        \n",
        "        print(\"\\\\n\\\\n3. РЕЗУЛТАТ:\")\n",
        "        print(\"-\" * 80)\n",
        "        print(\"\"\"\n",
        "        ✅ Имаме новини (от Yahoo Finance)\n",
        "        ✅ Имаме embeddings (от FinBERT) - 768 числа\n",
        "        ✅ Имаме sentiment (от FinBERT) - positive/negative/neutral\n",
        "        \n",
        "        Следваща стъпка: Добавяне на embeddings към техническите features\n",
        "        и трениране на модела!\n",
        "        \"\"\")\n",
        "        \n",
        "    else:\n",
        "        print(\"⚠️  Не са намерени новини. Може да е проблем с yfinance.\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ Грешка: {e}\")\n",
        "    print(\"\\\\nТова е нормално ако yfinance не е инсталиран.\")\n",
        "    print(\"Инсталирай с: pip install yfinance\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\" * 80)\n",
        "print(\"ЗАКЛЮЧЕНИЕ:\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "✅ News Source (yfinance) → Извлича новини от интернет\n",
        "✅ FinBERT → Обработва новините и ги конвертира в embeddings\n",
        "✅ Our Model → Използва embeddings като features за прогнози\n",
        "\n",
        "FinBERT е инструмент за обработка, не източник на новини!\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Решение за исторически новини (2010-2024)\n",
        "\n",
        "За целия период на модела (2010-2024) имаме няколко опции:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Опции за исторически новини (2010-2024)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ОПЦИИ ЗА ИСТОРИЧЕСКИ НОВИНИ (2010-2024)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "options = {\n",
        "    \"1. Yahoo Finance RSS Feeds\": {\n",
        "        \"Покритие\": \"Ограничено (обикновено последните 1-2 години)\",\n",
        "        \"Безплатно\": \"✅ Да\",\n",
        "        \"API Key\": \"❌ Не\",\n",
        "        \"Трудност\": \"Лесно\",\n",
        "        \"Препоръка\": \"За тестване, но не за пълно покритие\"\n",
        "    },\n",
        "    \"2. Web Scraping (Yahoo Finance, Seeking Alpha)\": {\n",
        "        \"Покритие\": \"Пълно (може да се стигне до 2010)\",\n",
        "        \"Безплатно\": \"✅ Да\",\n",
        "        \"API Key\": \"❌ Не\",\n",
        "        \"Трудност\": \"Средно-трудно\",\n",
        "        \"Препоръка\": \"Най-добро решение за безплатни данни\"\n",
        "    },\n",
        "    \"3. Alpha Vantage News API\": {\n",
        "        \"Покритие\": \"Ограничено (последните 1-2 години)\",\n",
        "        \"Безплатно\": \"✅ Да (free tier)\",\n",
        "        \"API Key\": \"✅ Да (безплатен)\",\n",
        "        \"Трудност\": \"Лесно\",\n",
        "        \"Препоръка\": \"Допълнение към scraping\"\n",
        "    },\n",
        "    \"4. Financial Modeling Prep API\": {\n",
        "        \"Покритие\": \"Добро (няколко години назад)\",\n",
        "        \"Безплатно\": \"⚠️ Частично (free tier ограничен)\",\n",
        "        \"API Key\": \"✅ Да\",\n",
        "        \"Трудност\": \"Лесно\",\n",
        "        \"Препоръка\": \"Ако free tier е достатъчен\"\n",
        "    },\n",
        "    \"5. Pre-collected Datasets\": {\n",
        "        \"Покритие\": \"Зависи от dataset-а\",\n",
        "        \"Безплатно\": \"✅ Да (ако намерим такъв)\",\n",
        "        \"API Key\": \"❌ Не\",\n",
        "        \"Трудност\": \"Много лесно\",\n",
        "        \"Препоръка\": \"Най-добро ако намерим подходящ dataset\"\n",
        "    },\n",
        "}\n",
        "\n",
        "for option, details in options.items():\n",
        "    print(f\"\\\\n{option}:\")\n",
        "    for key, value in details.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\" * 80)\n",
        "print(\"ПРЕПОРЪКА:\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "За целия период (2010-2024) препоръчвам КОМБИНИРАН подход:\n",
        "\n",
        "1. **Web Scraping** (основен източник)\n",
        "   - Yahoo Finance news pages (с уважение към rate limits)\n",
        "   - Seeking Alpha (ако има RSS или разрешение)\n",
        "   - MarketWatch (ако е достъпен)\n",
        "   \n",
        "2. **RSS Feeds** (допълнение)\n",
        "   - Yahoo Finance RSS\n",
        "   - Google News RSS (филтрирано за финанси)\n",
        "   \n",
        "3. **API-та** (за последните години)\n",
        "   - Alpha Vantage (за sentiment scores)\n",
        "   - yfinance (за най-новите новини)\n",
        "\n",
        "ВАЖНО:\n",
        "- Винаги проверявай robots.txt и Terms of Service\n",
        "- Добавяй забавяния между заявките (1-2 секунди)\n",
        "- Кеширай данните за да не правиш повторни заявки\n",
        "- Започни с малък тест преди пълно извличане\n",
        "\n",
        "Следваща стъпка: Създаване на scraping модул с правилно handling на rate limits.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test StockData.org API\n",
        "from src.data.news_loader import fetch_stockdata_news\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"TESTING STOCKDATA.ORG API\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Test with AAPL\n",
        "ticker = \"AAPL\"\n",
        "\n",
        "# Test 1: Recent news (last 30 days)\n",
        "print(f\"\\\\n1. Testing recent news for {ticker}...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "end_date = datetime.now()\n",
        "start_date = end_date - timedelta(days=30)\n",
        "\n",
        "try:\n",
        "    news_recent = fetch_stockdata_news(\n",
        "        ticker=ticker,\n",
        "        start_date=start_date,\n",
        "        end_date=end_date,\n",
        "        limit=50\n",
        "    )\n",
        "    \n",
        "    if news_recent:\n",
        "        print(f\"✅ Successfully fetched {len(news_recent)} recent news items\")\n",
        "        \n",
        "        # Convert to DataFrame for easier viewing\n",
        "        df_recent = pd.DataFrame(news_recent)\n",
        "        \n",
        "        print(f\"\\\\nDate range: {df_recent['published_time'].min()} to {df_recent['published_time'].max()}\")\n",
        "        print(f\"\\\\nSample news items:\")\n",
        "        for i, item in enumerate(news_recent[:3], 1):\n",
        "            print(f\"\\\\n  {i}. {item['title'][:80]}...\")\n",
        "            print(f\"     Source: {item.get('source', 'N/A')}\")\n",
        "            print(f\"     Date: {item.get('published_time', 'N/A')}\")\n",
        "            if item.get('description'):\n",
        "                print(f\"     Description: {item['description'][:100]}...\")\n",
        "    else:\n",
        "        print(\"⚠️  No news found for recent period\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error: {e}\")\n",
        "    print(\"\\\\nMake sure:\")\n",
        "    print(\"  1. .env file exists with STOCKDATA_API_KEY\")\n",
        "    print(\"  2. API key is valid\")\n",
        "    print(\"  3. You haven't exceeded daily limit (100 requests/day)\")\n",
        "\n",
        "# Test 2: Historical news (older period)\n",
        "print(f\"\\\\n\\\\n2. Testing historical news for {ticker}...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Try to get news from 2020-2021 (to test historical coverage)\n",
        "start_historical = datetime(2020, 1, 1)\n",
        "end_historical = datetime(2021, 12, 31)\n",
        "\n",
        "try:\n",
        "    news_historical = fetch_stockdata_news(\n",
        "        ticker=ticker,\n",
        "        start_date=start_historical,\n",
        "        end_date=end_historical,\n",
        "        limit=50\n",
        "    )\n",
        "    \n",
        "    if news_historical:\n",
        "        print(f\"✅ Successfully fetched {len(news_historical)} historical news items\")\n",
        "        df_historical = pd.DataFrame(news_historical)\n",
        "        print(f\"\\\\nDate range: {df_historical['published_time'].min()} to {df_historical['published_time'].max()}\")\n",
        "        print(f\"\\\\nThis shows StockData.org CAN provide historical data!\")\n",
        "    else:\n",
        "        print(\"⚠️  No historical news found (may be limited by free tier)\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error: {e}\")\n",
        "\n",
        "# Test 3: Check coverage for our full period (2010-2024)\n",
        "print(f\"\\\\n\\\\n3. Checking coverage for full model period (2010-2024)...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "start_full = datetime(2010, 1, 1)\n",
        "end_full = datetime.now()\n",
        "\n",
        "try:\n",
        "    # Just check first 10 to see date range\n",
        "    news_full = fetch_stockdata_news(\n",
        "        ticker=ticker,\n",
        "        start_date=start_full,\n",
        "        end_date=end_full,\n",
        "        limit=10\n",
        "    )\n",
        "    \n",
        "    if news_full:\n",
        "        df_full = pd.DataFrame(news_full)\n",
        "        oldest_date = df_full['published_time'].min()\n",
        "        newest_date = df_full['published_time'].max()\n",
        "        \n",
        "        print(f\"✅ Sample news date range: {oldest_date} to {newest_date}\")\n",
        "        \n",
        "        if oldest_date.year <= 2015:\n",
        "            print(f\"\\\\n✅ EXCELLENT! StockData.org provides data back to {oldest_date.year}\")\n",
        "            print(f\"   This should cover most of our backtest period!\")\n",
        "        elif oldest_date.year <= 2020:\n",
        "            print(f\"\\\\n⚠️  StockData.org provides data back to {oldest_date.year}\")\n",
        "            print(f\"   May need to combine with other sources for 2010-{oldest_date.year-1}\")\n",
        "        else:\n",
        "            print(f\"\\\\n⚠️  Limited historical coverage - only back to {oldest_date.year}\")\n",
        "            print(f\"   Will need additional sources for full period\")\n",
        "    else:\n",
        "        print(\"⚠️  No news found - may need to check API limits or date format\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error: {e}\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\" * 80)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "StockData.org API test completed.\n",
        "Check the results above to see:\n",
        "- How many news items we can fetch\n",
        "- What date range is available\n",
        "- If it covers our backtest period (2010-2024)\n",
        "\n",
        "Next steps:\n",
        "- If coverage is good → Use StockData.org as primary source\n",
        "- If coverage is limited → Combine with yfinance/RSS for full period\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking dataset: pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset info:\n",
            "  No description\n",
            "  Features: {'_id': Value('string'), 'compound': Value('float64'), 'date': Value('string'), 'headline': Value('string'), 'neg': Value('float64'), 'neu': Value('float64'), 'pos': Value('float64'), 'ticker': Value('string'), 'time': Value('string')}\n",
            "\n",
            "✅ Found news-related features: ['headline']\n"
          ]
        }
      ],
      "source": [
        "# Check Hugging Face dataset structure\n",
        "from datasets import load_dataset_builder, get_dataset_infos\n",
        "\n",
        "dataset_name = config.data.dataset_name\n",
        "print(f\"Checking dataset: {dataset_name}\")\n",
        "\n",
        "try:\n",
        "    builder = load_dataset_builder(dataset_name)\n",
        "    print(f\"\\nDataset info:\")\n",
        "    print(f\"  Description: {builder.info.description[:200]}...\" if builder.info.description else \"  No description\")\n",
        "    print(f\"  Features: {builder.info.features}\")\n",
        "    \n",
        "    # Check for news-related features\n",
        "    if hasattr(builder.info, 'features'):\n",
        "        feature_names = list(builder.info.features.keys()) if isinstance(builder.info.features, dict) else []\n",
        "        news_features = [f for f in feature_names if any(kw in f.lower() for kw in ['news', 'article', 'headline', 'text'])]\n",
        "        \n",
        "        if news_features:\n",
        "            print(f\"\\n✅ Found news-related features: {news_features}\")\n",
        "        else:\n",
        "            print(f\"\\n❌ No news-related features found\")\n",
        "            print(f\"\\nAvailable features: {feature_names[:20]}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n⚠️  Could not load dataset builder: {e}\")\n",
        "    print(\"This is okay - we'll proceed with external news sources\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 Test News APIs\n",
        "\n",
        "Let's test different news APIs to see which one works best for our use case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 1: Alpha Vantage News API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Alpha Vantage News API...\n",
            "Note: You need to set ALPHA_VANTAGE_API_KEY environment variable\n",
            "Get free API key at: https://www.alphavantage.co/support/#api-key\n",
            "\n",
            "⚠️  Using demo key - will likely hit rate limit. Set your API key to test properly.\n"
          ]
        }
      ],
      "source": [
        "# Alpha Vantage News API\n",
        "# Documentation: https://www.alphavantage.co/documentation/#news-sentiment\n",
        "# Free tier: 5 API calls per minute, 500 calls per day\n",
        "\n",
        "import requests\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# You'll need to get an API key from https://www.alphavantage.co/support/#api-key\n",
        "ALPHA_VANTAGE_API_KEY = os.getenv('GKXZ5NT78PUAR2DT', 'demo')  # Replace with your key\n",
        "\n",
        "def test_alpha_vantage_news(ticker='AAPL', limit=10):\n",
        "    \"\"\"Test Alpha Vantage News API\"\"\"\n",
        "    url = 'https://www.alphavantage.co/query'\n",
        "    params = {\n",
        "        'function': 'NEWS_SENTIMENT',\n",
        "        'tickers': ticker,\n",
        "        'limit': limit,\n",
        "        'apikey': ALPHA_VANTAGE_API_KEY\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        response = requests.get(url, params=params, timeout=10)\n",
        "        data = response.json()\n",
        "        \n",
        "        if 'Information' in data:\n",
        "            print(f\"⚠️  API Info: {data['Information']}\")\n",
        "            return None\n",
        "        \n",
        "        if 'feed' in data:\n",
        "            articles = data['feed']\n",
        "            print(f\"✅ Successfully fetched {len(articles)} articles for {ticker}\")\n",
        "            \n",
        "            if articles:\n",
        "                print(f\"\\nSample article:\")\n",
        "                article = articles[0]\n",
        "                print(f\"  Title: {article.get('title', 'N/A')[:100]}...\")\n",
        "                print(f\"  Source: {article.get('source', 'N/A')}\")\n",
        "                print(f\"  Time: {article.get('time_published', 'N/A')}\")\n",
        "                print(f\"  Sentiment Score: {article.get('overall_sentiment_score', 'N/A')}\")\n",
        "                print(f\"  Relevance Score: {article.get('relevance_score', 'N/A')}\")\n",
        "            \n",
        "            return articles\n",
        "        else:\n",
        "            print(f\"❌ Unexpected response format: {list(data.keys())}\")\n",
        "            return None\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"Testing Alpha Vantage News API...\")\n",
        "print(\"Note: You need to set ALPHA_VANTAGE_API_KEY environment variable\")\n",
        "print(\"Get free API key at: https://www.alphavantage.co/support/#api-key\\n\")\n",
        "\n",
        "if ALPHA_VANTAGE_API_KEY != 'demo':\n",
        "    alpha_vantage_results = test_alpha_vantage_news('AAPL', limit=5)\n",
        "else:\n",
        "    print(\"⚠️  Using demo key - will likely hit rate limit. Set your API key to test properly.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 2: NewsAPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing NewsAPI...\n",
            "⚠️  Set NEWSAPI_KEY environment variable to test\n"
          ]
        }
      ],
      "source": [
        "# NewsAPI\n",
        "# Documentation: https://newsapi.org/docs\n",
        "# Free tier: 100 requests per day\n",
        "\n",
        "NEWSAPI_KEY = os.getenv('NEWSAPI_KEY', '')  # Get from https://newsapi.org/register\n",
        "\n",
        "def test_newsapi(ticker='AAPL', days_back=7):\n",
        "    \"\"\"Test NewsAPI\"\"\"\n",
        "    if not NEWSAPI_KEY:\n",
        "        print(\"⚠️  NEWSAPI_KEY not set. Get one at https://newsapi.org/register\")\n",
        "        return None\n",
        "    \n",
        "    url = 'https://newsapi.org/v2/everything'\n",
        "    \n",
        "    # Calculate date range\n",
        "    to_date = datetime.now()\n",
        "    from_date = to_date - timedelta(days=days_back)\n",
        "    \n",
        "    params = {\n",
        "        'q': ticker,  # Search query\n",
        "        'from': from_date.strftime('%Y-%m-%d'),\n",
        "        'to': to_date.strftime('%Y-%m-%d'),\n",
        "        'sortBy': 'publishedAt',\n",
        "        'language': 'en',\n",
        "        'pageSize': 10,\n",
        "        'apiKey': NEWSAPI_KEY\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        response = requests.get(url, params=params, timeout=10)\n",
        "        data = response.json()\n",
        "        \n",
        "        if data.get('status') == 'ok':\n",
        "            articles = data.get('articles', [])\n",
        "            print(f\"✅ Successfully fetched {len(articles)} articles for {ticker}\")\n",
        "            \n",
        "            if articles:\n",
        "                print(f\"\\nSample article:\")\n",
        "                article = articles[0]\n",
        "                print(f\"  Title: {article.get('title', 'N/A')[:100]}...\")\n",
        "                print(f\"  Source: {article.get('source', {}).get('name', 'N/A')}\")\n",
        "                print(f\"  Published: {article.get('publishedAt', 'N/A')}\")\n",
        "                print(f\"  Description: {article.get('description', 'N/A')[:150]}...\")\n",
        "            \n",
        "            return articles\n",
        "        else:\n",
        "            print(f\"❌ Error: {data.get('message', 'Unknown error')}\")\n",
        "            return None\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"Testing NewsAPI...\")\n",
        "if NEWSAPI_KEY:\n",
        "    newsapi_results = test_newsapi('AAPL', days_back=7)\n",
        "else:\n",
        "    print(\"⚠️  Set NEWSAPI_KEY environment variable to test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 3: Yahoo Finance (Free, no API key needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Yahoo Finance (yfinance)...\n",
            "✅ Successfully fetched 10 news items for AAPL\n",
            "\n",
            "Sample news item:\n",
            "  Title: N/A...\n",
            "  Publisher: N/A\n",
            "  Published: N/A\n",
            "  Link: N/A...\n"
          ]
        }
      ],
      "source": [
        "# Yahoo Finance - Free option using yfinance library\n",
        "# No API key needed, but may have rate limits\n",
        "\n",
        "try:\n",
        "    import yfinance as yf\n",
        "    \n",
        "    def test_yahoo_finance_news(ticker='AAPL'):\n",
        "        \"\"\"Test Yahoo Finance news\"\"\"\n",
        "        try:\n",
        "            stock = yf.Ticker(ticker)\n",
        "            news = stock.news\n",
        "            \n",
        "            if news:\n",
        "                print(f\"✅ Successfully fetched {len(news)} news items for {ticker}\")\n",
        "                \n",
        "                if news:\n",
        "                    print(f\"\\nSample news item:\")\n",
        "                    item = news[0]\n",
        "                    print(f\"  Title: {item.get('title', 'N/A')[:100]}...\")\n",
        "                    print(f\"  Publisher: {item.get('publisher', 'N/A')}\")\n",
        "                    print(f\"  Published: {item.get('providerPublishTime', 'N/A')}\")\n",
        "                    print(f\"  Link: {item.get('link', 'N/A')[:80]}...\")\n",
        "                \n",
        "                return news\n",
        "            else:\n",
        "                print(f\"⚠️  No news found for {ticker}\")\n",
        "                return None\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error: {e}\")\n",
        "            return None\n",
        "    \n",
        "    print(\"Testing Yahoo Finance (yfinance)...\")\n",
        "    yahoo_results = test_yahoo_finance_news('AAPL')\n",
        "    \n",
        "except ImportError:\n",
        "    print(\"⚠️  yfinance not installed. Install with: pip install yfinance\")\n",
        "    print(\"This is a free option with no API key needed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.4 Comparison and Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "NEWS SOURCES COMPARISON\n",
            "================================================================================\n",
            "                  Source API Key Required         Rate Limit        Historical Data    Sentiment Score                Cost Ease of Use\n",
            "           Alpha Vantage       Yes (free)     5/min, 500/day                Limited     Yes (built-in) Free tier available      Medium\n",
            "                 NewsAPI       Yes (free)            100/day Limited (1 month free) No (need separate) Free tier available        Easy\n",
            "Yahoo Finance (yfinance)               No Unknown (may vary)            Recent only                 No                Free   Very Easy\n",
            "\n",
            "================================================================================\n",
            "RECOMMENDATION\n",
            "================================================================================\n",
            "\n",
            "For Phase 1, I recommend:\n",
            "\n",
            "1. **Start with Yahoo Finance (yfinance)** - Easiest to set up, no API key needed\n",
            "   - Good for testing and prototyping\n",
            "   - May have limitations for historical data\n",
            "\n",
            "2. **Alpha Vantage as backup** - If we need sentiment scores built-in\n",
            "   - Requires API key but free tier is generous\n",
            "   - Has built-in sentiment analysis\n",
            "\n",
            "3. **For production/historical data** - May need paid service or web scraping\n",
            "   - Consider Financial Modeling Prep or Polygon.io for better historical coverage\n",
            "\n",
            "Next steps:\n",
            "- Test yfinance with multiple tickers\n",
            "- Check if we can get historical news (may need to scrape or use paid API)\n",
            "- Evaluate data quality and coverage\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create comparison table\n",
        "comparison_data = {\n",
        "    'Source': ['Alpha Vantage', 'NewsAPI', 'Yahoo Finance (yfinance)'],\n",
        "    'API Key Required': ['Yes (free)', 'Yes (free)', 'No'],\n",
        "    'Rate Limit': ['5/min, 500/day', '100/day', 'Unknown (may vary)'],\n",
        "    'Historical Data': ['Limited', 'Limited (1 month free)', 'Recent only'],\n",
        "    'Sentiment Score': ['Yes (built-in)', 'No (need separate)', 'No'],\n",
        "    'Cost': ['Free tier available', 'Free tier available', 'Free'],\n",
        "    'Ease of Use': ['Medium', 'Easy', 'Very Easy'],\n",
        "}\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"NEWS SOURCES COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(df_comparison.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RECOMMENDATION\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "For Phase 1, I recommend:\n",
        "\n",
        "1. **Start with Yahoo Finance (yfinance)** - Easiest to set up, no API key needed\n",
        "   - Good for testing and prototyping\n",
        "   - May have limitations for historical data\n",
        "\n",
        "2. **Alpha Vantage as backup** - If we need sentiment scores built-in\n",
        "   - Requires API key but free tier is generous\n",
        "   - Has built-in sentiment analysis\n",
        "\n",
        "3. **For production/historical data** - May need paid service or web scraping\n",
        "   - Consider Financial Modeling Prep or Polygon.io for better historical coverage\n",
        "\n",
        "Next steps:\n",
        "- Test yfinance with multiple tickers\n",
        "- Check if we can get historical news (may need to scrape or use paid API)\n",
        "- Evaluate data quality and coverage\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.5 Test Historical News Availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing historical news availability...\n",
            "\n",
            "Note: Most free APIs only provide recent news (last 1-30 days)\n",
            "For backtesting, we need news from 2010-2024 period\n",
            "\n",
            "Options:\n",
            "1. Use paid API with historical data (Financial Modeling Prep, Polygon.io)\n",
            "2. Web scraping from financial news sites (with proper attribution)\n",
            "3. Use pre-collected datasets (like the Hugging Face one if it has news)\n",
            "4. Start with recent data and expand backwards gradually\n"
          ]
        }
      ],
      "source": [
        "# Test if we can get historical news (important for backtesting)\n",
        "print(\"Testing historical news availability...\")\n",
        "print(\"\\nNote: Most free APIs only provide recent news (last 1-30 days)\")\n",
        "print(\"For backtesting, we need news from 2010-2024 period\")\n",
        "print(\"\\nOptions:\")\n",
        "print(\"1. Use paid API with historical data (Financial Modeling Prep, Polygon.io)\")\n",
        "print(\"2. Web scraping from financial news sites (with proper attribution)\")\n",
        "print(\"3. Use pre-collected datasets (like the Hugging Face one if it has news)\")\n",
        "print(\"4. Start with recent data and expand backwards gradually\")\n",
        "\n",
        "# Check if yfinance can get older news\n",
        "try:\n",
        "    import yfinance as yf\n",
        "    from datetime import datetime\n",
        "    \n",
        "    stock = yf.Ticker('AAPL')\n",
        "    news = stock.news\n",
        "    \n",
        "    if news:\n",
        "        # Check date range\n",
        "        dates = []\n",
        "        for item in news:\n",
        "            if 'providerPublishTime' in item:\n",
        "                ts = item['providerPublishTime']\n",
        "                dt = datetime.fromtimestamp(ts)\n",
        "                dates.append(dt)\n",
        "        \n",
        "        if dates:\n",
        "            oldest = min(dates)\n",
        "            newest = max(dates)\n",
        "            print(f\"\\n✅ Yahoo Finance news date range:\")\n",
        "            print(f\"   Oldest: {oldest.strftime('%Y-%m-%d')}\")\n",
        "            print(f\"   Newest: {newest.strftime('%Y-%m-%d')}\")\n",
        "            print(f\"   Coverage: {(newest - oldest).days} days\")\n",
        "            \n",
        "            if oldest.year < 2020:\n",
        "                print(f\"\\n✅ Good! Can get historical data back to {oldest.year}\")\n",
        "            else:\n",
        "                print(f\"\\n⚠️  Limited historical data - only goes back to {oldest.year}\")\n",
        "                print(f\"   May need alternative source for full backtest period\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n⚠️  Could not test historical availability: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Next Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PHASE 1 SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "✅ Completed:\n",
        "1. Checked current dataset structure\n",
        "2. Tested multiple news API options\n",
        "3. Compared different sources\n",
        "\n",
        "📋 Next Steps (Phase 2):\n",
        "1. Choose primary news source (recommendation: yfinance for start)\n",
        "2. Create news_loader.py module\n",
        "3. Test fetching news for multiple tickers\n",
        "4. Design storage format for news data\n",
        "5. Create script to fetch historical news\n",
        "\n",
        "💡 Key Decisions:\n",
        "- Primary source: Yahoo Finance (yfinance) - easiest to start\n",
        "- Backup: Alpha Vantage (if we need sentiment scores)\n",
        "- Historical data: May need paid API or web scraping for full coverage\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
