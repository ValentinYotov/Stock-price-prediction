{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: News Sources Exploration\n",
        "\n",
        "This notebook explores different news sources and checks if our current dataset already contains news data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "project_root = Path().absolute().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "import os\n",
        "os.chdir(project_root)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from src.data.loader import load_raw_dataset\n",
        "from src.utils.config import load_config"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 Check Current Dataset for News Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load current dataset\n",
        "config = load_config()\n",
        "print(f\"Dataset name: {config.data.dataset_name}\")\n",
        "\n",
        "# Check local file first\n",
        "local_file = Path(\"data/raw/sp500_stocks_data.parquet\")\n",
        "if local_file.exists():\n",
        "    print(f\"\\nLoading local dataset: {local_file}\")\n",
        "    df = pd.read_parquet(local_file)\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"\\nColumns ({len(df.columns)}):\")\n",
        "    for i, col in enumerate(df.columns, 1):\n",
        "        print(f\"  {i}. {col}\")\n",
        "    \n",
        "    # Check for news-related columns\n",
        "    news_keywords = ['news', 'article', 'headline', 'title', 'content', 'text', 'sentiment']\n",
        "    news_cols = [col for col in df.columns if any(kw in col.lower() for kw in news_keywords)]\n",
        "    \n",
        "    if news_cols:\n",
        "        print(f\"\\n‚úÖ Found news-related columns: {news_cols}\")\n",
        "        for col in news_cols:\n",
        "            print(f\"\\n  {col}:\")\n",
        "            print(f\"    Non-null count: {df[col].notna().sum()} / {len(df)}\")\n",
        "            if df[col].dtype == 'object':\n",
        "                sample = df[col].dropna().iloc[0] if df[col].notna().any() else None\n",
        "                if sample:\n",
        "                    print(f\"    Sample (first 200 chars): {str(sample)[:200]}...\")\n",
        "    else:\n",
        "        print(f\"\\n‚ùå No news-related columns found in dataset\")\n",
        "    \n",
        "    # Show sample row\n",
        "    print(f\"\\nSample row (first 5 columns):\")\n",
        "    print(df.iloc[0][df.columns[:5]])\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  Local file not found. Would need to load from Hugging Face.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset name: pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs\n",
            "\n",
            "‚ö†Ô∏è  Local file not found. Would need to load from Hugging Face.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Check Hugging Face Dataset Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 4: FinBERT for Text Processing\n",
        "\n",
        "FinBERT is a specialized BERT model trained on financial texts. It's perfect for:\n",
        "- **Text embeddings** - Converting news text to numerical vectors\n",
        "- **Sentiment analysis** - Classifying news as positive/negative/neutral\n",
        "- **Financial domain understanding** - Better than general BERT for financial texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# FinBERT - Financial BERT model\n",
        "# Hugging Face: ProsusAI/finbert\n",
        "# Perfect for financial news embeddings and sentiment analysis\n",
        "\n",
        "def test_finbert():\n",
        "    \"\"\"Test FinBERT for financial text processing\"\"\"\n",
        "    try:\n",
        "        from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "        import torch\n",
        "        \n",
        "        print(\"Loading FinBERT model...\")\n",
        "        print(\"This may take a minute on first run (downloading ~500MB)...\")\n",
        "        \n",
        "        # Load FinBERT model and tokenizer\n",
        "        model_name = \"ProsusAI/finbert\"\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "        model.eval()\n",
        "        \n",
        "        print(f\"‚úÖ FinBERT loaded successfully!\")\n",
        "        print(f\"   Model: {model_name}\")\n",
        "        print(f\"   Max sequence length: {tokenizer.model_max_length}\")\n",
        "        \n",
        "        # Test with sample financial news\n",
        "        test_texts = [\n",
        "            \"Apple Inc. reported strong quarterly earnings, beating analyst expectations.\",\n",
        "            \"The stock market crashed following the unexpected interest rate hike.\",\n",
        "            \"Microsoft announced a new partnership with major cloud providers.\",\n",
        "        ]\n",
        "        \n",
        "        print(f\"\\\\nTesting sentiment analysis on sample texts:\")\n",
        "        print(\"=\" * 80)\n",
        "        \n",
        "        for text in test_texts:\n",
        "            # Tokenize\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "            \n",
        "            # Get predictions\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "            \n",
        "            # Get sentiment labels\n",
        "            labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "            scores = predictions[0].tolist()\n",
        "            \n",
        "            # Find predicted label\n",
        "            predicted_idx = scores.index(max(scores))\n",
        "            predicted_label = labels[predicted_idx]\n",
        "            confidence = scores[predicted_idx]\n",
        "            \n",
        "            print(f\"\\\\nText: {text[:70]}...\")\n",
        "            print(f\"Sentiment: {predicted_label.upper()} (confidence: {confidence:.3f})\")\n",
        "            print(f\"Scores: positive={scores[0]:.3f}, negative={scores[1]:.3f}, neutral={scores[2]:.3f}\")\n",
        "        \n",
        "        print(\"\\\\n\" + \"=\" * 80)\n",
        "        print(\"\\\\n‚úÖ FinBERT is working correctly!\")\n",
        "        print(\"\\\\nUsage:\")\n",
        "        print(\"  1. For sentiment: Use the classification head (as shown above)\")\n",
        "        print(\"  2. For embeddings: Use model.bert() to get hidden states\")\n",
        "        print(\"  3. For fine-tuning: Can further train on your specific data\")\n",
        "        \n",
        "        return model, tokenizer\n",
        "        \n",
        "    except ImportError:\n",
        "        print(\"‚ùå transformers library not installed\")\n",
        "        print(\"Install with: pip install transformers torch\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading FinBERT: {e}\")\n",
        "        return None, None\n",
        "\n",
        "print(\"Testing FinBERT...\")\n",
        "finbert_model, finbert_tokenizer = test_finbert()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing FinBERT...\n",
            "Loading FinBERT model...\n",
            "This may take a minute on first run (downloading ~500MB)...\n",
            "‚úÖ FinBERT loaded successfully!\n",
            "   Model: ProsusAI/finbert\n",
            "   Max sequence length: 512\n",
            "\\nTesting sentiment analysis on sample texts:\n",
            "================================================================================\n",
            "\\nText: Apple Inc. reported strong quarterly earnings, beating analyst expecta...\n",
            "Sentiment: POSITIVE (confidence: 0.952)\n",
            "Scores: positive=0.952, negative=0.025, neutral=0.022\n",
            "\\nText: The stock market crashed following the unexpected interest rate hike....\n",
            "Sentiment: NEGATIVE (confidence: 0.909)\n",
            "Scores: positive=0.017, negative=0.909, neutral=0.075\n",
            "\\nText: Microsoft announced a new partnership with major cloud providers....\n",
            "Sentiment: POSITIVE (confidence: 0.920)\n",
            "Scores: positive=0.920, negative=0.010, neutral=0.070\n",
            "\\n================================================================================\n",
            "\\n‚úÖ FinBERT is working correctly!\n",
            "\\nUsage:\n",
            "  1. For sentiment: Use the classification head (as shown above)\n",
            "  2. For embeddings: Use model.bert() to get hidden states\n",
            "  3. For fine-tuning: Can further train on your specific data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FinBERT Usage: Embeddings vs Sentiment\n",
        "\n",
        "FinBERT –º–æ–∂–µ –¥–∞ —Å–µ –∏–∑–ø–æ–ª–∑–≤–∞ –ø–æ **–¥–≤–∞ –Ω–∞—á–∏–Ω–∞**:\n",
        "\n",
        "1. **Sentiment Analysis (–æ—Ü–µ–Ω–∫–∞)** - –ö–ª–∞—Å–∏—Ñ–∏—Ü–∏—Ä–∞ –Ω–æ–≤–∏–Ω–∞—Ç–∞ –∫–∞—Ç–æ positive/negative/neutral\n",
        "2. **Text Embeddings (–∫–∞—Ç–æ features)** - –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞ —Ç–µ–∫—Å—Ç–∞ –≤ —á–∏—Å–ª–æ–≤ –≤–µ–∫—Ç–æ—Ä –∑–∞ –Ω–µ–≤—Ä–æ–Ω–Ω–∞—Ç–∞ –º—Ä–µ–∂–∞\n",
        "\n",
        "**–ó–∞ –Ω–∞—à–∏—è –º–æ–¥–µ–ª —â–µ –∏–∑–ø–æ–ª–∑–≤–∞–º–µ EMBEDDINGS –∫–∞—Ç–æ features!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: Using FinBERT embeddings as features for the model\n",
        "\n",
        "from src.models.news_encoder import FinBERTEncoder\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"FinBERT: Embeddings vs Sentiment\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Initialize encoder\n",
        "encoder = FinBERTEncoder()\n",
        "\n",
        "# Sample news text\n",
        "sample_news = [\n",
        "    \"Apple Inc. reported strong quarterly earnings, beating analyst expectations by 15%.\",\n",
        "    \"The Federal Reserve announced an unexpected interest rate hike, causing market volatility.\",\n",
        "    \"Microsoft announced a new strategic partnership with major cloud providers.\",\n",
        "]\n",
        "\n",
        "print(\"\\\\n1. SENTIMENT ANALYSIS (–æ—Ü–µ–Ω–∫–∞):\")\n",
        "print(\"-\" * 80)\n",
        "for news in sample_news:\n",
        "    sentiment = encoder.get_sentiment(news)\n",
        "    print(f\"\\\\nNews: {news[:60]}...\")\n",
        "    print(f\"Sentiment: {sentiment['label'].upper()}\")\n",
        "    print(f\"Probabilities: {sentiment['probabilities']}\")\n",
        "\n",
        "print(\"\\\\n\\\\n2. TEXT EMBEDDINGS (–∫–∞—Ç–æ features –∑–∞ –º–æ–¥–µ–ª–∞):\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Get embeddings (these will be used as features in the neural network)\n",
        "embeddings = encoder.encode_text(sample_news)\n",
        "print(f\"\\\\nEmbeddings shape: {embeddings.shape}\")\n",
        "print(f\"  - {embeddings.shape[0]} news items\")\n",
        "print(f\"  - {embeddings.shape[1]} dimensions per embedding\")\n",
        "print(f\"\\\\nThis is what we'll feed into the neural network!\")\n",
        "\n",
        "# Show sample embedding\n",
        "print(f\"\\\\nSample embedding (first 10 dimensions):\")\n",
        "print(embeddings[0][:10])\n",
        "\n",
        "print(\"\\\\n\\\\n3. COMBINED APPROACH:\")\n",
        "print(\"-\" * 80)\n",
        "print(\"We can use BOTH:\")\n",
        "print(\"  - Embeddings ‚Üí Input features for the model\")\n",
        "print(\"  - Sentiment ‚Üí Additional feature or for analysis\")\n",
        "\n",
        "# Get both embeddings and sentiment\n",
        "embeddings_with_sentiment, sentiments = encoder.encode_text(\n",
        "    sample_news,\n",
        "    return_sentiment=True\n",
        ")\n",
        "\n",
        "print(f\"\\\\nEmbeddings: {embeddings_with_sentiment.shape}\")\n",
        "print(f\"Sentiments: {len(sentiments)} items\")\n",
        "\n",
        "# We could add sentiment score as an additional feature\n",
        "sentiment_scores = []\n",
        "for sent in sentiments:\n",
        "    # Convert sentiment to numerical score\n",
        "    # positive = +1, neutral = 0, negative = -1\n",
        "    score_map = {'positive': 1.0, 'neutral': 0.0, 'negative': -1.0}\n",
        "    score = score_map.get(sent['label'], 0.0)\n",
        "    sentiment_scores.append(score)\n",
        "\n",
        "sentiment_scores = np.array(sentiment_scores)\n",
        "print(f\"\\\\nSentiment scores: {sentiment_scores}\")\n",
        "print(f\"  (Can be added as additional feature alongside embeddings)\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\" * 80)\n",
        "print(\"CONCLUSION:\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "‚úÖ FinBERT embeddings ‚Üí Main features for neural network (768 dimensions)\n",
        "‚úÖ Sentiment scores ‚Üí Optional additional feature (1 dimension)\n",
        "\n",
        "The embeddings capture semantic meaning of the news text,\n",
        "which the model can learn to correlate with price movements.\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –í–∞–∂–Ω–æ: –û—Ç–∫—ä–¥–µ –∏–¥–≤–∞—Ç –Ω–æ–≤–∏–Ω–∏—Ç–µ?\n",
        "\n",
        "**FinBERT –ù–ï –∏–∑–≤–ª–∏—á–∞ –Ω–æ–≤–∏–Ω–∏!** FinBERT —Å–∞–º–æ –æ–±—Ä–∞–±–æ—Ç–≤–∞ –Ω–æ–≤–∏–Ω–∏ –∫–æ–∏—Ç–æ –Ω–∏–µ –º—É –¥–∞–≤–∞–º–µ.\n",
        "\n",
        "**–ü—ä–ª–Ω–∏—è—Ç pipeline –µ:**\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  News Source    ‚îÇ  ‚Üê –ò–∑–≤–ª–∏—á–∞ –Ω–æ–≤–∏–Ω–∏ –æ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç\n",
        "‚îÇ  (yfinance/     ‚îÇ     (yfinance, Alpha Vantage, –∏ —Ç.–Ω.)\n",
        "‚îÇ   Alpha Vantage)‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "         ‚îÇ\n",
        "         ‚îÇ –Ω–æ–≤–∏–Ω–∏ (—Ç–µ–∫—Å—Ç)\n",
        "         ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ    FinBERT      ‚îÇ  ‚Üê –û–±—Ä–∞–±–æ—Ç–≤–∞ –Ω–æ–≤–∏–Ω–∏—Ç–µ\n",
        "‚îÇ  (news_encoder) ‚îÇ     (embeddings + sentiment)\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "         ‚îÇ\n",
        "         ‚îÇ embeddings (768 —á–∏—Å–ª–∞)\n",
        "         ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  Our Model      ‚îÇ  ‚Üê –ò–∑–ø–æ–ª–∑–≤–∞ embeddings –∫–∞—Ç–æ features\n",
        "‚îÇ  (Transformer)  ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "**–°—Ç—ä–ø–∫–∏:**\n",
        "1. **News Source** –∏–∑–≤–ª–∏—á–∞ –Ω–æ–≤–∏–Ω–∏ ‚Üí \"Apple reported strong earnings...\"\n",
        "2. **FinBERT** –æ–±—Ä–∞–±–æ—Ç–≤–∞ –Ω–æ–≤–∏–Ω–∏—Ç–µ ‚Üí [0.23, -0.45, ..., 0.12] (768 —á–∏—Å–ª–∞)\n",
        "3. **–ù–∞—à–∏—è—Ç –º–æ–¥–µ–ª** –∏–∑–ø–æ–ª–∑–≤–∞ embeddings ‚Üí –ø—Ä–æ–≥–Ω–æ–∑–∞ –∑–∞ —Ü–µ–Ω–∞—Ç–∞"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# –ü—Ä–∏–º–µ—Ä: –ü—ä–ª–µ–Ω pipeline –æ—Ç –Ω–æ–≤–∏–Ω–∏ –¥–æ embeddings\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"–ü–™–õ–ï–ù PIPELINE: News Source ‚Üí FinBERT ‚Üí Embeddings\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# –°—Ç—ä–ø–∫–∞ 1: –ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ –Ω–æ–≤–∏–Ω–∏ (–æ—Ç news source)\n",
        "print(\"\\\\n1. –ò–ó–í–õ–ò–ß–ê–ù–ï –ù–ê –ù–û–í–ò–ù–ò (–æ—Ç news source):\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "try:\n",
        "    from src.data.news_loader import fetch_yahoo_finance_news\n",
        "    \n",
        "    # –ò–∑–≤–ª–∏—á–∞–º–µ –Ω–æ–≤–∏–Ω–∏ –∑–∞ AAPL\n",
        "    print(\"–ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ –Ω–æ–≤–∏–Ω–∏ –∑–∞ AAPL –æ—Ç Yahoo Finance...\")\n",
        "    news_list = fetch_yahoo_finance_news('AAPL', limit=3)\n",
        "    \n",
        "    if news_list:\n",
        "        print(f\"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏ {len(news_list)} –Ω–æ–≤–∏–Ω–∏\")\n",
        "        print(\"\\\\n–ü—Ä–∏–º–µ—Ä–Ω–∞ –Ω–æ–≤–∏–Ω–∞:\")\n",
        "        news_item = news_list[0]\n",
        "        print(f\"  Title: {news_item['title']}\")\n",
        "        print(f\"  Publisher: {news_item['publisher']}\")\n",
        "        print(f\"  Time: {news_item['published_time']}\")\n",
        "        \n",
        "        # –°—Ç—ä–ø–∫–∞ 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å FinBERT\n",
        "        print(\"\\\\n\\\\n2. –û–ë–†–ê–ë–û–¢–ö–ê –° FINBERT:\")\n",
        "        print(\"-\" * 80)\n",
        "        \n",
        "        from src.models.news_encoder import FinBERTEncoder\n",
        "        encoder = FinBERTEncoder()\n",
        "        \n",
        "        # –í–∑–∏–º–∞–º–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –Ω–æ–≤–∏–Ω–∞—Ç–∞\n",
        "        news_text = news_item['title']  # –ú–æ–∂–µ –¥–∞ –¥–æ–±–∞–≤–∏–º –∏ description/summary\n",
        "        \n",
        "        print(f\"–û–±—Ä–∞–±–æ—Ç–≤–∞–Ω–µ –Ω–∞ –Ω–æ–≤–∏–Ω–∞: '{news_text[:80]}...'\")\n",
        "        \n",
        "        # –ü–æ–ª—É—á–∞–≤–∞–º–µ embeddings\n",
        "        embeddings = encoder.encode_text(news_text)\n",
        "        print(f\"\\\\n‚úÖ Embeddings shape: {embeddings.shape}\")\n",
        "        print(f\"   (–¢–æ–≤–∞ —Å–∞ {embeddings.shape[0]} —á–∏—Å–ª–∞ –∫–æ–∏—Ç–æ —â–µ –∏–∑–ø–æ–ª–∑–≤–∞–º–µ –∫–∞—Ç–æ features)\")\n",
        "        \n",
        "        # –ü–æ–ª—É—á–∞–≤–∞–º–µ sentiment\n",
        "        sentiment = encoder.get_sentiment(news_text)\n",
        "        print(f\"\\\\n‚úÖ Sentiment: {sentiment['label']}\")\n",
        "        print(f\"   Probabilities: {sentiment['probabilities']}\")\n",
        "        \n",
        "        print(\"\\\\n\\\\n3. –†–ï–ó–£–õ–¢–ê–¢:\")\n",
        "        print(\"-\" * 80)\n",
        "        print(\"\"\"\n",
        "        ‚úÖ –ò–º–∞–º–µ –Ω–æ–≤–∏–Ω–∏ (–æ—Ç Yahoo Finance)\n",
        "        ‚úÖ –ò–º–∞–º–µ embeddings (–æ—Ç FinBERT) - 768 —á–∏—Å–ª–∞\n",
        "        ‚úÖ –ò–º–∞–º–µ sentiment (–æ—Ç FinBERT) - positive/negative/neutral\n",
        "        \n",
        "        –°–ª–µ–¥–≤–∞—â–∞ —Å—Ç—ä–ø–∫–∞: –î–æ–±–∞–≤—è–Ω–µ –Ω–∞ embeddings –∫—ä–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ç–µ features\n",
        "        –∏ —Ç—Ä–µ–Ω–∏—Ä–∞–Ω–µ –Ω–∞ –º–æ–¥–µ–ª–∞!\n",
        "        \"\"\")\n",
        "        \n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  –ù–µ —Å–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏ –Ω–æ–≤–∏–Ω–∏. –ú–æ–∂–µ –¥–∞ –µ –ø—Ä–æ–±–ª–µ–º —Å yfinance.\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå –ì—Ä–µ—à–∫–∞: {e}\")\n",
        "    print(\"\\\\n–¢–æ–≤–∞ –µ –Ω–æ—Ä–º–∞–ª–Ω–æ –∞–∫–æ yfinance –Ω–µ –µ –∏–Ω—Å—Ç–∞–ª–∏—Ä–∞–Ω.\")\n",
        "    print(\"–ò–Ω—Å—Ç–∞–ª–∏—Ä–∞–π —Å: pip install yfinance\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\" * 80)\n",
        "print(\"–ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "‚úÖ News Source (yfinance) ‚Üí –ò–∑–≤–ª–∏—á–∞ –Ω–æ–≤–∏–Ω–∏ –æ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç\n",
        "‚úÖ FinBERT ‚Üí –û–±—Ä–∞–±–æ—Ç–≤–∞ –Ω–æ–≤–∏–Ω–∏—Ç–µ –∏ –≥–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞ –≤ embeddings\n",
        "‚úÖ Our Model ‚Üí –ò–∑–ø–æ–ª–∑–≤–∞ embeddings –∫–∞—Ç–æ features –∑–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏\n",
        "\n",
        "FinBERT –µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞, –Ω–µ –∏–∑—Ç–æ—á–Ω–∏–∫ –Ω–∞ –Ω–æ–≤–∏–Ω–∏!\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –†–µ—à–µ–Ω–∏–µ –∑–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –Ω–æ–≤–∏–Ω–∏ (2010-2024)\n",
        "\n",
        "–ó–∞ —Ü–µ–ª–∏—è –ø–µ—Ä–∏–æ–¥ –Ω–∞ –º–æ–¥–µ–ª–∞ (2010-2024) –∏–º–∞–º–µ –Ω—è–∫–æ–ª–∫–æ –æ–ø—Ü–∏–∏:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# –û–ø—Ü–∏–∏ –∑–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –Ω–æ–≤–∏–Ω–∏ (2010-2024)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"–û–ü–¶–ò–ò –ó–ê –ò–°–¢–û–†–ò–ß–ï–°–ö–ò –ù–û–í–ò–ù–ò (2010-2024)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "options = {\n",
        "    \"1. Yahoo Finance RSS Feeds\": {\n",
        "        \"–ü–æ–∫—Ä–∏—Ç–∏–µ\": \"–û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ (–æ–±–∏–∫–Ω–æ–≤–µ–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ç–µ 1-2 –≥–æ–¥–∏–Ω–∏)\",\n",
        "        \"–ë–µ–∑–ø–ª–∞—Ç–Ω–æ\": \"‚úÖ –î–∞\",\n",
        "        \"API Key\": \"‚ùå –ù–µ\",\n",
        "        \"–¢—Ä—É–¥–Ω–æ—Å—Ç\": \"–õ–µ—Å–Ω–æ\",\n",
        "        \"–ü—Ä–µ–ø–æ—Ä—ä–∫–∞\": \"–ó–∞ —Ç–µ—Å—Ç–≤–∞–Ω–µ, –Ω–æ –Ω–µ –∑–∞ –ø—ä–ª–Ω–æ –ø–æ–∫—Ä–∏—Ç–∏–µ\"\n",
        "    },\n",
        "    \"2. Web Scraping (Yahoo Finance, Seeking Alpha)\": {\n",
        "        \"–ü–æ–∫—Ä–∏—Ç–∏–µ\": \"–ü—ä–ª–Ω–æ (–º–æ–∂–µ –¥–∞ —Å–µ —Å—Ç–∏–≥–Ω–µ –¥–æ 2010)\",\n",
        "        \"–ë–µ–∑–ø–ª–∞—Ç–Ω–æ\": \"‚úÖ –î–∞\",\n",
        "        \"API Key\": \"‚ùå –ù–µ\",\n",
        "        \"–¢—Ä—É–¥–Ω–æ—Å—Ç\": \"–°—Ä–µ–¥–Ω–æ-—Ç—Ä—É–¥–Ω–æ\",\n",
        "        \"–ü—Ä–µ–ø–æ—Ä—ä–∫–∞\": \"–ù–∞–π-–¥–æ–±—Ä–æ —Ä–µ—à–µ–Ω–∏–µ –∑–∞ –±–µ–∑–ø–ª–∞—Ç–Ω–∏ –¥–∞–Ω–Ω–∏\"\n",
        "    },\n",
        "    \"3. Alpha Vantage News API\": {\n",
        "        \"–ü–æ–∫—Ä–∏—Ç–∏–µ\": \"–û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ (–ø–æ—Å–ª–µ–¥–Ω–∏—Ç–µ 1-2 –≥–æ–¥–∏–Ω–∏)\",\n",
        "        \"–ë–µ–∑–ø–ª–∞—Ç–Ω–æ\": \"‚úÖ –î–∞ (free tier)\",\n",
        "        \"API Key\": \"‚úÖ –î–∞ (–±–µ–∑–ø–ª–∞—Ç–µ–Ω)\",\n",
        "        \"–¢—Ä—É–¥–Ω–æ—Å—Ç\": \"–õ–µ—Å–Ω–æ\",\n",
        "        \"–ü—Ä–µ–ø–æ—Ä—ä–∫–∞\": \"–î–æ–ø—ä–ª–Ω–µ–Ω–∏–µ –∫—ä–º scraping\"\n",
        "    },\n",
        "    \"4. Financial Modeling Prep API\": {\n",
        "        \"–ü–æ–∫—Ä–∏—Ç–∏–µ\": \"–î–æ–±—Ä–æ (–Ω—è–∫–æ–ª–∫–æ –≥–æ–¥–∏–Ω–∏ –Ω–∞–∑–∞–¥)\",\n",
        "        \"–ë–µ–∑–ø–ª–∞—Ç–Ω–æ\": \"‚ö†Ô∏è –ß–∞—Å—Ç–∏—á–Ω–æ (free tier –æ–≥—Ä–∞–Ω–∏—á–µ–Ω)\",\n",
        "        \"API Key\": \"‚úÖ –î–∞\",\n",
        "        \"–¢—Ä—É–¥–Ω–æ—Å—Ç\": \"–õ–µ—Å–Ω–æ\",\n",
        "        \"–ü—Ä–µ–ø–æ—Ä—ä–∫–∞\": \"–ê–∫–æ free tier –µ –¥–æ—Å—Ç–∞—Ç—ä—á–µ–Ω\"\n",
        "    },\n",
        "    \"5. Pre-collected Datasets\": {\n",
        "        \"–ü–æ–∫—Ä–∏—Ç–∏–µ\": \"–ó–∞–≤–∏—Å–∏ –æ—Ç dataset-–∞\",\n",
        "        \"–ë–µ–∑–ø–ª–∞—Ç–Ω–æ\": \"‚úÖ –î–∞ (–∞–∫–æ –Ω–∞–º–µ—Ä–∏–º —Ç–∞–∫—ä–≤)\",\n",
        "        \"API Key\": \"‚ùå –ù–µ\",\n",
        "        \"–¢—Ä—É–¥–Ω–æ—Å—Ç\": \"–ú–Ω–æ–≥–æ –ª–µ—Å–Ω–æ\",\n",
        "        \"–ü—Ä–µ–ø–æ—Ä—ä–∫–∞\": \"–ù–∞–π-–¥–æ–±—Ä–æ –∞–∫–æ –Ω–∞–º–µ—Ä–∏–º –ø–æ–¥—Ö–æ–¥—è—â dataset\"\n",
        "    },\n",
        "}\n",
        "\n",
        "for option, details in options.items():\n",
        "    print(f\"\\\\n{option}:\")\n",
        "    for key, value in details.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\" * 80)\n",
        "print(\"–ü–†–ï–ü–û–†–™–ö–ê:\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "–ó–∞ —Ü–µ–ª–∏—è –ø–µ—Ä–∏–æ–¥ (2010-2024) –ø—Ä–µ–ø–æ—Ä—ä—á–≤–∞–º –ö–û–ú–ë–ò–ù–ò–†–ê–ù –ø–æ–¥—Ö–æ–¥:\n",
        "\n",
        "1. **Web Scraping** (–æ—Å–Ω–æ–≤–µ–Ω –∏–∑—Ç–æ—á–Ω–∏–∫)\n",
        "   - Yahoo Finance news pages (—Å —É–≤–∞–∂–µ–Ω–∏–µ –∫—ä–º rate limits)\n",
        "   - Seeking Alpha (–∞–∫–æ –∏–º–∞ RSS –∏–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ)\n",
        "   - MarketWatch (–∞–∫–æ –µ –¥–æ—Å—Ç—ä–ø–µ–Ω)\n",
        "   \n",
        "2. **RSS Feeds** (–¥–æ–ø—ä–ª–Ω–µ–Ω–∏–µ)\n",
        "   - Yahoo Finance RSS\n",
        "   - Google News RSS (—Ñ–∏–ª—Ç—Ä–∏—Ä–∞–Ω–æ –∑–∞ —Ñ–∏–Ω–∞–Ω—Å–∏)\n",
        "   \n",
        "3. **API-—Ç–∞** (–∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ç–µ –≥–æ–¥–∏–Ω–∏)\n",
        "   - Alpha Vantage (–∑–∞ sentiment scores)\n",
        "   - yfinance (–∑–∞ –Ω–∞–π-–Ω–æ–≤–∏—Ç–µ –Ω–æ–≤–∏–Ω–∏)\n",
        "\n",
        "–í–ê–ñ–ù–û:\n",
        "- –í–∏–Ω–∞–≥–∏ –ø—Ä–æ–≤–µ—Ä—è–≤–∞–π robots.txt –∏ Terms of Service\n",
        "- –î–æ–±–∞–≤—è–π –∑–∞–±–∞–≤—è–Ω–∏—è –º–µ–∂–¥—É –∑–∞—è–≤–∫–∏—Ç–µ (1-2 —Å–µ–∫—É–Ω–¥–∏)\n",
        "- –ö–µ—à–∏—Ä–∞–π –¥–∞–Ω–Ω–∏—Ç–µ –∑–∞ –¥–∞ –Ω–µ –ø—Ä–∞–≤–∏—à –ø–æ–≤—Ç–æ—Ä–Ω–∏ –∑–∞—è–≤–∫–∏\n",
        "- –ó–∞–ø–æ—á–Ω–∏ —Å –º–∞–ª—ä–∫ —Ç–µ—Å—Ç –ø—Ä–µ–¥–∏ –ø—ä–ª–Ω–æ –∏–∑–≤–ª–∏—á–∞–Ω–µ\n",
        "\n",
        "–°–ª–µ–¥–≤–∞—â–∞ —Å—Ç—ä–ø–∫–∞: –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ scraping –º–æ–¥—É–ª —Å –ø—Ä–∞–≤–∏–ª–Ω–æ handling –Ω–∞ rate limits.\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check Hugging Face dataset structure\n",
        "from datasets import load_dataset_builder, get_dataset_infos\n",
        "\n",
        "dataset_name = config.data.dataset_name\n",
        "print(f\"Checking dataset: {dataset_name}\")\n",
        "\n",
        "try:\n",
        "    builder = load_dataset_builder(dataset_name)\n",
        "    print(f\"\\nDataset info:\")\n",
        "    print(f\"  Description: {builder.info.description[:200]}...\" if builder.info.description else \"  No description\")\n",
        "    print(f\"  Features: {builder.info.features}\")\n",
        "    \n",
        "    # Check for news-related features\n",
        "    if hasattr(builder.info, 'features'):\n",
        "        feature_names = list(builder.info.features.keys()) if isinstance(builder.info.features, dict) else []\n",
        "        news_features = [f for f in feature_names if any(kw in f.lower() for kw in ['news', 'article', 'headline', 'text'])]\n",
        "        \n",
        "        if news_features:\n",
        "            print(f\"\\n‚úÖ Found news-related features: {news_features}\")\n",
        "        else:\n",
        "            print(f\"\\n‚ùå No news-related features found\")\n",
        "            print(f\"\\nAvailable features: {feature_names[:20]}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ö†Ô∏è  Could not load dataset builder: {e}\")\n",
        "    print(\"This is okay - we'll proceed with external news sources\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking dataset: pmoe7/SP_500_Stocks_Data-ratios_news_price_10_yrs\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset info:\n",
            "  No description\n",
            "  Features: {'_id': Value('string'), 'compound': Value('float64'), 'date': Value('string'), 'headline': Value('string'), 'neg': Value('float64'), 'neu': Value('float64'), 'pos': Value('float64'), 'ticker': Value('string'), 'time': Value('string')}\n",
            "\n",
            "‚úÖ Found news-related features: ['headline']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 Test News APIs\n",
        "\n",
        "Let's test different news APIs to see which one works best for our use case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 1: Alpha Vantage News API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Alpha Vantage News API\n",
        "# Documentation: https://www.alphavantage.co/documentation/#news-sentiment\n",
        "# Free tier: 5 API calls per minute, 500 calls per day\n",
        "\n",
        "import requests\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# You'll need to get an API key from https://www.alphavantage.co/support/#api-key\n",
        "ALPHA_VANTAGE_API_KEY = os.getenv('GKXZ5NT78PUAR2DT', 'demo')  # Replace with your key\n",
        "\n",
        "def test_alpha_vantage_news(ticker='AAPL', limit=10):\n",
        "    \"\"\"Test Alpha Vantage News API\"\"\"\n",
        "    url = 'https://www.alphavantage.co/query'\n",
        "    params = {\n",
        "        'function': 'NEWS_SENTIMENT',\n",
        "        'tickers': ticker,\n",
        "        'limit': limit,\n",
        "        'apikey': ALPHA_VANTAGE_API_KEY\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        response = requests.get(url, params=params, timeout=10)\n",
        "        data = response.json()\n",
        "        \n",
        "        if 'Information' in data:\n",
        "            print(f\"‚ö†Ô∏è  API Info: {data['Information']}\")\n",
        "            return None\n",
        "        \n",
        "        if 'feed' in data:\n",
        "            articles = data['feed']\n",
        "            print(f\"‚úÖ Successfully fetched {len(articles)} articles for {ticker}\")\n",
        "            \n",
        "            if articles:\n",
        "                print(f\"\\nSample article:\")\n",
        "                article = articles[0]\n",
        "                print(f\"  Title: {article.get('title', 'N/A')[:100]}...\")\n",
        "                print(f\"  Source: {article.get('source', 'N/A')}\")\n",
        "                print(f\"  Time: {article.get('time_published', 'N/A')}\")\n",
        "                print(f\"  Sentiment Score: {article.get('overall_sentiment_score', 'N/A')}\")\n",
        "                print(f\"  Relevance Score: {article.get('relevance_score', 'N/A')}\")\n",
        "            \n",
        "            return articles\n",
        "        else:\n",
        "            print(f\"‚ùå Unexpected response format: {list(data.keys())}\")\n",
        "            return None\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"Testing Alpha Vantage News API...\")\n",
        "print(\"Note: You need to set ALPHA_VANTAGE_API_KEY environment variable\")\n",
        "print(\"Get free API key at: https://www.alphavantage.co/support/#api-key\\n\")\n",
        "\n",
        "if ALPHA_VANTAGE_API_KEY != 'demo':\n",
        "    alpha_vantage_results = test_alpha_vantage_news('AAPL', limit=5)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Using demo key - will likely hit rate limit. Set your API key to test properly.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Alpha Vantage News API...\n",
            "Note: You need to set ALPHA_VANTAGE_API_KEY environment variable\n",
            "Get free API key at: https://www.alphavantage.co/support/#api-key\n",
            "\n",
            "‚ö†Ô∏è  Using demo key - will likely hit rate limit. Set your API key to test properly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 2: NewsAPI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# NewsAPI\n",
        "# Documentation: https://newsapi.org/docs\n",
        "# Free tier: 100 requests per day\n",
        "\n",
        "NEWSAPI_KEY = os.getenv('NEWSAPI_KEY', '')  # Get from https://newsapi.org/register\n",
        "\n",
        "def test_newsapi(ticker='AAPL', days_back=7):\n",
        "    \"\"\"Test NewsAPI\"\"\"\n",
        "    if not NEWSAPI_KEY:\n",
        "        print(\"‚ö†Ô∏è  NEWSAPI_KEY not set. Get one at https://newsapi.org/register\")\n",
        "        return None\n",
        "    \n",
        "    url = 'https://newsapi.org/v2/everything'\n",
        "    \n",
        "    # Calculate date range\n",
        "    to_date = datetime.now()\n",
        "    from_date = to_date - timedelta(days=days_back)\n",
        "    \n",
        "    params = {\n",
        "        'q': ticker,  # Search query\n",
        "        'from': from_date.strftime('%Y-%m-%d'),\n",
        "        'to': to_date.strftime('%Y-%m-%d'),\n",
        "        'sortBy': 'publishedAt',\n",
        "        'language': 'en',\n",
        "        'pageSize': 10,\n",
        "        'apiKey': NEWSAPI_KEY\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        response = requests.get(url, params=params, timeout=10)\n",
        "        data = response.json()\n",
        "        \n",
        "        if data.get('status') == 'ok':\n",
        "            articles = data.get('articles', [])\n",
        "            print(f\"‚úÖ Successfully fetched {len(articles)} articles for {ticker}\")\n",
        "            \n",
        "            if articles:\n",
        "                print(f\"\\nSample article:\")\n",
        "                article = articles[0]\n",
        "                print(f\"  Title: {article.get('title', 'N/A')[:100]}...\")\n",
        "                print(f\"  Source: {article.get('source', {}).get('name', 'N/A')}\")\n",
        "                print(f\"  Published: {article.get('publishedAt', 'N/A')}\")\n",
        "                print(f\"  Description: {article.get('description', 'N/A')[:150]}...\")\n",
        "            \n",
        "            return articles\n",
        "        else:\n",
        "            print(f\"‚ùå Error: {data.get('message', 'Unknown error')}\")\n",
        "            return None\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"Testing NewsAPI...\")\n",
        "if NEWSAPI_KEY:\n",
        "    newsapi_results = test_newsapi('AAPL', days_back=7)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Set NEWSAPI_KEY environment variable to test\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing NewsAPI...\n",
            "‚ö†Ô∏è  Set NEWSAPI_KEY environment variable to test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 3: Yahoo Finance (Free, no API key needed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Yahoo Finance - Free option using yfinance library\n",
        "# No API key needed, but may have rate limits\n",
        "\n",
        "try:\n",
        "    import yfinance as yf\n",
        "    \n",
        "    def test_yahoo_finance_news(ticker='AAPL'):\n",
        "        \"\"\"Test Yahoo Finance news\"\"\"\n",
        "        try:\n",
        "            stock = yf.Ticker(ticker)\n",
        "            news = stock.news\n",
        "            \n",
        "            if news:\n",
        "                print(f\"‚úÖ Successfully fetched {len(news)} news items for {ticker}\")\n",
        "                \n",
        "                if news:\n",
        "                    print(f\"\\nSample news item:\")\n",
        "                    item = news[0]\n",
        "                    print(f\"  Title: {item.get('title', 'N/A')[:100]}...\")\n",
        "                    print(f\"  Publisher: {item.get('publisher', 'N/A')}\")\n",
        "                    print(f\"  Published: {item.get('providerPublishTime', 'N/A')}\")\n",
        "                    print(f\"  Link: {item.get('link', 'N/A')[:80]}...\")\n",
        "                \n",
        "                return news\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è  No news found for {ticker}\")\n",
        "                return None\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {e}\")\n",
        "            return None\n",
        "    \n",
        "    print(\"Testing Yahoo Finance (yfinance)...\")\n",
        "    yahoo_results = test_yahoo_finance_news('AAPL')\n",
        "    \n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  yfinance not installed. Install with: pip install yfinance\")\n",
        "    print(\"This is a free option with no API key needed!\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Yahoo Finance (yfinance)...\n",
            "‚úÖ Successfully fetched 10 news items for AAPL\n",
            "\n",
            "Sample news item:\n",
            "  Title: N/A...\n",
            "  Publisher: N/A\n",
            "  Published: N/A\n",
            "  Link: N/A...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.4 Comparison and Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create comparison table\n",
        "comparison_data = {\n",
        "    'Source': ['Alpha Vantage', 'NewsAPI', 'Yahoo Finance (yfinance)'],\n",
        "    'API Key Required': ['Yes (free)', 'Yes (free)', 'No'],\n",
        "    'Rate Limit': ['5/min, 500/day', '100/day', 'Unknown (may vary)'],\n",
        "    'Historical Data': ['Limited', 'Limited (1 month free)', 'Recent only'],\n",
        "    'Sentiment Score': ['Yes (built-in)', 'No (need separate)', 'No'],\n",
        "    'Cost': ['Free tier available', 'Free tier available', 'Free'],\n",
        "    'Ease of Use': ['Medium', 'Easy', 'Very Easy'],\n",
        "}\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"NEWS SOURCES COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(df_comparison.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RECOMMENDATION\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "For Phase 1, I recommend:\n",
        "\n",
        "1. **Start with Yahoo Finance (yfinance)** - Easiest to set up, no API key needed\n",
        "   - Good for testing and prototyping\n",
        "   - May have limitations for historical data\n",
        "\n",
        "2. **Alpha Vantage as backup** - If we need sentiment scores built-in\n",
        "   - Requires API key but free tier is generous\n",
        "   - Has built-in sentiment analysis\n",
        "\n",
        "3. **For production/historical data** - May need paid service or web scraping\n",
        "   - Consider Financial Modeling Prep or Polygon.io for better historical coverage\n",
        "\n",
        "Next steps:\n",
        "- Test yfinance with multiple tickers\n",
        "- Check if we can get historical news (may need to scrape or use paid API)\n",
        "- Evaluate data quality and coverage\n",
        "\"\"\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "NEWS SOURCES COMPARISON\n",
            "================================================================================\n",
            "                  Source API Key Required         Rate Limit        Historical Data    Sentiment Score                Cost Ease of Use\n",
            "           Alpha Vantage       Yes (free)     5/min, 500/day                Limited     Yes (built-in) Free tier available      Medium\n",
            "                 NewsAPI       Yes (free)            100/day Limited (1 month free) No (need separate) Free tier available        Easy\n",
            "Yahoo Finance (yfinance)               No Unknown (may vary)            Recent only                 No                Free   Very Easy\n",
            "\n",
            "================================================================================\n",
            "RECOMMENDATION\n",
            "================================================================================\n",
            "\n",
            "For Phase 1, I recommend:\n",
            "\n",
            "1. **Start with Yahoo Finance (yfinance)** - Easiest to set up, no API key needed\n",
            "   - Good for testing and prototyping\n",
            "   - May have limitations for historical data\n",
            "\n",
            "2. **Alpha Vantage as backup** - If we need sentiment scores built-in\n",
            "   - Requires API key but free tier is generous\n",
            "   - Has built-in sentiment analysis\n",
            "\n",
            "3. **For production/historical data** - May need paid service or web scraping\n",
            "   - Consider Financial Modeling Prep or Polygon.io for better historical coverage\n",
            "\n",
            "Next steps:\n",
            "- Test yfinance with multiple tickers\n",
            "- Check if we can get historical news (may need to scrape or use paid API)\n",
            "- Evaluate data quality and coverage\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.5 Test Historical News Availability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test if we can get historical news (important for backtesting)\n",
        "print(\"Testing historical news availability...\")\n",
        "print(\"\\nNote: Most free APIs only provide recent news (last 1-30 days)\")\n",
        "print(\"For backtesting, we need news from 2010-2024 period\")\n",
        "print(\"\\nOptions:\")\n",
        "print(\"1. Use paid API with historical data (Financial Modeling Prep, Polygon.io)\")\n",
        "print(\"2. Web scraping from financial news sites (with proper attribution)\")\n",
        "print(\"3. Use pre-collected datasets (like the Hugging Face one if it has news)\")\n",
        "print(\"4. Start with recent data and expand backwards gradually\")\n",
        "\n",
        "# Check if yfinance can get older news\n",
        "try:\n",
        "    import yfinance as yf\n",
        "    from datetime import datetime\n",
        "    \n",
        "    stock = yf.Ticker('AAPL')\n",
        "    news = stock.news\n",
        "    \n",
        "    if news:\n",
        "        # Check date range\n",
        "        dates = []\n",
        "        for item in news:\n",
        "            if 'providerPublishTime' in item:\n",
        "                ts = item['providerPublishTime']\n",
        "                dt = datetime.fromtimestamp(ts)\n",
        "                dates.append(dt)\n",
        "        \n",
        "        if dates:\n",
        "            oldest = min(dates)\n",
        "            newest = max(dates)\n",
        "            print(f\"\\n‚úÖ Yahoo Finance news date range:\")\n",
        "            print(f\"   Oldest: {oldest.strftime('%Y-%m-%d')}\")\n",
        "            print(f\"   Newest: {newest.strftime('%Y-%m-%d')}\")\n",
        "            print(f\"   Coverage: {(newest - oldest).days} days\")\n",
        "            \n",
        "            if oldest.year < 2020:\n",
        "                print(f\"\\n‚úÖ Good! Can get historical data back to {oldest.year}\")\n",
        "            else:\n",
        "                print(f\"\\n‚ö†Ô∏è  Limited historical data - only goes back to {oldest.year}\")\n",
        "                print(f\"   May need alternative source for full backtest period\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ö†Ô∏è  Could not test historical availability: {e}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing historical news availability...\n",
            "\n",
            "Note: Most free APIs only provide recent news (last 1-30 days)\n",
            "For backtesting, we need news from 2010-2024 period\n",
            "\n",
            "Options:\n",
            "1. Use paid API with historical data (Financial Modeling Prep, Polygon.io)\n",
            "2. Web scraping from financial news sites (with proper attribution)\n",
            "3. Use pre-collected datasets (like the Hugging Face one if it has news)\n",
            "4. Start with recent data and expand backwards gradually\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Next Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PHASE 1 SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "‚úÖ Completed:\n",
        "1. Checked current dataset structure\n",
        "2. Tested multiple news API options\n",
        "3. Compared different sources\n",
        "\n",
        "üìã Next Steps (Phase 2):\n",
        "1. Choose primary news source (recommendation: yfinance for start)\n",
        "2. Create news_loader.py module\n",
        "3. Test fetching news for multiple tickers\n",
        "4. Design storage format for news data\n",
        "5. Create script to fetch historical news\n",
        "\n",
        "üí° Key Decisions:\n",
        "- Primary source: Yahoo Finance (yfinance) - easiest to start\n",
        "- Backup: Alpha Vantage (if we need sentiment scores)\n",
        "- Historical data: May need paid API or web scraping for full coverage\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}